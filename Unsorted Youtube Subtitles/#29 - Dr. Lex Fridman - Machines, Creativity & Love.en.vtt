WEBVTT
Kind: captions
Language: en

00:00:00.125 --> 00:00:00.958
[bright music]

00:00:00.958 --> 00:00:02.330
- Welcome to the "Huberman Lab Podcast,"

00:00:02.330 --> 00:00:04.930
where we discuss science
and science-based tools

00:00:04.930 --> 00:00:05.973
for everyday life.

00:00:09.350 --> 00:00:10.460
I'm Andrew Huberman,

00:00:10.460 --> 00:00:13.270
and I'm a Professor of
Neurobiology and Ophthalmology

00:00:13.270 --> 00:00:15.060
at Stanford School of Medicine.

00:00:15.060 --> 00:00:17.950
Today I have the pleasure of
introducing Dr. Lex Fridman

00:00:17.950 --> 00:00:21.150
as our guest on the
"Huberman Lab Podcast."

00:00:21.150 --> 00:00:23.920
Dr. Fridman is a researcher
at MIT specializing

00:00:23.920 --> 00:00:25.160
in machine learning,

00:00:25.160 --> 00:00:29.360
artificial intelligence and
human robot interactions.

00:00:29.360 --> 00:00:31.850
I must say that the conversation with Lex

00:00:31.850 --> 00:00:33.830
was without question,

00:00:33.830 --> 00:00:35.700
one of the most fascinating conversations

00:00:35.700 --> 00:00:36.640
that I've ever had,

00:00:36.640 --> 00:00:39.131
not just in my career, but in my lifetime.

00:00:39.131 --> 00:00:41.550
I knew that Lex worked on these topics.

00:00:41.550 --> 00:00:43.950
And I think many of you are
probably familiar with Lex

00:00:43.950 --> 00:00:45.240
and his interest in these topics

00:00:45.240 --> 00:00:48.290
from his incredible podcast,
the "Lex Fridman Podcast."

00:00:48.290 --> 00:00:50.280
If you're not already
watching that podcast,

00:00:50.280 --> 00:00:51.180
please subscribe to it.

00:00:51.180 --> 00:00:53.760
It is absolutely fantastic.

00:00:53.760 --> 00:00:55.500
But in holding this conversation with Lex,

00:00:55.500 --> 00:00:58.327
I realized something far more important.

00:00:58.327 --> 00:01:00.950
He revealed to us a bit of his dream.

00:01:00.950 --> 00:01:03.400
His dream about humans and robots,

00:01:03.400 --> 00:01:05.020
about humans and machines,

00:01:05.020 --> 00:01:06.630
and about how those interactions

00:01:06.630 --> 00:01:08.920
can change the way that
we perceive ourselves

00:01:08.920 --> 00:01:10.800
and that we interact with the world.

00:01:10.800 --> 00:01:13.100
We discuss relationships of all kinds,

00:01:13.100 --> 00:01:14.750
relationships with animals,

00:01:14.750 --> 00:01:16.470
relationships with friends,

00:01:16.470 --> 00:01:20.460
relationships with family
and romantic relationships.

00:01:20.460 --> 00:01:23.230
And we discuss relationships
with the machines.

00:01:23.230 --> 00:01:26.224
Machines that move and
machines that don't move,

00:01:26.224 --> 00:01:29.020
and machines that come
to understand us in ways

00:01:29.020 --> 00:01:31.730
that we could never
understand for ourselves,

00:01:31.730 --> 00:01:35.770
and how those machines can
educate us about ourselves.

00:01:35.770 --> 00:01:36.940
Before this conversation,

00:01:36.940 --> 00:01:39.420
I had no concept of the ways

00:01:39.420 --> 00:01:41.380
in which machines could inform me

00:01:41.380 --> 00:01:43.740
or anyone about themselves.

00:01:43.740 --> 00:01:44.620
By the end,

00:01:44.620 --> 00:01:46.820
I was absolutely taken with the idea,

00:01:46.820 --> 00:01:48.580
and I'm still taken with the idea

00:01:48.580 --> 00:01:49.980
that interactions with machines

00:01:49.980 --> 00:01:51.970
have a very particular kind,

00:01:51.970 --> 00:01:55.210
a kind that Lex understands and
wants to bring to the world,

00:01:55.210 --> 00:01:56.972
can not only transform the self,

00:01:56.972 --> 00:02:00.140
but may very well transform humanity.

00:02:00.140 --> 00:02:01.390
So whether or not you're familiar

00:02:01.390 --> 00:02:03.350
with Dr. Lex Fridman or not,

00:02:03.350 --> 00:02:04.420
I'm certain you're going to learn

00:02:04.420 --> 00:02:05.890
a tremendous amount from him

00:02:05.890 --> 00:02:07.550
during the course of our discussion,

00:02:07.550 --> 00:02:08.730
and that it will transform

00:02:08.730 --> 00:02:12.090
the way that you think about
yourself and about the world.

00:02:12.090 --> 00:02:13.210
Before we begin,

00:02:13.210 --> 00:02:14.690
I want to mention that this podcast

00:02:14.690 --> 00:02:17.580
is separate from my teaching
and research roles at Stanford.

00:02:17.580 --> 00:02:19.632
It is however part of my desire and effort

00:02:19.632 --> 00:02:22.770
to bring zero cost to consumer
information about science

00:02:22.770 --> 00:02:25.600
and science-related tools
to the general public.

00:02:25.600 --> 00:02:26.750
In keeping with that theme,

00:02:26.750 --> 00:02:29.630
I'd like to thank the
sponsors of today's podcast.

00:02:29.630 --> 00:02:31.331
Our first sponsor is ROKA.

00:02:31.331 --> 00:02:33.380
ROKA makes sunglasses and eyeglasses

00:02:33.380 --> 00:02:35.670
that are of absolutely phenomenal quality.

00:02:35.670 --> 00:02:36.530
The company was founded

00:02:36.530 --> 00:02:38.530
by two All-American
swimmers from Stanford,

00:02:38.530 --> 00:02:40.200
and everything about the sunglasses

00:02:40.200 --> 00:02:43.950
and eyeglasses they've designed
had performance in mind.

00:02:43.950 --> 00:02:46.260
I've spent a career working
on the visual system.

00:02:46.260 --> 00:02:47.730
And one of the fundamental issues

00:02:47.730 --> 00:02:49.740
that your visual system has to deal with

00:02:49.740 --> 00:02:51.960
is how to adjust what you see

00:02:51.960 --> 00:02:54.640
when it gets darker or
brighter in your environment.

00:02:54.640 --> 00:02:56.860
With ROKA Sunglasses and Eyeglasses,

00:02:56.860 --> 00:02:59.140
whether or not it's dim
in the room or outside,

00:02:59.140 --> 00:03:00.190
or not there's cloud cover,

00:03:00.190 --> 00:03:01.590
or whether or not you walk into a shadow,

00:03:01.590 --> 00:03:04.320
you can always see the
world with absolute clarity.

00:03:04.320 --> 00:03:06.260
And that just tells me
that they really understand

00:03:06.260 --> 00:03:07.650
the way that the visual system works.

00:03:07.650 --> 00:03:10.180
Processes like habituation
and attenuation.

00:03:10.180 --> 00:03:12.560
All these things that work
at a real mechanistic level

00:03:12.560 --> 00:03:14.590
have been built into these glasses.

00:03:14.590 --> 00:03:16.790
In addition, the glasses
are very lightweight.

00:03:16.790 --> 00:03:19.110
You don't even notice really
that they're on your face.

00:03:19.110 --> 00:03:21.800
And the quality of the lenses is terrific.

00:03:21.800 --> 00:03:23.500
Now, the glasses were also designed

00:03:23.500 --> 00:03:24.410
so that you could use them,

00:03:24.410 --> 00:03:26.860
not just while working
or at dinner, et cetera,

00:03:26.860 --> 00:03:28.590
but while exercising.

00:03:28.590 --> 00:03:30.620
They don't fall off your
face or slip off your face

00:03:30.620 --> 00:03:31.810
if you're sweating.

00:03:31.810 --> 00:03:32.643
And as I mentioned,

00:03:32.643 --> 00:03:33.476
they're extremely lightweight.

00:03:33.476 --> 00:03:34.860
So you can use them while running,

00:03:34.860 --> 00:03:37.070
you can use them while
cycling and so forth.

00:03:37.070 --> 00:03:39.690
Also the aesthetic of
ROKA glasses is terrific.

00:03:39.690 --> 00:03:41.690
Unlike a lot of performance
glasses out there,

00:03:41.690 --> 00:03:44.286
which frankly make
people look like cyborgs,

00:03:44.286 --> 00:03:46.030
these glasses look great.

00:03:46.030 --> 00:03:47.210
You can wear them out to dinner,

00:03:47.210 --> 00:03:50.480
you can wear them for
essentially any occasion.

00:03:50.480 --> 00:03:52.010
If you'd like to try ROKA glasses,

00:03:52.010 --> 00:03:53.660
you can go to roka.com.

00:03:53.660 --> 00:03:56.900
That's R-O-K-A .com and
enter the code Huberman

00:03:56.900 --> 00:03:59.200
to save 20% off your first order.

00:03:59.200 --> 00:04:00.033
That's ROKA,

00:04:00.033 --> 00:04:03.540
R-O-K-A .com and enter the
code Huberman at checkout.

00:04:03.540 --> 00:04:06.899
Today's episode is also
brought to us by InsideTracker.

00:04:06.899 --> 00:04:09.430
InsideTracker is a
personalized nutrition platform

00:04:09.430 --> 00:04:12.010
that analyzes data from your blood and DNA

00:04:12.010 --> 00:04:13.610
to help you better understand your body

00:04:13.610 --> 00:04:15.740
and help you reach your health goals.

00:04:15.740 --> 00:04:18.250
I'm a big believer in getting
regular blood work done

00:04:18.250 --> 00:04:20.740
for the simple reason
that many of the factors

00:04:20.740 --> 00:04:23.210
that impact our immediate
and long-term health

00:04:23.210 --> 00:04:25.870
can only be assessed from
a quality blood test.

00:04:25.870 --> 00:04:28.500
And now with the advent
of quality DNA tests,

00:04:28.500 --> 00:04:29.386
we can also get insight

00:04:29.386 --> 00:04:31.780
into some of our genetic underpinnings

00:04:31.780 --> 00:04:34.019
of our current and long-term health.

00:04:34.019 --> 00:04:35.610
The problem with a lot of blood

00:04:35.610 --> 00:04:37.470
and DNA tests out there, however,

00:04:37.470 --> 00:04:39.410
is you get the data back and
you don't know what to do

00:04:39.410 --> 00:04:40.510
with those data.

00:04:40.510 --> 00:04:41.810
You see that certain things are high

00:04:41.810 --> 00:04:43.030
or certain things are low,

00:04:43.030 --> 00:04:45.240
but you really don't know
what the actionable items are,

00:04:45.240 --> 00:04:47.330
what to do with all that information.

00:04:47.330 --> 00:04:48.690
With InsideTracker,

00:04:48.690 --> 00:04:51.690
they make it very easy to
act in the appropriate ways

00:04:51.690 --> 00:04:53.290
on the information that you get back

00:04:53.290 --> 00:04:55.110
from those blood and DNA tests.

00:04:55.110 --> 00:04:57.630
And that's through the use
of their online platform.

00:04:57.630 --> 00:04:59.910
They have a really easy to use dashboard

00:04:59.910 --> 00:05:02.529
that tells you what sorts of
things can bring the numbers

00:05:02.529 --> 00:05:05.770
for your metabolic factors,
endocrine factors, et cetera,

00:05:05.770 --> 00:05:08.070
into the ranges that you want and need

00:05:08.070 --> 00:05:10.190
for immediate and long-term health.

00:05:10.190 --> 00:05:13.130
In fact, I know one individual
just by way of example,

00:05:13.130 --> 00:05:14.270
that was feeling good,

00:05:14.270 --> 00:05:16.500
but decided to go with
an InsideTracker test

00:05:16.500 --> 00:05:18.000
and discovered that they had high levels

00:05:18.000 --> 00:05:19.850
of what's called C-reactive protein.

00:05:19.850 --> 00:05:21.850
They would have never
detected that otherwise.

00:05:21.850 --> 00:05:23.390
C-reactive protein is associated

00:05:23.390 --> 00:05:25.970
with a number of deleterious
health conditions,

00:05:25.970 --> 00:05:28.240
some heart issues, eye issues, et cetera.

00:05:28.240 --> 00:05:30.220
And so they were able
to take immediate action

00:05:30.220 --> 00:05:33.420
to try and resolve those CRP levels.

00:05:33.420 --> 00:05:34.660
And so with InsideTracker,

00:05:34.660 --> 00:05:36.020
you get that sort of insight.

00:05:36.020 --> 00:05:37.060
And as I mentioned before,

00:05:37.060 --> 00:05:38.480
without a blood or DNA test,

00:05:38.480 --> 00:05:40.410
there's no way you're going
to get that sort of insight

00:05:40.410 --> 00:05:42.860
until symptoms start to show up.

00:05:42.860 --> 00:05:44.350
If you'd like to try InsideTracker,

00:05:44.350 --> 00:05:47.400
you can go to insidetracker.com/huberman

00:05:47.400 --> 00:05:50.290
to get 25% off any of
InsideTracker's plans.

00:05:50.290 --> 00:05:52.720
You just use the code
Huberman at checkout.

00:05:52.720 --> 00:05:55.450
That's insidetracker.com/huberman

00:05:55.450 --> 00:05:58.730
to get 25% off any of
InsideTracker's plans.

00:05:58.730 --> 00:06:01.570
Today's podcast is brought
to us by Athletic Greens.

00:06:01.570 --> 00:06:03.240
Athletic Greens is an all-in-one

00:06:03.240 --> 00:06:05.680
vitamin mineral probiotic drink.

00:06:05.680 --> 00:06:09.050
I started taking Athletic
Greens way back in 2012.

00:06:09.050 --> 00:06:11.910
And so I'm delighted that
they're sponsoring the podcast.

00:06:11.910 --> 00:06:13.760
The reason I started
taking Athletic Greens

00:06:13.760 --> 00:06:15.840
and the reason I still
take Athletic Greens

00:06:15.840 --> 00:06:19.470
is that it covers all of my
vitamin mineral probiotic basis.

00:06:19.470 --> 00:06:22.050
In fact, when people ask
me, what should I take?

00:06:22.050 --> 00:06:24.490
I always suggest that the
first supplement people take

00:06:24.490 --> 00:06:25.650
is Athletic Greens,

00:06:25.650 --> 00:06:26.960
for the simple reason,

00:06:26.960 --> 00:06:29.520
is that the things that
contains covers your bases

00:06:29.520 --> 00:06:31.920
for metabolic health, endocrine health,

00:06:31.920 --> 00:06:34.030
and all sorts of other
systems in the body.

00:06:34.030 --> 00:06:35.730
And the inclusion of probiotics

00:06:35.730 --> 00:06:38.617
are essential for a
healthy gut microbiome.

00:06:38.617 --> 00:06:40.570
There are now tons of data showing

00:06:40.570 --> 00:06:42.850
that we have neurons in our gut,

00:06:42.850 --> 00:06:44.800
and keeping those neurons healthy requires

00:06:44.800 --> 00:06:45.660
that they are exposed

00:06:45.660 --> 00:06:47.980
to what are called the correct microbiota,

00:06:47.980 --> 00:06:49.930
little microorganisms that live in our gut

00:06:49.930 --> 00:06:51.150
and keep us healthy.

00:06:51.150 --> 00:06:53.900
And those neurons in turn
help keep our brain healthy.

00:06:53.900 --> 00:06:56.550
They influence things like
mood, our ability to focus,

00:06:56.550 --> 00:06:59.930
and many, many other
factors related to health.

00:06:59.930 --> 00:07:01.440
With Athletic Greens, it's terrific,

00:07:01.440 --> 00:07:03.200
because it also tastes really good.

00:07:03.200 --> 00:07:04.740
I drink it once or twice a day.

00:07:04.740 --> 00:07:07.080
I mix mine with water and
I add a little lemon juice,

00:07:07.080 --> 00:07:09.430
or sometimes a little bit of lime juice.

00:07:09.430 --> 00:07:11.130
If you want to try athletic greens,

00:07:11.130 --> 00:07:14.130
you can go to athleticgreens.com/huberman.

00:07:14.130 --> 00:07:16.710
And if you do that, you can
claim their special offer.

00:07:16.710 --> 00:07:18.700
They're giving away
five free travel packs,

00:07:18.700 --> 00:07:21.080
little packs that make it
easy to mix up Athletic Greens

00:07:21.080 --> 00:07:22.228
while you're on the road.

00:07:22.228 --> 00:07:24.280
And they'll give you a year supply

00:07:24.280 --> 00:07:26.310
of vitamin D3 and K2.

00:07:26.310 --> 00:07:28.970
Again, go to athleticgreens.com/huberman

00:07:28.970 --> 00:07:30.930
to claim that special offer.

00:07:30.930 --> 00:07:34.640
And now, my conversation
with Dr. Lex Fridman.

00:07:34.640 --> 00:07:35.580
- We meet again.

00:07:35.580 --> 00:07:36.543
- We meet again.

00:07:37.460 --> 00:07:39.650
Thanks so much for sitting down with me.

00:07:39.650 --> 00:07:43.001
I have a question that I think
is on a lot of people's minds

00:07:43.001 --> 00:07:46.440
or ought to be on a lot of people's minds,

00:07:46.440 --> 00:07:50.090
because we hear these
terms a lot these days,

00:07:50.090 --> 00:07:51.360
but I think most people,

00:07:51.360 --> 00:07:55.030
including most scientists and including me

00:07:55.030 --> 00:08:00.030
don't know really what is
artificial intelligence,

00:08:00.090 --> 00:08:01.377
and how is it different

00:08:01.377 --> 00:08:05.290
from things like machine
learning and robotics?

00:08:05.290 --> 00:08:08.960
So, if you would be so
kind as to explain to us,

00:08:08.960 --> 00:08:11.610
what is artificial intelligence,

00:08:11.610 --> 00:08:14.040
and what is machine learning?

00:08:14.040 --> 00:08:17.140
- Well, I think that
question is as complicated

00:08:17.140 --> 00:08:21.810
and as fascinating as the
question of, what is intelligence?

00:08:21.810 --> 00:08:25.650
So, I think of artificial intelligence,

00:08:25.650 --> 00:08:28.780
first, as a big philosophical thing.

00:08:28.780 --> 00:08:33.780
Pamela McCormick said
AI was the ancient wish

00:08:37.210 --> 00:08:38.340
to forge the gods,

00:08:38.340 --> 00:08:41.760
or was born as an ancient
wish to forge the gods.

00:08:41.760 --> 00:08:44.290
So I think at the big philosophical level,

00:08:44.290 --> 00:08:48.340
it's our longing to create
other intelligence systems.

00:08:48.340 --> 00:08:50.443
Perhaps systems more powerful than us.

00:08:51.770 --> 00:08:54.210
At the more narrow level,

00:08:54.210 --> 00:08:57.040
I think it's also set of tools

00:08:57.040 --> 00:08:59.290
that are computational mathematical tools

00:08:59.290 --> 00:09:01.160
to automate different tasks.

00:09:01.160 --> 00:09:05.660
And then also it's our attempt
to understand our own mind.

00:09:05.660 --> 00:09:09.960
So, build systems that exhibit
some intelligent behavior

00:09:09.960 --> 00:09:12.412
in order to understand
what is intelligence

00:09:12.412 --> 00:09:14.630
in our own selves.

00:09:14.630 --> 00:09:16.210
So all of those things are true.

00:09:16.210 --> 00:09:19.360
Of course, what AI really
means as a community,

00:09:19.360 --> 00:09:21.540
as a set of researchers and engineers,

00:09:21.540 --> 00:09:22.680
it's a set of tools,

00:09:22.680 --> 00:09:25.330
a set of computational techniques

00:09:25.330 --> 00:09:27.693
that allow you to solve various problems.

00:09:28.638 --> 00:09:33.050
There's a long history
that approaches the problem

00:09:33.050 --> 00:09:34.250
from different perspectives.

00:09:34.250 --> 00:09:37.690
What's always been throughout
one of the threads,

00:09:37.690 --> 00:09:40.310
one of the communities goes under the flag

00:09:40.310 --> 00:09:41.250
of machine learning,

00:09:41.250 --> 00:09:45.688
which is emphasizing in the AI space,

00:09:45.688 --> 00:09:48.130
the task of learning.

00:09:48.130 --> 00:09:49.560
How do you make a machine

00:09:49.560 --> 00:09:51.200
that knows very little in the beginning,

00:09:51.200 --> 00:09:53.479
follow some kind of process

00:09:53.479 --> 00:09:57.710
and learns to become better and
better at a particular task?

00:09:57.710 --> 00:10:02.710
What's been most very effective
in the recent about 15 years

00:10:03.700 --> 00:10:05.730
is a set of techniques
that fall under the flag

00:10:05.730 --> 00:10:08.700
of deep learning that
utilize neural networks.

00:10:08.700 --> 00:10:12.970
When your networks are these
fascinating things inspired

00:10:12.970 --> 00:10:16.320
by the structure of the human brain,

00:10:16.320 --> 00:10:18.460
very loosely, but they have a,

00:10:18.460 --> 00:10:21.600
it's a network of these little
basic computational units

00:10:21.600 --> 00:10:24.048
called neurons, artificial neurons.

00:10:24.048 --> 00:10:25.820
And they have,

00:10:25.820 --> 00:10:28.760
these architectures have
an input and output.

00:10:28.760 --> 00:10:30.190
They know nothing in the beginning,

00:10:30.190 --> 00:10:33.250
and their task with learning
something interesting.

00:10:33.250 --> 00:10:35.270
What that's something interesting is,

00:10:35.270 --> 00:10:38.260
usually involves a particular task.

00:10:38.260 --> 00:10:41.200
There's a lot of ways to talk about this

00:10:41.200 --> 00:10:42.033
and break this down.

00:10:42.033 --> 00:10:45.920
Like one of them is how
much human supervision

00:10:45.920 --> 00:10:48.370
is required to teach this thing.

00:10:48.370 --> 00:10:51.890
So supervised learning is broad category,

00:10:51.890 --> 00:10:56.210
is the neural network knows
nothing in the beginning

00:10:56.210 --> 00:11:00.420
and then it's given a bunch
of examples in computer vision

00:11:00.420 --> 00:11:04.057
that will be examples of cats,
dogs, cars, traffic signs,

00:11:04.057 --> 00:11:06.150
and then you're given the image

00:11:06.150 --> 00:11:09.590
and you're given the ground
truth of what's in that image.

00:11:09.590 --> 00:11:13.070
And when you get a large
database of such image examples

00:11:13.070 --> 00:11:14.320
where you know the truth,

00:11:15.302 --> 00:11:18.660
the neural network is
able to learn by example,

00:11:18.660 --> 00:11:21.114
that's called supervised learning.

00:11:21.114 --> 00:11:23.880
There's a lot of fascinating
questions within that,

00:11:23.880 --> 00:11:26.070
which is, how do you provide the truth?

00:11:26.070 --> 00:11:28.853
When you given an image of a cat,

00:11:29.916 --> 00:11:32.960
how do you provide to the computer

00:11:32.960 --> 00:11:34.960
that this image contains a cat?

00:11:34.960 --> 00:11:38.010
Do you just say the entire
image is a picture of a cat?

00:11:38.010 --> 00:11:40.370
Do you do what's very commonly been done,

00:11:40.370 --> 00:11:41.570
which is a bounding box,

00:11:41.570 --> 00:11:45.430
you have a very crude box
around the cat's face saying,

00:11:45.430 --> 00:11:46.550
this is a cat?

00:11:46.550 --> 00:11:48.770
Do you do semantic segmentation?

00:11:48.770 --> 00:11:51.050
Mind you, this is a 2D image of a cat.

00:11:51.050 --> 00:11:51.883
So it's not,

00:11:53.000 --> 00:11:53.980
the computer knows nothing

00:11:53.980 --> 00:11:55.700
about our three-dimensional world,

00:11:55.700 --> 00:11:57.370
is just looking at a set of pixels.

00:11:57.370 --> 00:12:01.180
So, semantic segmentation
is drawing a nice,

00:12:01.180 --> 00:12:04.960
very crisp outline around the
cat and saying, that's a cat.

00:12:04.960 --> 00:12:07.110
That's really difficult
to provide that truth.

00:12:07.110 --> 00:12:09.550
And one of the fundamental open questions

00:12:09.550 --> 00:12:10.830
in computer vision is,

00:12:10.830 --> 00:12:13.840
is that even a good
representation of the truth?

00:12:13.840 --> 00:12:18.600
Now, there's another
contrasting set of ideas

00:12:18.600 --> 00:12:21.580
that our attention they're overlapping is,

00:12:21.580 --> 00:12:24.370
well, it's used to be called
unsupervised learning.

00:12:24.370 --> 00:12:27.190
What's commonly now called
self-supervised learning.

00:12:27.190 --> 00:12:29.460
Which is trying to get less and less

00:12:29.460 --> 00:12:34.010
and less human supervision into the task.

00:12:34.010 --> 00:12:38.023
So self-supervised learning is more,

00:12:38.966 --> 00:12:42.040
it's been very successful in
the domain of language model,

00:12:42.040 --> 00:12:43.220
natural English processing,

00:12:43.220 --> 00:12:45.000
and now more and more as being successful

00:12:45.000 --> 00:12:46.510
in computer vision task.

00:12:46.510 --> 00:12:48.900
And the idea there is,

00:12:48.900 --> 00:12:53.180
let the machine without
any ground-truth annotation

00:12:53.180 --> 00:12:55.770
just look at pictures on the internet,

00:12:55.770 --> 00:12:57.630
or look at texts on the internet

00:12:57.630 --> 00:13:02.360
and try to learn something generalizable

00:13:02.360 --> 00:13:05.840
about the ideas that are
at the core of language

00:13:05.840 --> 00:13:07.230
or at the core of vision.

00:13:07.230 --> 00:13:08.663
And based on that,

00:13:09.610 --> 00:13:12.940
we humans at its best like
to call that common sense.

00:13:12.940 --> 00:13:13.773
So with this,

00:13:13.773 --> 00:13:16.030
we have this giant base of knowledge

00:13:16.030 --> 00:13:18.750
on top of which we build
more sophisticated knowledge.

00:13:18.750 --> 00:13:21.570
We have this kind of
commonsense knowledge.

00:13:21.570 --> 00:13:23.420
And so the idea with
self-supervised learning

00:13:23.420 --> 00:13:27.320
is to build this
commonsense knowledge about,

00:13:27.320 --> 00:13:30.470
what are the fundamental visual ideas

00:13:30.470 --> 00:13:32.050
that make up a cat and a dog

00:13:32.050 --> 00:13:33.310
and all those kinds of things

00:13:33.310 --> 00:13:35.810
without ever having human supervision?

00:13:35.810 --> 00:13:38.471
The dream there is the,

00:13:38.471 --> 00:13:43.350
you just let an AI system
that's self supervised

00:13:43.350 --> 00:13:44.495
run around the internet for awhile,

00:13:44.495 --> 00:13:47.500
watch YouTube videos for
millions and millions of hours,

00:13:47.500 --> 00:13:51.420
and without any supervision be primed

00:13:51.420 --> 00:13:54.680
and ready to actually learn
with very few examples

00:13:54.680 --> 00:13:56.720
once the human is able to show up.

00:13:56.720 --> 00:13:59.300
We think of children in this way,

00:13:59.300 --> 00:14:00.180
human children,

00:14:00.180 --> 00:14:03.080
is your parents only
give one or two examples

00:14:03.080 --> 00:14:04.325
to teach a concept.

00:14:04.325 --> 00:14:07.070
The dream with self-supervised learning

00:14:07.070 --> 00:14:10.120
is that will be the same with machines.

00:14:10.120 --> 00:14:14.010
That they would watch millions
of hours of YouTube videos,

00:14:14.010 --> 00:14:16.820
and then come to a human
and be able to understand

00:14:16.820 --> 00:14:19.400
when the human shows them, this is a cat.

00:14:19.400 --> 00:14:20.830
Like, remember this' a cat.

00:14:20.830 --> 00:14:22.740
They will understand that a cat

00:14:22.740 --> 00:14:24.980
is not just the thing with pointy ears,

00:14:24.980 --> 00:14:28.830
or a cat is a thing that's
orange, or is furry,

00:14:28.830 --> 00:14:30.850
they'll see something more fundamental

00:14:30.850 --> 00:14:32.750
that we humans might not actually be able

00:14:32.750 --> 00:14:33.940
to introspect and understand.

00:14:33.940 --> 00:14:35.090
Like, if I asked you,

00:14:35.090 --> 00:14:36.830
what makes a cat versus a dog,

00:14:36.830 --> 00:14:39.440
you wouldn't probably not
be able to answer that,

00:14:39.440 --> 00:14:42.790
but if I showed you, brought
to you a cat and a dog,

00:14:42.790 --> 00:14:44.430
you'll be able to tell the difference.

00:14:44.430 --> 00:14:47.090
What are the ideas that your brain uses

00:14:47.090 --> 00:14:48.840
to make that difference?

00:14:48.840 --> 00:14:51.310
That's the whole dream with
self-supervised learning,

00:14:51.310 --> 00:14:53.930
is it would be able to
learn that on its own.

00:14:53.930 --> 00:14:56.120
That set of commonsense knowledge,

00:14:56.120 --> 00:14:57.910
that's able to tell the difference.

00:14:57.910 --> 00:15:01.640
And then there's like a
lot of incredible uses

00:15:01.640 --> 00:15:03.063
of self-supervised learning,

00:15:04.040 --> 00:15:07.340
very weirdly called self-play mechanism.

00:15:07.340 --> 00:15:08.376
That's the mechanism behind

00:15:08.376 --> 00:15:12.410
the reinforcement learning successes

00:15:12.410 --> 00:15:15.760
of the systems that won at Go,

00:15:15.760 --> 00:15:18.890
at, AlphaZero that won a chess.

00:15:18.890 --> 00:15:19.723
- Oh, I see.

00:15:19.723 --> 00:15:20.870
That play games?

00:15:20.870 --> 00:15:21.703
- [Lex] That play games.

00:15:21.703 --> 00:15:22.536
- Got it.

00:15:22.536 --> 00:15:24.860
- So the idea of self-play is probably,

00:15:24.860 --> 00:15:27.920
applies to other domains than just games.

00:15:27.920 --> 00:15:30.900
Is a system that just
plays against itself.

00:15:30.900 --> 00:15:33.620
And this is fascinating
in all kinds of domains,

00:15:33.620 --> 00:15:36.640
but it knows nothing in the beginning.

00:15:36.640 --> 00:15:38.600
And the whole idea is it creates

00:15:38.600 --> 00:15:41.090
a bunch of mutations of itself

00:15:41.090 --> 00:15:45.403
and plays against those
versions of itself.

00:15:46.670 --> 00:15:50.270
And the fascinating thing is
when you play against systems

00:15:50.270 --> 00:15:51.850
that are a little bit better than you,

00:15:51.850 --> 00:15:53.750
you start to get better yourself.

00:15:53.750 --> 00:15:54.583
Like learning,

00:15:54.583 --> 00:15:56.150
that's how learning happens.

00:15:56.150 --> 00:15:57.330
That's true for martial arts.

00:15:57.330 --> 00:15:59.290
It's true in a lot of cases.

00:15:59.290 --> 00:16:02.080
Where you want to be
interacting with systems

00:16:02.080 --> 00:16:03.930
that are just a little better than you.

00:16:03.930 --> 00:16:06.840
And then through this process
of interacting with systems

00:16:06.840 --> 00:16:08.170
just a little better than you,

00:16:08.170 --> 00:16:09.980
you start following this process

00:16:09.980 --> 00:16:11.980
where everybody starts getting
better and better and better

00:16:11.980 --> 00:16:15.260
and better until you are
several orders of magnitude

00:16:15.260 --> 00:16:17.947
better than the world champion
in chess, for example.

00:16:17.947 --> 00:16:21.090
And it's fascinating because
it's like a runaway system.

00:16:21.090 --> 00:16:23.590
One of the most terrifying
and exciting things

00:16:23.590 --> 00:16:26.390
that David Silver, the creator
of AlphaGo and AlphaZero,

00:16:27.240 --> 00:16:29.113
one of the leaders of the team said,

00:16:30.380 --> 00:16:31.980
to me is a,

00:16:31.980 --> 00:16:36.670
they haven't found the
ceiling for AlphaZero.

00:16:36.670 --> 00:16:39.400
Meaning it could just
arbitrarily keep improving.

00:16:39.400 --> 00:16:40.870
Now, in the realm of chess,

00:16:40.870 --> 00:16:41.900
that doesn't matter to us.

00:16:41.900 --> 00:16:43.030
That it's like,

00:16:43.030 --> 00:16:45.020
it just ran away with the game of chess.

00:16:45.020 --> 00:16:47.935
Like it's like just so
much better than humans.

00:16:47.935 --> 00:16:49.470
But the question is what,

00:16:49.470 --> 00:16:54.330
if you can create that in the
realm that does have a bigger,

00:16:54.330 --> 00:16:57.910
deeper effect on human
beings and societies,

00:16:57.910 --> 00:17:00.000
that can be a terrifying process.

00:17:00.000 --> 00:17:01.820
To me, it's an exciting process

00:17:01.820 --> 00:17:03.750
if you supervise it correctly,

00:17:03.750 --> 00:17:08.750
if you inject, if what's
called value alignment,

00:17:09.830 --> 00:17:13.530
you make sure that the goals
that the AI is optimizing

00:17:13.530 --> 00:17:17.030
is aligned with human
beings and human societies.

00:17:17.030 --> 00:17:19.260
There's a lot of fascinating
things to talk about

00:17:19.260 --> 00:17:23.240
within the specifics of neural networks

00:17:23.240 --> 00:17:25.620
and all the problems that
people are working on.

00:17:25.620 --> 00:17:27.580
But I would say the really big,

00:17:27.580 --> 00:17:29.660
exciting one is self-supervised learning.

00:17:29.660 --> 00:17:33.053
We're trying to get less
and less human supervision,

00:17:35.570 --> 00:17:38.780
less and less human
supervision of neural networks.

00:17:38.780 --> 00:17:42.010
And also just a comment and I'll shut up.

00:17:42.010 --> 00:17:43.130
- No, please keep going.

00:17:43.130 --> 00:17:44.390
I'm learning.

00:17:44.390 --> 00:17:45.520
I have questions, but I'm learning.

00:17:45.520 --> 00:17:46.510
So please keep going.

00:17:46.510 --> 00:17:49.470
- So, to me what's
exciting is not the theory,

00:17:49.470 --> 00:17:50.818
it's always the application.

00:17:50.818 --> 00:17:52.960
One of the most exciting applications

00:17:52.960 --> 00:17:55.140
of artificial intelligence,

00:17:55.140 --> 00:17:57.510
specifically neural networks
and machine learning

00:17:57.510 --> 00:17:59.170
is Tesla Autopilot.

00:17:59.170 --> 00:18:01.620
So these are systems that are
working in the real world.

00:18:01.620 --> 00:18:03.650
This isn't an academic exercise.

00:18:03.650 --> 00:18:05.250
This is human lives at stake.

00:18:05.250 --> 00:18:07.250
This is safety-critical.

00:18:07.250 --> 00:18:08.577
- These are automated vehicles.

00:18:08.577 --> 00:18:10.430
Autonomous vehicles.
- Semi-autonomous.

00:18:10.430 --> 00:18:11.300
We want to be.

00:18:11.300 --> 00:18:12.370
- Okay.

00:18:12.370 --> 00:18:15.000
- We've gone through wars on these topics,

00:18:15.000 --> 00:18:16.310
- Semi-autonomous vehicles.

00:18:16.310 --> 00:18:17.143
- Semi-autonomous.

00:18:17.143 --> 00:18:22.143
So, even though it's called
a FSD, Full Self-Driving,

00:18:22.590 --> 00:18:25.000
it is currently not fully autonomous,

00:18:25.000 --> 00:18:27.780
meaning human supervision is required.

00:18:27.780 --> 00:18:30.940
So, human is tasked with
overseeing the systems.

00:18:30.940 --> 00:18:35.250
In fact, liability-wise, the
human is always responsible.

00:18:35.250 --> 00:18:37.990
This is a human factor
psychology question,

00:18:37.990 --> 00:18:39.410
which is fascinating.

00:18:39.410 --> 00:18:43.030
I'm fascinated by the whole space,

00:18:43.030 --> 00:18:46.200
which is a whole 'nother space
of human robot interaction

00:18:46.200 --> 00:18:48.800
when AI systems and humans work together

00:18:48.800 --> 00:18:50.010
to accomplish tasks.

00:18:50.010 --> 00:18:55.010
That dance to me is one of
the smaller communities,

00:18:55.440 --> 00:18:57.630
but I think it will be one of the most

00:18:57.630 --> 00:19:00.370
important open problems
once they're solved,

00:19:00.370 --> 00:19:03.561
is how the humans and
robots dance together.

00:19:03.561 --> 00:19:07.573
To me, semi-autonomous driving
is one of those spaces.

00:19:07.573 --> 00:19:11.720
So for Elon, for example,
he doesn't see it that way,

00:19:11.720 --> 00:19:16.550
he sees semi-autonomous
driving as a stepping stone

00:19:16.550 --> 00:19:18.660
towards fully autonomous driving.

00:19:18.660 --> 00:19:22.760
Like, humans and robots
can't dance well together.

00:19:22.760 --> 00:19:25.370
Like, humans and humans dance
and robots and robots dance.

00:19:25.370 --> 00:19:26.461
Like, we need to,

00:19:26.461 --> 00:19:28.100
this is an engineering problem,

00:19:28.100 --> 00:19:31.730
we need to design a perfect
robot that solves this problem.

00:19:31.730 --> 00:19:32.780
To me forever,

00:19:32.780 --> 00:19:34.170
maybe this is not the case with driving,

00:19:34.170 --> 00:19:37.170
but the world is going
to be full of problems

00:19:37.170 --> 00:19:40.430
with always humans and
robots have to interact,

00:19:40.430 --> 00:19:43.550
because I think robots
will always be flawed,

00:19:43.550 --> 00:19:47.169
just like humans are going
to be flawed, are flawed.

00:19:47.169 --> 00:19:50.040
And that's what makes life beautiful,

00:19:50.040 --> 00:19:51.040
that they're flawed.

00:19:51.040 --> 00:19:52.400
That's where learning happens

00:19:52.400 --> 00:19:55.890
at the edge of your capabilities.

00:19:55.890 --> 00:19:57.560
So you always have to figure out,

00:19:57.560 --> 00:20:02.560
how can flawed robots and
flawed humans interact together

00:20:03.522 --> 00:20:08.400
such that they, like the sum
is bigger than the whole,

00:20:08.400 --> 00:20:11.580
as opposed to focusing on just
building the perfect robot?

00:20:11.580 --> 00:20:12.590
- Mm-hmm.

00:20:12.590 --> 00:20:15.370
- So that's one of the
most exciting applications

00:20:15.370 --> 00:20:17.830
I would say of artificial
intelligence to me

00:20:17.830 --> 00:20:20.690
is autonomous driving, the
semi-autonomous driving.

00:20:20.690 --> 00:20:23.290
And that's a really good
example of machine learning

00:20:23.290 --> 00:20:25.590
because those systems
are constantly learning.

00:20:26.800 --> 00:20:31.280
And there's a process there
that maybe I can comment on,

00:20:31.280 --> 00:20:33.957
the, Andrej Karpathy who's
the head of autopilot

00:20:33.957 --> 00:20:36.098
calls it the data engine.

00:20:36.098 --> 00:20:38.940
And this process applies for
a lot of machine learning,

00:20:38.940 --> 00:20:40.940
which is you build a
system that's pretty good

00:20:40.940 --> 00:20:41.851
at doing stuff,

00:20:41.851 --> 00:20:45.380
you send it out into the real world,

00:20:45.380 --> 00:20:46.870
it starts doing the stuff

00:20:46.870 --> 00:20:49.230
and then it runs into what
are called edge cases,

00:20:49.230 --> 00:20:50.700
like failure cases,

00:20:50.700 --> 00:20:52.491
where it screws up.

00:20:52.491 --> 00:20:53.990
We do this as kids.

00:20:53.990 --> 00:20:54.997
That you have-

00:20:54.997 --> 00:20:56.380
- You do this as adults.

00:20:56.380 --> 00:20:57.358
- We do this as adults.

00:20:57.358 --> 00:20:58.620
Exactly.

00:20:58.620 --> 00:21:00.170
But we learn really quickly.

00:21:00.170 --> 00:21:01.380
But the whole point,

00:21:01.380 --> 00:21:03.309
and this is the fascinating
thing about driving,

00:21:03.309 --> 00:21:06.163
is you realize there's
millions of edge cases.

00:21:07.000 --> 00:21:11.020
There's just like weird situations
that you did not expect.

00:21:11.020 --> 00:21:13.120
And so the data engine process

00:21:13.120 --> 00:21:15.150
is you collect those edge cases,

00:21:15.150 --> 00:21:17.110
and then you go back to the drawing board

00:21:17.110 --> 00:21:18.047
and learn from them.

00:21:18.047 --> 00:21:21.020
And so you have to
create this data pipeline

00:21:21.020 --> 00:21:22.690
where all these cars,

00:21:22.690 --> 00:21:25.380
hundreds of thousands of
cars are driving around

00:21:25.380 --> 00:21:27.080
and something weird happens.

00:21:27.080 --> 00:21:30.940
And so whenever this weird detector fires,

00:21:30.940 --> 00:21:32.490
it's another important concept,

00:21:33.430 --> 00:21:37.430
that piece of data goes
back to the mothership

00:21:37.430 --> 00:21:39.360
for the training,

00:21:39.360 --> 00:21:40.880
for the retraining of the system.

00:21:40.880 --> 00:21:42.680
And through this data engine process,

00:21:42.680 --> 00:21:44.423
it keeps improving and
getting better and better

00:21:44.423 --> 00:21:45.910
and better and better.

00:21:45.910 --> 00:21:47.650
So basically you send out

00:21:47.650 --> 00:21:50.560
a pretty clever AI
systems out into the world

00:21:50.560 --> 00:21:54.460
and let it find the edge cases,

00:21:54.460 --> 00:21:57.240
let it screw up just enough to figure out

00:21:57.240 --> 00:21:58.570
where the edge cases are,

00:21:58.570 --> 00:22:00.840
and then go back and learn from them,

00:22:00.840 --> 00:22:02.670
and then send out that new version

00:22:02.670 --> 00:22:04.280
and keep updating that version.

00:22:04.280 --> 00:22:06.340
- Is the updating done by humans?

00:22:06.340 --> 00:22:08.980
- The annotation is done by humans.

00:22:08.980 --> 00:22:11.070
The, so you have to,

00:22:11.070 --> 00:22:13.470
the weird examples come back,

00:22:13.470 --> 00:22:14.830
the edge cases,

00:22:14.830 --> 00:22:17.730
and you have to label what
actually happened in there.

00:22:17.730 --> 00:22:22.143
There's also some mechanisms
for automatically labeling,

00:22:23.180 --> 00:22:24.230
but mostly,

00:22:24.230 --> 00:22:26.790
I think you always have to
rely on humans to improve,

00:22:26.790 --> 00:22:30.040
to understand what's
happening in the weird cases.

00:22:30.040 --> 00:22:31.790
And then there's a lot of debate.

00:22:31.790 --> 00:22:32.690
And this, the other thing,

00:22:32.690 --> 00:22:34.500
what is artificial intelligence?

00:22:34.500 --> 00:22:36.850
Which is a bunch of smart people

00:22:36.850 --> 00:22:39.780
having very different opinions
about what is intelligence.

00:22:39.780 --> 00:22:41.920
So AI is basically a community of people

00:22:41.920 --> 00:22:43.178
who don't agree on anything.

00:22:43.178 --> 00:22:45.063
- And it seems to be the case.

00:22:45.970 --> 00:22:46.930
First of all,

00:22:46.930 --> 00:22:48.700
this is a beautiful description of terms

00:22:48.700 --> 00:22:51.940
that I've heard many times
among my colleagues at Stanford,

00:22:51.940 --> 00:22:53.800
at meetings in the outside world.

00:22:53.800 --> 00:22:55.990
And there are so many fascinating things.

00:22:55.990 --> 00:22:56.980
I have so many questions,

00:22:56.980 --> 00:23:00.250
but I do want to ask one
question about the culture of AI,

00:23:00.250 --> 00:23:01.760
because it does seem to be a community

00:23:01.760 --> 00:23:04.000
where at least as an outsider,

00:23:04.000 --> 00:23:06.180
where it seems like there's
very little consensus

00:23:06.180 --> 00:23:07.330
about what the terms

00:23:07.330 --> 00:23:09.390
and the operational definitions even mean.

00:23:09.390 --> 00:23:12.240
And there seems to be a lot
of splitting happening now

00:23:12.240 --> 00:23:14.930
of not just supervised
and unsupervised learning,

00:23:14.930 --> 00:23:18.110
but these sort of intermediate conditions

00:23:18.110 --> 00:23:20.820
where machines are autonomous,

00:23:20.820 --> 00:23:22.150
but then go back for more instruction

00:23:22.150 --> 00:23:24.050
like kids go home from
college during the summer

00:23:24.050 --> 00:23:25.260
and get a little,

00:23:25.260 --> 00:23:26.270
moms still feeds them

00:23:26.270 --> 00:23:28.770
then eventually they leave
the nest kind of thing.

00:23:29.800 --> 00:23:32.670
Is there something in
particular about engineers,

00:23:32.670 --> 00:23:35.860
or about people in this
realm of engineering

00:23:35.860 --> 00:23:39.120
that you think lends
itself to disagreement?

00:23:39.120 --> 00:23:39.963
- Yeah, I think,

00:23:41.270 --> 00:23:43.480
so, first of all, the
more specific you get,

00:23:43.480 --> 00:23:44.680
the less disagreement there is.

00:23:44.680 --> 00:23:45.960
So there's lot of disagreement

00:23:45.960 --> 00:23:47.900
about what is artificial intelligence,

00:23:47.900 --> 00:23:50.670
but there's less disagreement
about what is machine learning

00:23:50.670 --> 00:23:52.730
and even less when you
talk about active learning

00:23:52.730 --> 00:23:56.630
or machine teaching or
self-supervised learning.

00:23:56.630 --> 00:23:57.550
And then when you get

00:23:57.550 --> 00:24:00.670
into like NLP language
models or transformers,

00:24:00.670 --> 00:24:03.820
when you get into specific
neural network architectures,

00:24:03.820 --> 00:24:05.670
there's less and less
and less disagreement

00:24:05.670 --> 00:24:06.710
about those terms.

00:24:06.710 --> 00:24:08.100
So you might be hearing the disagreement

00:24:08.100 --> 00:24:09.370
from the high-level terms,

00:24:09.370 --> 00:24:12.110
and that has to do with
the fact that engineering,

00:24:12.110 --> 00:24:15.240
especially when you're talking
about intelligence systems

00:24:15.240 --> 00:24:20.240
is a little bit of an art and a science.

00:24:20.870 --> 00:24:25.360
So the art part is the thing
that creates disagreements,

00:24:25.360 --> 00:24:28.660
because then you start
having disagreements

00:24:28.660 --> 00:24:33.660
about how easy or difficult
the particular problem is.

00:24:33.910 --> 00:24:34.743
For example,

00:24:34.743 --> 00:24:37.610
a lot of people disagree with Elon

00:24:37.610 --> 00:24:41.140
how difficult the problem
of autonomous driving is.

00:24:41.140 --> 00:24:43.160
And so, but nobody knows.

00:24:43.160 --> 00:24:44.770
So there's a lot of disagreement about,

00:24:44.770 --> 00:24:47.200
what are the limits of these techniques?

00:24:47.200 --> 00:24:48.490
And through that,

00:24:48.490 --> 00:24:52.160
the terminology also contains
within it the disagreements.

00:24:54.000 --> 00:24:54.833
But overall,

00:24:54.833 --> 00:24:56.810
I think it's also a young science

00:24:56.810 --> 00:24:58.860
that also has to do with that.

00:24:58.860 --> 00:25:01.230
So like it's not just engineering,

00:25:01.230 --> 00:25:03.700
it's that artificial intelligence truly

00:25:03.700 --> 00:25:05.520
is a large-scale discipline,

00:25:05.520 --> 00:25:08.140
where it's thousands, tens of thousands,

00:25:08.140 --> 00:25:10.070
hundreds of thousands
of people working on it,

00:25:10.070 --> 00:25:13.870
huge amounts of money being
made as a very recent thing.

00:25:13.870 --> 00:25:16.490
So we're trying to figure out those terms.

00:25:16.490 --> 00:25:17.323
And, of course,

00:25:17.323 --> 00:25:20.993
there's egos and personalities
and a lot of fame to be made.

00:25:22.650 --> 00:25:25.770
Like the term deep learning, for example,

00:25:25.770 --> 00:25:27.020
neural networks have been around

00:25:27.020 --> 00:25:28.657
for many, many decades since the '60s,

00:25:28.657 --> 00:25:30.880
you can argue since the '40s.

00:25:30.880 --> 00:25:33.490
So there was a rebranding
of neural networks

00:25:33.490 --> 00:25:35.450
into the word, deep learning,

00:25:35.450 --> 00:25:36.604
term, deep learning,

00:25:36.604 --> 00:25:40.940
that was part of the
re-invigoration of the field,

00:25:40.940 --> 00:25:42.720
but it's really the same exact thing.

00:25:42.720 --> 00:25:43.670
- I didn't know that.

00:25:43.670 --> 00:25:46.060
I mean, I grew up in
the age of neuroscience

00:25:46.060 --> 00:25:49.090
when neural networks were discussed,

00:25:49.090 --> 00:25:51.420
computational neuroscience
and theoretical neuroscience,

00:25:51.420 --> 00:25:53.110
they had their own journals.

00:25:53.110 --> 00:25:55.060
It wasn't actually
taken terribly seriously

00:25:55.060 --> 00:25:57.260
by experimentalists until a few years ago.

00:25:57.260 --> 00:26:00.720
I would say about five to seven years ago.

00:26:00.720 --> 00:26:03.540
Excellent theoretical
neuroscientist like Larry Abbott

00:26:03.540 --> 00:26:06.350
and other colleagues,

00:26:06.350 --> 00:26:07.363
certainly at Stanford as well

00:26:07.363 --> 00:26:08.830
that people started paying attention

00:26:08.830 --> 00:26:10.360
to computational methods.

00:26:10.360 --> 00:26:11.193
But these terms,

00:26:11.193 --> 00:26:13.250
neural networks, computational methods,

00:26:13.250 --> 00:26:15.180
I actually didn't know
that neural network works

00:26:15.180 --> 00:26:18.570
in deep learning where
those have now become

00:26:18.570 --> 00:26:19.461
kind of synonymous.

00:26:19.461 --> 00:26:22.740
- No, they're always the same thing.

00:26:22.740 --> 00:26:23.573
- Interesting.

00:26:23.573 --> 00:26:24.406
It was, so.

00:26:24.406 --> 00:26:25.790
- I'm a neuroscientist
and I didn't know that.

00:26:25.790 --> 00:26:27.730
- So, well, because neural networks

00:26:27.730 --> 00:26:28.970
probably means something else

00:26:28.970 --> 00:26:30.230
and neural science not something else,

00:26:30.230 --> 00:26:32.640
but a little different flavor
depending on the field.

00:26:32.640 --> 00:26:34.120
And that's fascinating too,

00:26:34.120 --> 00:26:37.100
because neuroscience and AI people

00:26:37.100 --> 00:26:40.392
have started working together
and dancing a lot more

00:26:40.392 --> 00:26:41.600
in the recent,

00:26:41.600 --> 00:26:43.060
I would say probably decade.

00:26:43.060 --> 00:26:45.060
- Oh, machines are going into the brain.

00:26:45.992 --> 00:26:47.650
I have a couple of questions,

00:26:47.650 --> 00:26:49.840
but one thing that I'm sort of fixated on

00:26:49.840 --> 00:26:51.880
that I find incredibly interesting

00:26:51.880 --> 00:26:55.770
is this example you gave of playing a game

00:26:55.770 --> 00:26:59.460
with a mutated version of
yourself as a competitor.

00:26:59.460 --> 00:27:00.293
- Yeah.

00:27:00.293 --> 00:27:02.360
- I find that incredibly interesting

00:27:02.360 --> 00:27:05.250
as a kind of a parallel or a mirror

00:27:05.250 --> 00:27:07.640
for what happens when we
try and learn as humans,

00:27:07.640 --> 00:27:10.030
which is we generate repetitions

00:27:10.030 --> 00:27:11.960
of whatever it is we're trying to learn,

00:27:11.960 --> 00:27:13.280
and we make errors.

00:27:13.280 --> 00:27:15.060
Occasionally we succeed.

00:27:15.060 --> 00:27:16.700
In a simple example, for instance,

00:27:16.700 --> 00:27:18.800
of trying to throw bulls
eyes on a dartboard.

00:27:18.800 --> 00:27:19.633
- Yeah.

00:27:19.633 --> 00:27:20.510
- I'm going to have
errors, errors, errors.

00:27:20.510 --> 00:27:21.730
I'll probably miss the dartboard.

00:27:21.730 --> 00:27:23.440
And maybe occasionally, hit a bullseye.

00:27:23.440 --> 00:27:25.946
And I don't know exactly
what I just did, right?

00:27:25.946 --> 00:27:28.760
But then let's say I was playing darts

00:27:28.760 --> 00:27:30.370
against a version of myself

00:27:30.370 --> 00:27:32.480
where I was wearing a visual prism,

00:27:32.480 --> 00:27:34.863
like my visual, I had a visual defect,

00:27:36.650 --> 00:27:38.980
you learn certain things
in that mode as well.

00:27:38.980 --> 00:27:42.920
You're saying that a machine
can sort of mutate itself,

00:27:42.920 --> 00:27:45.130
does the mutation always
cause a deficiency

00:27:45.130 --> 00:27:46.560
that it needs to overcome?

00:27:46.560 --> 00:27:48.010
Because of mutations in biology

00:27:48.010 --> 00:27:49.630
sometimes give us super powers, right?

00:27:49.630 --> 00:27:51.100
Occasionally, you'll get somebody

00:27:51.100 --> 00:27:52.750
who has better than 2020 vision,

00:27:52.750 --> 00:27:56.410
and they can see better than
99.9% of people out there.

00:27:56.410 --> 00:27:59.170
So, when you talk about
a machine playing a game

00:27:59.170 --> 00:28:01.370
against a mutated version of itself,

00:28:01.370 --> 00:28:04.266
is the mutation always say what
we call a negative mutation,

00:28:04.266 --> 00:28:07.680
or an adaptive or a maladaptive mutation?

00:28:07.680 --> 00:28:09.793
- No, you don't know until you get,

00:28:11.010 --> 00:28:12.060
so, you mutate first

00:28:12.060 --> 00:28:14.500
and then figure out and they
compete against each other.

00:28:14.500 --> 00:28:15.830
- So, you're evolving,

00:28:15.830 --> 00:28:18.430
the machine gets to evolve
itself in real time.

00:28:18.430 --> 00:28:19.263
- Yeah.

00:28:19.263 --> 00:28:20.860
And I think of it,

00:28:20.860 --> 00:28:21.860
which would be exciting

00:28:21.860 --> 00:28:23.640
if you could actually do with humans.

00:28:23.640 --> 00:28:25.210
It's not just.

00:28:25.210 --> 00:28:30.210
So, usually you freeze
a version of the system.

00:28:30.370 --> 00:28:33.960
So, really you take on Andrew of yesterday

00:28:33.960 --> 00:28:35.773
and you make 10 clones of them.

00:28:36.640 --> 00:28:39.020
And then maybe you mutate, maybe not.

00:28:39.020 --> 00:28:41.130
And then you do a bunch of competitions

00:28:41.130 --> 00:28:44.120
of the Andrew of today,
like you fight to the death,

00:28:44.120 --> 00:28:45.690
and who wins last.

00:28:45.690 --> 00:28:46.610
So, I love that idea

00:28:46.610 --> 00:28:49.040
of like creating a bunch
of clones of myself

00:28:49.040 --> 00:28:52.430
from like from each of
the day for the past year,

00:28:52.430 --> 00:28:54.580
and just seeing who's going to be better

00:28:54.580 --> 00:28:56.550
at like podcasting or science,

00:28:56.550 --> 00:29:00.230
or picking up chicks at
a bar or I don't know,

00:29:00.230 --> 00:29:02.260
or competing in Jujitsu.

00:29:02.260 --> 00:29:03.170
That's the one way to do it,

00:29:03.170 --> 00:29:06.400
I mean, a lot of Lexes would
have to die for that process,

00:29:06.400 --> 00:29:07.930
but that's essentially what happens,

00:29:07.930 --> 00:29:09.480
is in reinforcement learning

00:29:09.480 --> 00:29:11.014
through the self-play mechanisms,

00:29:11.014 --> 00:29:14.370
it's a graveyard of systems
that didn't do that well.

00:29:14.370 --> 00:29:19.370
And the surviving, the good ones survive.

00:29:19.800 --> 00:29:22.770
- Do you think that, I mean,
Darwin's Theory of Evolution

00:29:23.740 --> 00:29:26.340
might have worked in
some sense in this way,

00:29:26.340 --> 00:29:27.770
but at the population level.

00:29:27.770 --> 00:29:29.600
I mean, you get a bunch of birds
with different shaped beaks

00:29:29.600 --> 00:29:31.010
and some birds have the shaped beak

00:29:31.010 --> 00:29:32.320
that allows them to get the seeds.

00:29:32.320 --> 00:29:34.920
I mean, is a trivially simple example

00:29:34.920 --> 00:29:36.220
of Darwinian in evolution,

00:29:36.220 --> 00:29:40.850
but I think it's correct even
though it's not exhaustive.

00:29:40.850 --> 00:29:42.190
Is what you're referring to?

00:29:42.190 --> 00:29:44.130
You essentially that normally this is done

00:29:44.130 --> 00:29:45.600
between members of a different species,

00:29:45.600 --> 00:29:48.030
lots of different members of
species have different traits

00:29:48.030 --> 00:29:49.005
and some get selected for,

00:29:49.005 --> 00:29:52.620
but you could actually create
multiple versions of yourself

00:29:52.620 --> 00:29:53.920
with different traits.

00:29:53.920 --> 00:29:56.500
- So, with, I should
probably have said this,

00:29:56.500 --> 00:29:59.963
but perhaps it's implied
with machine learning,

00:29:59.963 --> 00:30:02.520
with reinforcement learning
through these processes.

00:30:02.520 --> 00:30:03.885
One of the big requirements,

00:30:03.885 --> 00:30:06.540
is to have an objective
function, a loss function,

00:30:06.540 --> 00:30:07.840
a utility function,

00:30:07.840 --> 00:30:09.669
those are all different
terms for the same thing,

00:30:09.669 --> 00:30:14.669
is there's a like any equation
that says what's good,

00:30:15.120 --> 00:30:17.550
and then you're trying to
optimize that equation.

00:30:17.550 --> 00:30:20.602
So, there's a clear
goal for these systems.

00:30:20.602 --> 00:30:23.960
- Because it's a game, like
with chess, there's a goal.

00:30:23.960 --> 00:30:25.320
- But for anything.

00:30:25.320 --> 00:30:27.690
Anything you want machine
learning to solve,

00:30:27.690 --> 00:30:29.970
there needs to be an objective function.

00:30:29.970 --> 00:30:32.307
In machine learning, it's
usually called Loss Function,

00:30:32.307 --> 00:30:34.380
that you're optimizing.

00:30:34.380 --> 00:30:36.513
The interesting thing about evolution,

00:30:37.540 --> 00:30:38.740
it's complicated of course,

00:30:38.740 --> 00:30:41.740
but the goal also seems to be evolving.

00:30:41.740 --> 00:30:44.050
Like it's a, I guess,
adaptation to the environment,

00:30:44.050 --> 00:30:44.990
is the goal,

00:30:44.990 --> 00:30:48.320
but it's unclear that you
can convert that always.

00:30:48.320 --> 00:30:52.180
It's like survival of the fittest.

00:30:52.180 --> 00:30:53.890
It's unclear what the fittest is.

00:30:53.890 --> 00:30:55.370
In machine learning,

00:30:55.370 --> 00:30:56.850
the starting point,

00:30:56.850 --> 00:31:00.490
and this is like what
human ingenuity provides,

00:31:00.490 --> 00:31:04.450
is that fitness function of
what's good and what's bad,

00:31:04.450 --> 00:31:08.380
which it lets you know which
of the systems is going to win.

00:31:08.380 --> 00:31:10.579
So, you need to have a equation like that.

00:31:10.579 --> 00:31:12.890
One of the fascinating
things about humans,

00:31:12.890 --> 00:31:17.170
is we figure out objective
functions for ourselves.

00:31:17.170 --> 00:31:20.540
Like it's the meaning of life,

00:31:20.540 --> 00:31:22.990
like why the hell are we here?

00:31:22.990 --> 00:31:25.110
And a machine currently

00:31:25.110 --> 00:31:29.270
has to have a hard-coded
statement about why.

00:31:29.270 --> 00:31:30.530
- It has to have a meaning of-

00:31:30.530 --> 00:31:31.363
- Yeah.

00:31:31.363 --> 00:31:33.280
- Artificial intelligence-based life.

00:31:33.280 --> 00:31:34.113
- Right.

00:31:34.113 --> 00:31:34.946
It can't.

00:31:34.946 --> 00:31:37.630
So, like there's a lot of
interesting explorations

00:31:37.630 --> 00:31:42.440
about that function being
more about curiosity,

00:31:42.440 --> 00:31:45.270
about learning new things
and all that kind of stuff,

00:31:45.270 --> 00:31:46.720
but it's still hard coded.

00:31:46.720 --> 00:31:49.620
If you want a machine to be
able to be good at stuff,

00:31:49.620 --> 00:31:53.480
it has to be given very clear statements

00:31:53.480 --> 00:31:56.110
of what good at stuff means.

00:31:56.110 --> 00:31:58.400
That's one of the challenges
of artificial intelligence,

00:31:58.400 --> 00:32:01.630
is you have to formalize the,

00:32:01.630 --> 00:32:03.897
in order to solve a problem,
you have to formalize it

00:32:03.897 --> 00:32:06.190
and you have to provide

00:32:06.190 --> 00:32:08.290
both like the full sensory information,

00:32:08.290 --> 00:32:10.667
you have to be very clear
about what is the data

00:32:10.667 --> 00:32:12.208
that's being collected,

00:32:12.208 --> 00:32:15.900
and you have to also be clear
about the objective function.

00:32:15.900 --> 00:32:18.880
What is the goal that
you're trying to reach?

00:32:18.880 --> 00:32:20.750
And that's a very difficult thing

00:32:20.750 --> 00:32:22.140
for artificial intelligence.

00:32:22.140 --> 00:32:23.990
- I love that you mentioned curiosity,

00:32:23.990 --> 00:32:26.980
I am sure this definition
falls short in many ways,

00:32:26.980 --> 00:32:28.470
but I define curiosity

00:32:28.470 --> 00:32:33.190
as a strong interest in knowing something,

00:32:33.190 --> 00:32:35.598
but without an attachment to the outcome.

00:32:35.598 --> 00:32:39.360
It's sort of a, it could
be a random search,

00:32:39.360 --> 00:32:42.100
but there's not really
an emotional attachment,

00:32:42.100 --> 00:32:43.370
it's really just a desire

00:32:43.370 --> 00:32:45.570
to discover and unveil what's there

00:32:45.570 --> 00:32:48.910
without hoping it's a
gold coin under a rock,

00:32:48.910 --> 00:32:50.269
you're just looking under rocks.

00:32:50.269 --> 00:32:52.390
Is that more or less how the,

00:32:52.390 --> 00:32:53.910
within machine learning,

00:32:53.910 --> 00:32:55.320
it sounds like there are elements

00:32:55.320 --> 00:32:58.600
of reward prediction and rewards.

00:32:58.600 --> 00:33:01.500
The machine has to know when
it's done the right thing.

00:33:01.500 --> 00:33:05.320
So, can you make machines
that are curious,

00:33:05.320 --> 00:33:08.050
or are the sorts of machines
that you are describing,

00:33:08.050 --> 00:33:09.403
curious by design?

00:33:10.250 --> 00:33:15.250
- Yeah, curiosity is a kind
of a symptom, not the goal.

00:33:16.310 --> 00:33:18.200
So, what happens,

00:33:18.200 --> 00:33:22.330
is one of the big trade-offs
in reinforcement learning,

00:33:22.330 --> 00:33:25.195
is this exploration versus exploitation.

00:33:25.195 --> 00:33:29.640
So, when you know very little,
it pays off to explore a lot,

00:33:29.640 --> 00:33:32.470
even suboptimal, like even trajectories

00:33:32.470 --> 00:33:34.670
that seem like they're not
going to lead anywhere,

00:33:34.670 --> 00:33:36.210
that's called exploration.

00:33:36.210 --> 00:33:38.247
The smarter and smarter
and smarter you get,

00:33:38.247 --> 00:33:41.860
the more emphasis you put on exploitation,

00:33:41.860 --> 00:33:45.369
meaning you take the best
solution, you take the best path.

00:33:45.369 --> 00:33:47.250
Now, through that process,

00:33:47.250 --> 00:33:52.250
the exploration can look
like curiosity by us humans,

00:33:52.567 --> 00:33:55.710
but it's really just trying to
get out of the local optimal,

00:33:55.710 --> 00:33:57.410
the thing it's already discovered.

00:33:58.780 --> 00:34:00.200
From an AI perspective,

00:34:00.200 --> 00:34:04.410
it's always looking to optimize
the objective function,

00:34:04.410 --> 00:34:08.190
it derives, and we can
talk about the slot more,

00:34:08.190 --> 00:34:11.550
but in terms of the tools
of machine learning today,

00:34:11.550 --> 00:34:15.990
it derives no pleasure
from just the curiosity

00:34:15.990 --> 00:34:19.522
of like, I don't know, discovery.

00:34:19.522 --> 00:34:20.605
- So, there's no dopamine

00:34:20.605 --> 00:34:21.860
for machine learning.
- There's no dopamine.

00:34:21.860 --> 00:34:24.030
- There's no reward, system chemical,

00:34:24.030 --> 00:34:26.930
or I guess electronic-reward system.

00:34:26.930 --> 00:34:30.410
- That said, if you look at
machine learning literature

00:34:30.410 --> 00:34:32.100
and reinforcement learning literature,

00:34:32.100 --> 00:34:33.010
that will use,

00:34:33.010 --> 00:34:35.780
like deep mind, we use
terms like dopamine,

00:34:35.780 --> 00:34:38.860
we're constantly trying
to use the human brain

00:34:38.860 --> 00:34:41.870
to inspire totally new
solutions to these problems.

00:34:41.870 --> 00:34:42.750
So, they'll think like,

00:34:42.750 --> 00:34:45.000
how does dopamine function
in the human brain,

00:34:45.000 --> 00:34:49.160
and how can it lead to
more interesting ways

00:34:49.160 --> 00:34:51.520
to discover optimal solutions?

00:34:51.520 --> 00:34:53.233
But ultimately currently,

00:34:54.140 --> 00:34:57.500
there has to be a formal
objective function.

00:34:57.500 --> 00:34:58.333
Now, you could argue

00:34:58.333 --> 00:35:00.510
the humans also has a set
of objective functions

00:35:00.510 --> 00:35:04.550
we try and optimize, we're just
not able to introspect them.

00:35:04.550 --> 00:35:07.930
- Yeah, we don't actually
know what we're looking for

00:35:07.930 --> 00:35:09.350
and seeking and doing.

00:35:09.350 --> 00:35:11.050
- Well, like Lisa Feldman Barrett

00:35:11.050 --> 00:35:13.560
who we spoken with at least
on Instagram, I hope you-

00:35:13.560 --> 00:35:14.810
- I met her through you, yeah.

00:35:14.810 --> 00:35:17.580
- Yeah, I hope you actually
have are on this podcast.

00:35:17.580 --> 00:35:18.850
- Yes, she's terrific.

00:35:18.850 --> 00:35:20.713
- So, she has a very,

00:35:22.482 --> 00:35:25.923
it has to do with homeostasis like that.

00:35:26.820 --> 00:35:28.743
Basically, there's a very
dumb objective function

00:35:28.743 --> 00:35:30.890
that the brain is trying to optimize,

00:35:30.890 --> 00:35:32.970
like to keep like body
temperature the same.

00:35:32.970 --> 00:35:34.350
Like there's a very dom

00:35:34.350 --> 00:35:36.480
kind of optimization function happening.

00:35:36.480 --> 00:35:39.580
And then what we humans do
with our fancy consciousness

00:35:39.580 --> 00:35:42.045
and cognitive abilities, is
we tell stories to ourselves

00:35:42.045 --> 00:35:44.080
so we can have nice podcasts,

00:35:44.080 --> 00:35:48.110
but really it's the brain
trying to maintain a,

00:35:48.110 --> 00:35:50.760
just like healthy state, I guess.

00:35:50.760 --> 00:35:51.910
That's fascinating.

00:35:51.910 --> 00:35:55.890
I also see the human brain,

00:35:55.890 --> 00:35:58.990
and I hope artificial
intelligence systems,

00:35:58.990 --> 00:36:03.990
as not just systems that solve
problems, or optimize a goal,

00:36:04.210 --> 00:36:06.300
but are also storytellers.

00:36:06.300 --> 00:36:08.860
I think there's a power
to telling stories.

00:36:08.860 --> 00:36:11.374
We tell stories to each other,
that's what communication is.

00:36:11.374 --> 00:36:16.374
Like when you're alone, that's
when you solve problems,

00:36:16.720 --> 00:36:19.090
that's when it makes sense to
talk about solving problems.

00:36:19.090 --> 00:36:20.860
But when you're a community,

00:36:20.860 --> 00:36:24.033
the capability to
communicate, tell stories,

00:36:25.470 --> 00:36:28.240
share ideas in such a way
that those ideas are stable

00:36:28.240 --> 00:36:30.030
over a long period of time,

00:36:30.030 --> 00:36:33.340
that's like, that's being
a charismatic storyteller.

00:36:33.340 --> 00:36:35.900
And I think both humans
are very good at this.

00:36:35.900 --> 00:36:40.260
Arguably, I would argue
that's why we are who we are,

00:36:40.260 --> 00:36:41.993
is we're great storytellers.

00:36:41.993 --> 00:36:44.820
And then AI I hope will also become that.

00:36:44.820 --> 00:36:47.480
So, it's not just about
being able to solve problems

00:36:47.480 --> 00:36:49.060
with a clear objective function,

00:36:49.060 --> 00:36:51.950
it's afterwards, be able
to tell like a way better,

00:36:51.950 --> 00:36:54.820
like make up a way better story
about why you did something,

00:36:54.820 --> 00:36:55.800
or why you failed.

00:36:55.800 --> 00:36:59.880
- So, you think that robots or,
and/or machines of some sort

00:36:59.880 --> 00:37:02.370
are going to start telling human stories?

00:37:02.370 --> 00:37:03.480
- Well, definitely.

00:37:03.480 --> 00:37:07.380
So, the technical field for
that is called Explainable AI,

00:37:07.380 --> 00:37:09.350
Explainable Artificial Intelligence,

00:37:09.350 --> 00:37:13.877
is trying to figure out
how you get the AI system

00:37:13.877 --> 00:37:17.560
to explain to us humans
why the hell it failed,

00:37:17.560 --> 00:37:19.075
or why it succeeded,

00:37:19.075 --> 00:37:22.360
or there's a lot of different
sort of versions of this,

00:37:22.360 --> 00:37:26.350
or to visualize how it
understands the world.

00:37:26.350 --> 00:37:28.140
That's a really difficult problem,

00:37:28.140 --> 00:37:29.670
especially with neural networks

00:37:29.670 --> 00:37:32.824
that are famously opaque,

00:37:32.824 --> 00:37:36.360
that we don't understand in many cases,

00:37:36.360 --> 00:37:40.510
why a particular neural network
does what it does so well,

00:37:40.510 --> 00:37:43.730
and to try to figure out
where it's going to fail,

00:37:43.730 --> 00:37:46.280
that requires the AI to explain itself.

00:37:46.280 --> 00:37:48.373
There's a huge amount of money,

00:37:49.570 --> 00:37:52.390
like there's a huge
amount of money in this,

00:37:52.390 --> 00:37:54.600
especially from government
funding and so on.

00:37:54.600 --> 00:37:59.149
Because if you want to deploy
AI systems in the real world,

00:37:59.149 --> 00:38:02.900
we humans at least, want
to ask it a question like,

00:38:02.900 --> 00:38:04.300
why the hell did you do that?

00:38:04.300 --> 00:38:06.700
Like in a dark way,

00:38:06.700 --> 00:38:09.170
why did you just kill that person, right?

00:38:09.170 --> 00:38:10.660
Like if a car ran over a person,

00:38:10.660 --> 00:38:13.050
we want to understand why that happened.

00:38:13.050 --> 00:38:17.930
And now again, we're sometimes
very unfair to AI systems

00:38:17.930 --> 00:38:21.920
because we humans can often
not explain why very well.

00:38:21.920 --> 00:38:25.600
But that's the field of Explainable AI

00:38:25.600 --> 00:38:28.210
that people are very interested in

00:38:28.210 --> 00:38:31.540
because the more and more
we rely on AI systems,

00:38:31.540 --> 00:38:34.060
like the Twitter recommender system,

00:38:34.060 --> 00:38:39.060
that AI algorithm that's, I
would say impacting elections,

00:38:39.190 --> 00:38:42.020
perhaps starting wars, or
at least military conflict,

00:38:42.020 --> 00:38:46.050
that algorithm, we want
to ask that algorithm,

00:38:46.050 --> 00:38:48.530
first of all, do you know
what the hell you're doing?

00:38:48.530 --> 00:38:52.770
Do you understand the society-level
effects you're having?

00:38:52.770 --> 00:38:55.860
And can you explain the
possible other trajectories?

00:38:55.860 --> 00:38:58.350
Like we would have that kind
of conversation with a human,

00:38:58.350 --> 00:39:00.070
we want to be able to do that with an AI.

00:39:00.070 --> 00:39:02.060
And in my own personal level,

00:39:02.060 --> 00:39:05.480
I think it would be nice
to talk to AI systems

00:39:05.480 --> 00:39:10.073
for stupid stuff, like
robots when they fail to-

00:39:11.650 --> 00:39:12.940
- Why'd you fall down the stairs?

00:39:12.940 --> 00:39:13.773
- Yeah.

00:39:13.773 --> 00:39:15.910
But not an engineering question,

00:39:15.910 --> 00:39:18.842
but almost like an endearing question,

00:39:18.842 --> 00:39:21.650
like I'm looking for,

00:39:21.650 --> 00:39:25.040
if I fell and you and I were hanging out,

00:39:25.040 --> 00:39:28.070
I don't think you need an explanation

00:39:28.070 --> 00:39:29.890
exactly what were the dynamics,

00:39:29.890 --> 00:39:32.810
like what was the under
actuated system problem here?

00:39:32.810 --> 00:39:35.650
Like what was the texture of the floor?

00:39:35.650 --> 00:39:36.483
Or so on.

00:39:36.483 --> 00:39:37.427
Or like, what was the-

00:39:37.427 --> 00:39:39.060
- No, I want to know what you're thinking.

00:39:39.060 --> 00:39:41.250
- That, or you might joke about like,

00:39:41.250 --> 00:39:43.140
you're drunk again, go home, or something,

00:39:43.140 --> 00:39:46.990
like there could be humor in
it, that's an opportunity.

00:39:46.990 --> 00:39:50.662
Like storytelling, isn't just
explanation of what happened,

00:39:50.662 --> 00:39:54.440
it's something that makes people laugh,

00:39:54.440 --> 00:39:57.510
it makes people fall in
love, it makes people dream,

00:39:57.510 --> 00:39:59.010
and understand things

00:39:59.010 --> 00:40:02.020
in a way that poetry makes
people understand things

00:40:02.020 --> 00:40:04.680
as opposed to a rigorous log

00:40:04.680 --> 00:40:09.590
of where every sensor was,
where every actuator was.

00:40:09.590 --> 00:40:11.510
- I mean, I find this incredible

00:40:11.510 --> 00:40:13.910
because one of the hallmarks

00:40:13.910 --> 00:40:16.713
of severe autism spectrum disorders is,

00:40:17.670 --> 00:40:21.900
a report of experience
from the autistic person

00:40:21.900 --> 00:40:25.350
that is very much a
catalog of action steps.

00:40:25.350 --> 00:40:26.420
It's like, how do you feel today?

00:40:26.420 --> 00:40:28.010
And they'll say, well,
I got up and I did this,

00:40:28.010 --> 00:40:29.130
and then I did this, and I did this.

00:40:29.130 --> 00:40:31.720
And it's not at all the way that a person

00:40:31.720 --> 00:40:35.750
who doesn't have autism
spectrum disorder would respond.

00:40:35.750 --> 00:40:38.800
And the way you describe these machines

00:40:38.800 --> 00:40:42.450
has so much humanism,

00:40:42.450 --> 00:40:45.460
or so much of a human
and biological element,

00:40:45.460 --> 00:40:48.010
but I realized that we were
talking about machines.

00:40:48.926 --> 00:40:51.720
I want to make sure that I understand

00:40:51.720 --> 00:40:56.720
if there's a distinction
between a machine that learns,

00:40:57.900 --> 00:41:00.840
a machine with artificial
intelligence and a robot.

00:41:00.840 --> 00:41:03.890
Like at what point does
a machine become a robot?

00:41:03.890 --> 00:41:06.500
So, if I have a ballpoint pen,

00:41:06.500 --> 00:41:08.700
I'm assuming I wouldn't call that a robot,

00:41:08.700 --> 00:41:12.440
but if my ballpoint pen can come to me

00:41:12.440 --> 00:41:15.360
when I moved to the
opposite side of the table,

00:41:15.360 --> 00:41:17.970
if it moves by whatever mechanism,

00:41:17.970 --> 00:41:20.700
at that point, does it become a robot?

00:41:20.700 --> 00:41:23.460
- Okay, there's 1 million
ways to explore this question.

00:41:23.460 --> 00:41:25.130
It's a fascinating one.

00:41:25.130 --> 00:41:28.143
So, first of all, there's
a question of what is life?

00:41:29.260 --> 00:41:32.500
Like how do you know something
as a living form and not?

00:41:32.500 --> 00:41:35.500
And it's to the question
of when does sort of a,

00:41:35.500 --> 00:41:39.383
maybe a cold computational
system becomes a,

00:41:40.237 --> 00:41:42.720
or already loading these
words with a lot of meaning,

00:41:42.720 --> 00:41:43.853
robot and machine,

00:41:46.240 --> 00:41:50.690
So, one, I think movement is important,

00:41:50.690 --> 00:41:52.370
but that's a kind of a boring idea

00:41:52.370 --> 00:41:54.227
that a robot is just a machine

00:41:54.227 --> 00:41:56.650
that's able to act in the world.

00:41:56.650 --> 00:41:58.860
So, one artificial intelligence

00:41:58.860 --> 00:42:01.840
could be both just the thinking thing,

00:42:01.840 --> 00:42:04.080
which I think is what machine learning is,

00:42:04.080 --> 00:42:05.760
and also the acting thing,

00:42:05.760 --> 00:42:07.930
which is what we usually
think about robots.

00:42:07.930 --> 00:42:09.757
So, robots are the things
that have a perception system

00:42:09.757 --> 00:42:11.640
that's able to take in the world

00:42:11.640 --> 00:42:13.190
however you define the world,

00:42:13.190 --> 00:42:14.640
is able to think and learn

00:42:14.640 --> 00:42:16.750
and do whatever the hell it does inside,

00:42:16.750 --> 00:42:18.730
and then act on the world.

00:42:18.730 --> 00:42:19.563
So, that's the difference

00:42:19.563 --> 00:42:23.260
between maybe an AI system
learning machine and a robot,

00:42:23.260 --> 00:42:24.300
it's something that's able,

00:42:24.300 --> 00:42:27.260
a robot is something that's
able to perceive the world

00:42:27.260 --> 00:42:28.210
and act in the world.

00:42:28.210 --> 00:42:31.120
- So, it could be through
language or sound,

00:42:31.120 --> 00:42:32.690
or it could be through movement or both.

00:42:32.690 --> 00:42:33.734
- Yeah.

00:42:33.734 --> 00:42:36.120
And I think it could also
be in the digital space

00:42:36.120 --> 00:42:39.070
as long as there's a aspect of entity

00:42:39.070 --> 00:42:40.954
that's inside the machine

00:42:40.954 --> 00:42:44.240
and a world that's outside the machine.

00:42:44.240 --> 00:42:46.480
And there's a sense in which the machine

00:42:46.480 --> 00:42:49.370
is sensing that world and acting in it.

00:42:49.370 --> 00:42:50.203
- So, we could,

00:42:50.203 --> 00:42:52.640
for instance, there could
be a version of a robot,

00:42:52.640 --> 00:42:55.440
according to the definition
that I think you're providing,

00:42:55.440 --> 00:42:58.280
where the robot, where
I go to sleep at night

00:42:58.280 --> 00:43:01.470
and this robot goes and
forges for information

00:43:01.470 --> 00:43:04.830
that it thinks I want to
see loaded onto my desktop

00:43:04.830 --> 00:43:05.663
in the morning.

00:43:05.663 --> 00:43:07.040
There was no movement of that machine,

00:43:07.040 --> 00:43:07.873
there was no language,

00:43:07.873 --> 00:43:11.170
but it essentially, has
movement in cyberspace.

00:43:11.170 --> 00:43:15.873
- Yeah, there's a distinction
that I think is important

00:43:18.430 --> 00:43:23.430
in that there's an element
of it being an entity,

00:43:24.210 --> 00:43:26.660
whether it's in the digital
or the physical space.

00:43:26.660 --> 00:43:30.043
So, when you have something
like Alexa in your home,

00:43:32.310 --> 00:43:36.760
most of the speech recognition,
most of what Alexa is doing,

00:43:36.760 --> 00:43:39.183
is constantly being sent
back to the mothership.

00:43:42.090 --> 00:43:46.990
When Alexa is there on its
own, that's to me, a robot,

00:43:46.990 --> 00:43:49.094
when it's there
interacting with the world.

00:43:49.094 --> 00:43:54.094
When it's simply a finger
of the main mothership,

00:43:54.374 --> 00:43:56.700
then the Alexa is not a robot,

00:43:56.700 --> 00:43:58.910
then it's just an interaction device,

00:43:58.910 --> 00:44:02.400
then may be the main Amazon Alexa AI,

00:44:02.400 --> 00:44:04.830
big, big system is the robot.

00:44:04.830 --> 00:44:08.890
So, that's important because
there's some element,

00:44:08.890 --> 00:44:12.600
to us humans, I think, where
we want there to be an entity,

00:44:12.600 --> 00:44:14.780
whether in the digital
or the physical space,

00:44:14.780 --> 00:44:16.780
that's where ideas of
consciousness come in

00:44:16.780 --> 00:44:18.610
and all those kinds of things

00:44:18.610 --> 00:44:20.753
that we project our understanding

00:44:20.753 --> 00:44:23.153
of what it means to be a being.

00:44:24.300 --> 00:44:27.050
And so, to take that further,

00:44:27.050 --> 00:44:29.043
when does a machine become a robot,

00:44:31.400 --> 00:44:35.260
I think there's a special moment.

00:44:35.260 --> 00:44:37.757
There's a special moment
in a person's life

00:44:37.757 --> 00:44:40.803
and in a robot's life
where it surprises you.

00:44:41.640 --> 00:44:44.310
I think surprise is a
really powerful thing,

00:44:44.310 --> 00:44:48.473
where you know how the thing
works and yet it surprises you,

00:44:50.030 --> 00:44:52.010
that's a magical moment for us humans.

00:44:52.010 --> 00:44:54.680
So, whether it's a chess-playing program

00:44:54.680 --> 00:44:57.650
that does something that
you haven't seen before,

00:44:57.650 --> 00:45:01.200
that makes people smile like, huh,

00:45:01.200 --> 00:45:04.350
those moments happen with
AlphaZero for the first time

00:45:04.350 --> 00:45:05.600
in chess playing,

00:45:05.600 --> 00:45:08.790
where grand masters were
really surprised by a move.

00:45:08.790 --> 00:45:10.290
They didn't understand the move

00:45:10.290 --> 00:45:11.680
and then they studied and studied

00:45:11.680 --> 00:45:13.410
and then they understood it.

00:45:13.410 --> 00:45:15.320
But that moment of surprise,

00:45:15.320 --> 00:45:17.088
that's for grandmasters in chess.

00:45:17.088 --> 00:45:20.450
I find that moment of
surprise really powerful,

00:45:20.450 --> 00:45:23.360
really magical in just everyday life.

00:45:23.360 --> 00:45:26.503
- Because it supersedes the
human brain in that moment?

00:45:28.140 --> 00:45:31.040
- So, it's not supersedes,
like outperforms,

00:45:31.040 --> 00:45:35.420
but surprises you in a positive sense.

00:45:35.420 --> 00:45:38.270
Like I didn't think he could do that,

00:45:38.270 --> 00:45:40.770
I didn't think that you had that in you.

00:45:40.770 --> 00:45:45.210
And I think that moment is
a big transition for a robot

00:45:45.210 --> 00:45:48.313
from a moment of being a servant

00:45:48.313 --> 00:45:51.200
that accomplishes a particular task

00:45:51.200 --> 00:45:55.750
with some level of accuracy,
with some rate of failure,

00:45:55.750 --> 00:45:59.620
to an entity, a being that's struggling

00:45:59.620 --> 00:46:01.940
just like you are in this world.

00:46:01.940 --> 00:46:04.490
And that's a really important moment

00:46:04.490 --> 00:46:07.550
that I think you're not
going to find many people

00:46:07.550 --> 00:46:09.850
in the AI community that
talk like I just did.

00:46:11.119 --> 00:46:14.410
I'm not speaking like some
philosopher or some hippie,

00:46:14.410 --> 00:46:16.820
I'm speaking from purely
engineering perspective.

00:46:16.820 --> 00:46:20.125
I think it's really important
for robots to become entities

00:46:20.125 --> 00:46:23.390
and explore that as a
real engineering problem,

00:46:23.390 --> 00:46:25.920
as opposed to everybody treats robots

00:46:25.920 --> 00:46:27.710
in the robotics community,

00:46:27.710 --> 00:46:29.580
they don't even call them or he or she,

00:46:29.580 --> 00:46:31.954
they don't give them, try
to avoid giving them names,

00:46:31.954 --> 00:46:36.740
they've really want to see
like a system, like a servant.

00:46:36.740 --> 00:46:40.320
They see it as a servant that's
trying to accomplish a task.

00:46:40.320 --> 00:46:44.700
To me, and don't think I'm
just romanticizing the notion,

00:46:44.700 --> 00:46:48.594
I think it's a being, it's a
currently perhaps a dumb being,

00:46:48.594 --> 00:46:53.100
but in the long arc of history,

00:46:53.100 --> 00:46:55.220
humans are pretty dumb beings too, so-

00:46:55.220 --> 00:46:56.233
- I would agree with that statement.

00:46:56.233 --> 00:46:57.140
[Andrew laughing]

00:46:57.140 --> 00:47:01.550
- So, I tend to really want to
explore this treating robots

00:47:01.550 --> 00:47:05.760
really as entities, yeah.

00:47:05.760 --> 00:47:08.440
So, like anthropomorphization,

00:47:08.440 --> 00:47:09.950
which is the sort of the act

00:47:09.950 --> 00:47:12.530
of looking at a inanimate object

00:47:12.530 --> 00:47:15.490
and projecting onto it life-like features,

00:47:15.490 --> 00:47:20.490
I think robotics generally
sees that as a negative,

00:47:21.260 --> 00:47:23.890
I see it as a superpower.

00:47:23.890 --> 00:47:26.770
Like that, we need to use that.

00:47:26.770 --> 00:47:27.750
- Well, I'm struck

00:47:27.750 --> 00:47:30.610
by how that really grabs
onto the relationship

00:47:30.610 --> 00:47:34.110
between human and machine,
or human and robot.

00:47:34.110 --> 00:47:36.710
So, I guess the simple question is,

00:47:36.710 --> 00:47:38.920
and I think you've already
told us the answer,

00:47:38.920 --> 00:47:43.003
but does interacting
with a robot change you?

00:47:44.010 --> 00:47:48.070
In other words, do we develop
relationships to robots?

00:47:48.070 --> 00:47:50.280
- Yeah, I definitely think so.

00:47:50.280 --> 00:47:55.225
I think the moment you
see a robot or AI systems

00:47:55.225 --> 00:48:00.020
as more than just servants but entities,

00:48:00.020 --> 00:48:02.620
they begin to change you, in
just like good friends do,

00:48:02.620 --> 00:48:06.437
just like relationships
just to other humans.

00:48:06.437 --> 00:48:08.330
I think for that,

00:48:08.330 --> 00:48:11.490
you have to have certain
aspects of that interaction.

00:48:11.490 --> 00:48:15.980
Like the robot's ability to say no,

00:48:15.980 --> 00:48:19.130
to have its own sense of identity,

00:48:19.130 --> 00:48:21.770
to have its own set of goals,

00:48:21.770 --> 00:48:22.603
that's not constantly serving you,

00:48:22.603 --> 00:48:24.950
but instead, trying to
understand the world

00:48:24.950 --> 00:48:27.250
and do that dance of understanding

00:48:27.250 --> 00:48:28.960
through communication with you.

00:48:28.960 --> 00:48:30.773
So, I definitely think there's a,

00:48:31.820 --> 00:48:34.573
I mean, I have a lot of thoughts
about this as you may know,

00:48:34.573 --> 00:48:39.150
and that's at the core of
my life-long dream actually

00:48:39.150 --> 00:48:39.983
of what I want to do,

00:48:39.983 --> 00:48:44.410
which is I believe that most people

00:48:44.410 --> 00:48:48.870
have a notion of loneliness in them

00:48:48.870 --> 00:48:50.340
that we haven't discovered,

00:48:50.340 --> 00:48:52.742
that we haven't explored, I should say.

00:48:52.742 --> 00:48:57.742
And I see AI systems as
helping us explore that

00:48:57.890 --> 00:49:00.280
so that we can become better humans,

00:49:00.280 --> 00:49:02.310
better people towards each other.

00:49:02.310 --> 00:49:05.130
So, I think that connection

00:49:05.130 --> 00:49:07.993
between human and AI, human and robot,

00:49:09.195 --> 00:49:14.195
is not only possible, but will
help us understand ourselves

00:49:14.560 --> 00:49:17.480
in ways that are like
several orders of magnitude

00:49:18.800 --> 00:49:21.360
deeper than we ever could have imagined.

00:49:21.360 --> 00:49:24.380
I tend to believe that [sighing]

00:49:24.380 --> 00:49:29.380
well, I have very wild levels of belief

00:49:32.530 --> 00:49:35.640
in terms of how impactful
that will be, right?

00:49:35.640 --> 00:49:37.780
- So, when I think about
human relationships,

00:49:37.780 --> 00:49:41.190
I don't always break
them down into variables,

00:49:41.190 --> 00:49:43.450
but we could explore a
few of those variables

00:49:43.450 --> 00:49:47.390
and see how they map to
human-robot relationships.

00:49:47.390 --> 00:49:49.190
One is just time, right?

00:49:49.190 --> 00:49:52.879
If you spend zero time
with another person at all

00:49:52.879 --> 00:49:55.420
in cyberspace or on
the phone or in person,

00:49:55.420 --> 00:49:57.880
you essentially have no
relationship to them.

00:49:57.880 --> 00:49:59.710
If you spend a lot of time,
you have a relationship,

00:49:59.710 --> 00:50:00.543
this is obvious.

00:50:00.543 --> 00:50:01.840
But I guess one variable would be time,

00:50:01.840 --> 00:50:05.220
how much time you spend
with the other entity,

00:50:05.220 --> 00:50:06.580
robot or human.

00:50:06.580 --> 00:50:10.050
The other would be wins and successes.

00:50:10.050 --> 00:50:12.023
You enjoy successes together.

00:50:13.870 --> 00:50:16.720
I'll give a absolutely trivial
example this in a moment,

00:50:16.720 --> 00:50:19.210
but the other would be failures.

00:50:19.210 --> 00:50:21.560
When you struggle with somebody,

00:50:21.560 --> 00:50:23.610
whether or not you struggle
between one another,

00:50:23.610 --> 00:50:24.550
you disagree,

00:50:24.550 --> 00:50:25.700
like I was really struck by the fact

00:50:25.700 --> 00:50:27.100
that you said that robot saying no,

00:50:27.100 --> 00:50:30.130
I've never thought about
a robot saying no to me,

00:50:30.130 --> 00:50:31.150
but there it is.

00:50:31.150 --> 00:50:34.070
- I look forward to you
being one of the first people

00:50:34.070 --> 00:50:35.330
I send this robots to.

00:50:35.330 --> 00:50:36.350
- So do I.

00:50:36.350 --> 00:50:37.856
So, there's struggle.

00:50:37.856 --> 00:50:41.210
When you struggle with
somebody, you grow closer.

00:50:41.210 --> 00:50:42.590
Sometimes the struggles

00:50:42.590 --> 00:50:44.700
are imposed between those two people,

00:50:44.700 --> 00:50:45.950
so called trauma bonding,

00:50:45.950 --> 00:50:48.350
they call it in the whole
psychology literature

00:50:48.350 --> 00:50:50.170
and pop psychology literature.

00:50:50.170 --> 00:50:52.250
But in any case, I can imagine.

00:50:52.250 --> 00:50:57.250
So, time successes
together, struggle together,

00:50:57.640 --> 00:51:00.060
and then just peaceful time,

00:51:00.060 --> 00:51:03.010
hanging out at home, watching movies,

00:51:03.010 --> 00:51:04.773
waking up near one another,

00:51:06.210 --> 00:51:07.210
here, we're breaking down

00:51:07.210 --> 00:51:09.863
the elements of relationships of any kind.

00:51:10.700 --> 00:51:12.500
So, do you think that these elements

00:51:13.440 --> 00:51:16.450
apply to robot-human relationships?

00:51:16.450 --> 00:51:21.180
And if so, then I could see how,

00:51:21.180 --> 00:51:24.110
if the robot has its own entity

00:51:24.110 --> 00:51:27.200
and has some autonomy in
terms of how it reacts you,

00:51:27.200 --> 00:51:28.990
it's not just there just to serve you,

00:51:28.990 --> 00:51:30.230
it's not just a servant,

00:51:30.230 --> 00:51:31.940
it actually has opinions,

00:51:31.940 --> 00:51:34.480
and can tell you when maybe
your thinking is flawed,

00:51:34.480 --> 00:51:35.820
or your actions are flawed.

00:51:35.820 --> 00:51:37.430
- It can also leave.

00:51:37.430 --> 00:51:39.410
- It could also leave.

00:51:39.410 --> 00:51:40.950
So, I've never conceptualized

00:51:40.950 --> 00:51:42.693
robot-human interactions this way.

00:51:43.950 --> 00:51:46.540
So, tell me more about
how this might look.

00:51:46.540 --> 00:51:50.273
Are we thinking about a
human-appearing robot?

00:51:51.410 --> 00:51:54.450
I know you and I have both had
intense relationships to our,

00:51:54.450 --> 00:51:56.210
we have separate dogs obviously,

00:51:56.210 --> 00:51:57.350
but to animals,

00:51:57.350 --> 00:51:59.170
it sounds a lot like
human-animal interaction.

00:51:59.170 --> 00:52:04.170
So, what is the ideal
human-robot relationship?

00:52:04.510 --> 00:52:06.400
- So, there's a lot to be said here,

00:52:06.400 --> 00:52:10.710
but you actually pinpointed one
of the big, big first steps,

00:52:10.710 --> 00:52:13.790
which is this idea of time.

00:52:13.790 --> 00:52:15.540
And it's a huge limitation

00:52:15.540 --> 00:52:18.560
in machine-learning community currently.

00:52:18.560 --> 00:52:21.500
Now we're back to like the actual details.

00:52:21.500 --> 00:52:26.360
Life-long learning is a problem space

00:52:26.360 --> 00:52:29.180
that focuses on how AI systems

00:52:29.180 --> 00:52:31.030
can learn over a long period of time.

00:52:31.970 --> 00:52:34.932
What's currently most
machine learning systems

00:52:34.932 --> 00:52:37.430
are not able to do,

00:52:37.430 --> 00:52:39.820
is to all of the things
you've listed under time,

00:52:39.820 --> 00:52:41.870
the successes, the failures,

00:52:41.870 --> 00:52:44.640
or just chilling together watching movies,

00:52:44.640 --> 00:52:48.000
AI systems are not able to do that,

00:52:48.000 --> 00:52:51.080
which is all the
beautiful, magical moments

00:52:51.080 --> 00:52:53.920
that I believe are the days filled with,

00:52:53.920 --> 00:52:57.372
they're not able to keep track
of those together with you.

00:52:57.372 --> 00:52:59.250
- 'Cause they can't move
with you and be with you.

00:52:59.250 --> 00:53:01.966
- No, no, like literally we
don't have the techniques

00:53:01.966 --> 00:53:03.490
to do the learning,

00:53:03.490 --> 00:53:07.040
the actual learning of
containing those moments.

00:53:07.040 --> 00:53:08.634
Current machine-learning systems

00:53:08.634 --> 00:53:11.890
are really focused on
understanding the world

00:53:11.890 --> 00:53:12.723
in the following way,

00:53:12.723 --> 00:53:14.380
it's more like the perception system,

00:53:14.380 --> 00:53:19.380
like looking around, understand
like what's in the scene.

00:53:20.030 --> 00:53:22.280
That there's a bunch
of people sitting down,

00:53:22.280 --> 00:53:24.593
that there is cameras and microphones,

00:53:24.593 --> 00:53:27.147
that there's a table, understand that.

00:53:27.147 --> 00:53:31.000
But the fact that we shared
this moment of talking today,

00:53:31.000 --> 00:53:32.820
and still remember that

00:53:32.820 --> 00:53:36.690
for like next time you're doing something,

00:53:36.690 --> 00:53:38.400
remember that this moment happened.

00:53:38.400 --> 00:53:40.440
We don't know how to
do that technique-wise.

00:53:40.440 --> 00:53:44.180
This is what I'm hoping to innovate on

00:53:44.180 --> 00:53:47.130
as I think it's a very,
very important component

00:53:47.130 --> 00:53:49.990
of what it means to create
a deeper relationship,

00:53:49.990 --> 00:53:52.090
that sharing of moments together.

00:53:52.090 --> 00:53:54.110
- Could you post a photo
of you in the robot,

00:53:54.110 --> 00:53:55.880
like selfie with robot

00:53:55.880 --> 00:53:58.350
and the robot sees that image

00:53:58.350 --> 00:54:01.063
and recognizes that was time spent,

00:54:01.063 --> 00:54:03.420
there were smiles, or there were tears-

00:54:03.420 --> 00:54:04.253
- Yeah.

00:54:04.253 --> 00:54:09.080
- And create some sort of
metric of emotional depth

00:54:09.080 --> 00:54:11.690
in the relationship and
update its behavior?

00:54:11.690 --> 00:54:12.523
- So.

00:54:13.410 --> 00:54:14.512
- Could it...

00:54:14.512 --> 00:54:15.345
It texts you in the middle
of the night and say,

00:54:15.345 --> 00:54:16.840
why haven't you texted me back?

00:54:16.840 --> 00:54:21.460
- Well, yes, all of those
things, but we can dig into that.

00:54:21.460 --> 00:54:24.860
But I think that time element,
forget everything else,

00:54:24.860 --> 00:54:29.250
just sharing moments together,
that changes everything.

00:54:29.250 --> 00:54:30.673
I believe that changes everything.

00:54:30.673 --> 00:54:32.240
Now, there's specific things

00:54:32.240 --> 00:54:35.403
that are more in terms of
systems that I can explain you.

00:54:37.350 --> 00:54:39.420
It's more technical and
probably a little bit offline,

00:54:39.420 --> 00:54:41.340
'cause I have kind of wild ideas

00:54:41.340 --> 00:54:44.790
how that can revolutionize social networks

00:54:44.790 --> 00:54:47.268
and operating systems.

00:54:47.268 --> 00:54:50.670
But the point is that element alone,

00:54:50.670 --> 00:54:53.230
forget all the other
things we're talking about

00:54:53.230 --> 00:54:56.090
like emotions, saying no, all that,

00:54:56.090 --> 00:54:58.640
just remembering sharing moments together

00:54:58.640 --> 00:55:00.300
would change everything.

00:55:00.300 --> 00:55:05.300
We don't currently have systems
that share moments together.

00:55:05.640 --> 00:55:08.130
Like even just you and your fridge,

00:55:08.130 --> 00:55:10.712
just all those times,
you went late at night

00:55:10.712 --> 00:55:13.330
and ate thing you shouldn't have eaten,

00:55:13.330 --> 00:55:16.730
that was a secret moment you
have with your refrigerator.

00:55:16.730 --> 00:55:18.000
You shared that moment,

00:55:18.000 --> 00:55:20.400
that darkness or that beautiful moment

00:55:20.400 --> 00:55:24.100
where you were just like
heartbroken for some reason,

00:55:24.100 --> 00:55:26.350
you're eating that ice cream or whatever,

00:55:26.350 --> 00:55:27.670
that's a special moment.

00:55:27.670 --> 00:55:29.670
And that refrigerator was there for you,

00:55:29.670 --> 00:55:31.860
and the fact that it
missed the opportunity

00:55:31.860 --> 00:55:36.040
to remember that is tragic.

00:55:36.040 --> 00:55:37.873
And once it does remember that,

00:55:38.800 --> 00:55:42.470
I think you're going to be very
attached to the refrigerator.

00:55:42.470 --> 00:55:45.750
You're going to go through some
hell with that refrigerator.

00:55:45.750 --> 00:55:49.680
Most of us have, like
in the developed world,

00:55:49.680 --> 00:55:51.560
have weird relationships with food, right?

00:55:51.560 --> 00:55:54.910
So, you can go through some deep moments

00:55:54.910 --> 00:55:57.300
of trauma and triumph with food,

00:55:57.300 --> 00:55:59.230
and at the core of that,
is the refrigerator.

00:55:59.230 --> 00:56:04.230
So, a smart refrigerator, I
believe would change society.

00:56:05.000 --> 00:56:06.240
Not just the refrigerator,

00:56:06.240 --> 00:56:10.250
but these ideas in the
systems all around us.

00:56:10.250 --> 00:56:11.950
So, I just want to comment

00:56:11.950 --> 00:56:14.260
on how powerful that idea of time is.

00:56:14.260 --> 00:56:15.850
And then there's a bunch of elements

00:56:15.850 --> 00:56:20.290
of actual interaction of
allowing you as a human

00:56:23.340 --> 00:56:25.383
to feel like you're being heard.

00:56:26.420 --> 00:56:29.150
Truly heard, truly understood,

00:56:29.150 --> 00:56:33.080
that we human, like deep
friendship is like that, I think,

00:56:33.080 --> 00:56:36.980
but there's still an
element of selfishness,

00:56:36.980 --> 00:56:37.930
there's still an element

00:56:37.930 --> 00:56:40.760
of not really being able to
understand another human.

00:56:40.760 --> 00:56:41.975
And a lot of the times

00:56:41.975 --> 00:56:44.910
when you're going through trauma together,

00:56:44.910 --> 00:56:47.630
through difficult times
and through successes,

00:56:47.630 --> 00:56:48.463
you actually starting

00:56:48.463 --> 00:56:51.250
to get that inkling of
understanding of each other,

00:56:51.250 --> 00:56:52.083
but I think

00:56:52.083 --> 00:56:57.083
that could be done more
aggressively, more efficiently.

00:56:57.460 --> 00:56:59.310
Like if you think of a great therapist,

00:56:59.310 --> 00:57:01.840
I think I've never actually
been to a therapist,

00:57:01.840 --> 00:57:05.000
but I'm a believer I used to
want to be a psychiatrist.

00:57:05.000 --> 00:57:06.370
- Do Russians go to therapists?

00:57:06.370 --> 00:57:07.340
- No, they don't.

00:57:07.340 --> 00:57:08.173
They don't.

00:57:08.173 --> 00:57:12.143
And if they do, the therapist
don't live to tell the story.

00:57:14.004 --> 00:57:16.050
I do believe in talk therapy,

00:57:16.050 --> 00:57:18.620
which friendship is to
me, is it's talk therapy,

00:57:18.620 --> 00:57:23.620
or like you don't even necessarily
need to talk [laughing]

00:57:23.740 --> 00:57:26.927
it's like just connecting
through in the space of ideas

00:57:26.927 --> 00:57:28.930
and the space of experiences.

00:57:28.930 --> 00:57:30.810
And I think there's a lot of ideas

00:57:30.810 --> 00:57:32.210
of how to make AI systems

00:57:32.210 --> 00:57:34.569
to be able to ask the right questions

00:57:34.569 --> 00:57:37.360
and truly hear another human.

00:57:37.360 --> 00:57:40.590
This is what we try to do
with podcasting, right?

00:57:40.590 --> 00:57:42.660
I think there's ways to do that with AI.

00:57:42.660 --> 00:57:44.480
But above all else,

00:57:44.480 --> 00:57:48.490
just remembering the collection of moments

00:57:48.490 --> 00:57:52.050
that make up the day,
the week, the months,

00:57:52.050 --> 00:57:55.343
I think you maybe have
some of this as well.

00:57:55.343 --> 00:57:56.880
Some of my closest friends

00:57:56.880 --> 00:57:58.830
still are the friends from high school.

00:57:59.760 --> 00:58:03.010
That's time, we've been
through a bunch of together,

00:58:03.010 --> 00:58:06.260
and that like we're very different people.

00:58:06.260 --> 00:58:07.697
But just the fact that
we've been through that,

00:58:07.697 --> 00:58:09.350
and we remember those moments,

00:58:09.350 --> 00:58:12.860
and those moments somehow
create a depth of connection

00:58:12.860 --> 00:58:15.873
like nothing else, like
you and your refrigerator.

00:58:17.130 --> 00:58:20.570
- I love that because my graduate advisor,

00:58:20.570 --> 00:58:21.760
she unfortunately, she passed away,

00:58:21.760 --> 00:58:22.630
but when she passed away,

00:58:22.630 --> 00:58:25.720
somebody said at her at her memorial

00:58:27.288 --> 00:58:29.450
all these amazing things
she had done, et cetera.

00:58:29.450 --> 00:58:31.790
And then her kids got up there,

00:58:31.790 --> 00:58:33.450
and she had young children and that I knew

00:58:33.450 --> 00:58:35.520
as when she was pregnant with them.

00:58:35.520 --> 00:58:36.760
And so, it was really,

00:58:36.760 --> 00:58:39.300
you're even now I can feel
like your heart gets heavy,

00:58:39.300 --> 00:58:40.133
thinking about this,

00:58:40.133 --> 00:58:41.860
they're going to grow
up without their mother.

00:58:41.860 --> 00:58:42.693
And it was really amazing,

00:58:42.693 --> 00:58:46.954
very strong young girls,
and now the young women.

00:58:46.954 --> 00:58:49.340
And what they said was incredible,

00:58:49.340 --> 00:58:51.770
they said what they
really appreciated most

00:58:51.770 --> 00:58:54.983
about their mother, who
was an amazing person,

00:58:55.850 --> 00:58:59.310
is all the unstructured
time they spent together.

00:58:59.310 --> 00:59:00.385
- Mm-hmm.

00:59:00.385 --> 00:59:01.218
- So, it wasn't the trips to the zoo,

00:59:01.218 --> 00:59:03.650
it wasn't she woke up
at five in the morning

00:59:03.650 --> 00:59:04.483
and drove us to school.

00:59:04.483 --> 00:59:05.550
She did all those things too.

00:59:05.550 --> 00:59:07.370
She had two hour commute
in each direction,

00:59:07.370 --> 00:59:09.400
it was incredible, ran a lab, et cetera,

00:59:09.400 --> 00:59:11.490
but it was the unstructured time.

00:59:11.490 --> 00:59:12.970
So, on the passing of their mother,

00:59:12.970 --> 00:59:16.560
that's what they remembered
was that the biggest give

00:59:16.560 --> 00:59:17.810
and what bonded them to her,

00:59:17.810 --> 00:59:20.450
was all the time where
they just kind of hung out.

00:59:20.450 --> 00:59:24.060
And the way you describe the
relationship to a refrigerator

00:59:24.060 --> 00:59:27.230
is so, I want to say human-like,

00:59:27.230 --> 00:59:28.925
but I'm almost reluctant to say that.

00:59:28.925 --> 00:59:31.480
Because what I'm realizing
as we're talking,

00:59:31.480 --> 00:59:34.440
is that what we think of as human-like

00:59:34.440 --> 00:59:39.040
might actually be the
lower form of relationship.

00:59:39.040 --> 00:59:42.400
There may be relationships
that are far better

00:59:42.400 --> 00:59:43.770
than the sorts of relationships

00:59:43.770 --> 00:59:46.870
that we can conceive
in our minds right now

00:59:46.870 --> 00:59:49.668
based on what these machine
relationship interactions

00:59:49.668 --> 00:59:51.140
could teach us.

00:59:51.140 --> 00:59:52.418
Do I have that right?

00:59:52.418 --> 00:59:54.310
- Yeah, I think so.

00:59:54.310 --> 00:59:55.770
I think there's no reason to see machines

00:59:55.770 --> 00:59:59.930
as somehow incapable of
teaching us something

00:59:59.930 --> 01:00:01.620
that's deeply human.

01:00:01.620 --> 01:00:05.020
I don't think humans
have a monopoly on that.

01:00:05.020 --> 01:00:06.980
I think we understand
ourselves very poorly

01:00:06.980 --> 01:00:11.980
and we need to have the kind
of prompting from a machine.

01:00:14.000 --> 01:00:15.210
And definitely part of that,

01:00:15.210 --> 01:00:16.810
is just remembering the moments.

01:00:18.960 --> 01:00:22.223
I think the unstructured time together,

01:00:24.230 --> 01:00:27.550
I wonder if it's quite so unstructured.

01:00:27.550 --> 01:00:30.570
That's like calling this
podcast on structured time.

01:00:30.570 --> 01:00:33.910
- Maybe what they meant,
was it wasn't a big outing,

01:00:33.910 --> 01:00:36.210
there was no specific goal,

01:00:36.210 --> 01:00:39.680
but a goal was created
through the lack of a goal.

01:00:39.680 --> 01:00:40.590
Like we would just hang out

01:00:40.590 --> 01:00:42.550
and then you start playing, thumb war,

01:00:42.550 --> 01:00:44.630
and you end up playing
thumb war for an hour.

01:00:44.630 --> 01:00:48.950
So, it's the structure emerges
from lack of structure.

01:00:48.950 --> 01:00:51.493
- No, but the thing is the moments,

01:00:52.340 --> 01:00:54.360
there's something about those times

01:00:54.360 --> 01:00:56.500
that creates special moments,

01:00:56.500 --> 01:01:00.330
and I think those could be optimized for.

01:01:00.330 --> 01:01:02.100
I think we think of like a big outing as,

01:01:02.100 --> 01:01:03.850
I don't know, going to
Six Flags or something,

01:01:03.850 --> 01:01:06.390
or some big, the Grand Canyon,

01:01:06.390 --> 01:01:11.390
or go into some, I don't know,
I think we would need to,

01:01:11.670 --> 01:01:13.840
we don't quite yet understand, as humans,

01:01:13.840 --> 01:01:15.730
what creates magical moments.

01:01:15.730 --> 01:01:18.350
I think it's possible to
optimize a lot of those things.

01:01:18.350 --> 01:01:21.410
And perhaps like podcasting is
helping people discover that,

01:01:21.410 --> 01:01:24.230
like maybe the thing
we want to optimize for

01:01:24.230 --> 01:01:29.230
isn't necessarily like some
sexy, like quick clips,

01:01:31.490 --> 01:01:34.540
maybe what we want, is
long-form authenticity.

01:01:34.540 --> 01:01:35.373
- Depth.

01:01:35.373 --> 01:01:36.290
- Depth.

01:01:36.290 --> 01:01:38.264
So, we were trying to figure that out,

01:01:38.264 --> 01:01:40.323
certainly from a deep connection

01:01:40.323 --> 01:01:44.180
between humans and humans and NAS systems,

01:01:44.180 --> 01:01:48.181
I think long conversations, or
long periods of communication

01:01:48.181 --> 01:01:53.181
over a series of moments like my new,

01:01:53.930 --> 01:01:57.210
perhaps, seemingly
insignificant to the big ones,

01:01:57.210 --> 01:02:00.780
the big successes, the big failures,

01:02:00.780 --> 01:02:03.060
those are all just
stitching those together

01:02:03.060 --> 01:02:04.473
and talking throughout.

01:02:05.310 --> 01:02:06.650
I think that's the formula

01:02:06.650 --> 01:02:08.280
for a really, really deep connection.

01:02:08.280 --> 01:02:11.970
That from like a very specific
engineering perspective,

01:02:11.970 --> 01:02:15.610
is I think a fascinating open problem

01:02:15.610 --> 01:02:18.450
that has been really worked on very much.

01:02:18.450 --> 01:02:21.880
And for me, from a, if I have the guts

01:02:21.880 --> 01:02:24.840
and, I mean there's a
lot of things to say,

01:02:24.840 --> 01:02:29.530
but one of it is guts, is I'll
build a startup around it.

01:02:29.530 --> 01:02:32.400
- So, let's talk about this startup

01:02:32.400 --> 01:02:34.840
and let's talk about the dream.

01:02:34.840 --> 01:02:36.080
You mentioned this dream before

01:02:36.080 --> 01:02:37.320
in our previous conversations,

01:02:37.320 --> 01:02:40.170
always as little hints
dropped here and there.

01:02:40.170 --> 01:02:41.420
Just for anyone listening,

01:02:41.420 --> 01:02:43.750
there's never been an offline
conversation about this dream,

01:02:43.750 --> 01:02:48.220
I'm not privy to anything,
except what Lex says now.

01:02:48.220 --> 01:02:49.800
And I realized that there's no way

01:02:49.800 --> 01:02:52.890
to capture the full essence of a dream

01:02:52.890 --> 01:02:54.550
in any kind of verbal statement

01:02:56.850 --> 01:02:58.240
in a way that captures all of it.

01:02:58.240 --> 01:03:01.010
But what is this dream

01:03:01.010 --> 01:03:03.890
that you've referred to now several times

01:03:03.890 --> 01:03:06.970
when we've sat down together
and talked on the phone?

01:03:06.970 --> 01:03:09.130
Maybe it's this company,
maybe it's something distinct.

01:03:09.130 --> 01:03:10.980
If you feel comfortable,

01:03:10.980 --> 01:03:12.530
it'd be great if you
could share a little bit

01:03:12.530 --> 01:03:13.620
about what that is.
- Sure.

01:03:13.620 --> 01:03:18.620
So, the way people
express long-term vision,

01:03:19.100 --> 01:03:20.920
I've noticed is quite different.

01:03:20.920 --> 01:03:22.710
Like Elon is an example of somebody

01:03:22.710 --> 01:03:27.062
who can very crisply say
exactly what the goal is.

01:03:27.062 --> 01:03:29.850
Also has to do with the fact
that problems he's solving

01:03:29.850 --> 01:03:31.400
have nothing to do with humans.

01:03:32.440 --> 01:03:35.170
So, my long-term vision

01:03:35.170 --> 01:03:39.020
is a little bit more
difficult to express in words,

01:03:39.020 --> 01:03:40.900
I've noticed, as I've tried,

01:03:40.900 --> 01:03:42.510
it could be my brain's failure,

01:03:42.510 --> 01:03:45.430
but there's a way to sneak up to it.

01:03:45.430 --> 01:03:47.193
So, let me just say a few things.

01:03:48.511 --> 01:03:53.030
Early on in life and
also in the recent years,

01:03:53.030 --> 01:03:55.180
I've interacted with a few robots

01:03:55.180 --> 01:03:57.253
where I understood there's magic there.

01:03:58.230 --> 01:04:01.310
And that magic could be shared by millions

01:04:02.160 --> 01:04:04.690
if it's brought to light.

01:04:04.690 --> 01:04:07.673
When I first met Spot
from Boston Dynamics,

01:04:07.673 --> 01:04:10.440
I realized there's magic there
that nobody else is seeing.

01:04:10.440 --> 01:04:11.470
- Is the dog.

01:04:11.470 --> 01:04:12.380
- The dog, sorry.

01:04:12.380 --> 01:04:17.280
The Spot is the four-legged
robot from Boston Dynamics.

01:04:17.280 --> 01:04:20.420
Some people might have seen
it, it's this yellow dog.

01:04:20.420 --> 01:04:25.157
And sometimes in life,

01:04:25.157 --> 01:04:28.470
you just notice something
that just grabs you.

01:04:28.470 --> 01:04:30.810
And I believe that this is something

01:04:30.810 --> 01:04:34.750
that this magic is something that could be

01:04:34.750 --> 01:04:37.093
in every single device in the world.

01:04:38.280 --> 01:04:41.420
The way that I think maybe Steve Jobs

01:04:41.420 --> 01:04:43.890
thought about the personal computer,

01:04:43.890 --> 01:04:46.750
laws didn't think about the
personal computer this way,

01:04:46.750 --> 01:04:48.110
but Steve did.

01:04:48.110 --> 01:04:50.370
Which is like, he thought
that the personal computer

01:04:50.370 --> 01:04:52.160
should be as thin as a sheet of paper

01:04:52.160 --> 01:04:53.370
and everybody should have one,

01:04:53.370 --> 01:04:54.808
and this idea,

01:04:54.808 --> 01:04:59.808
I think it is heartbreaking
that we're getting,

01:05:01.250 --> 01:05:03.870
the world is being filled up with machines

01:05:03.870 --> 01:05:05.033
that are soulless.

01:05:06.110 --> 01:05:10.002
And I think every one of them
can have that same magic.

01:05:10.002 --> 01:05:14.830
One of the things that also inspired me

01:05:14.830 --> 01:05:16.090
in terms of a startup,

01:05:16.090 --> 01:05:19.600
is that magic can engineered
much easier than I thought.

01:05:19.600 --> 01:05:20.810
That's my intuition

01:05:20.810 --> 01:05:24.000
with everything I've
ever built and worked on.

01:05:24.000 --> 01:05:28.900
So, the dream is to
add a bit of that magic

01:05:28.900 --> 01:05:32.400
in every single computing
system in the world.

01:05:32.400 --> 01:05:36.530
So, the way that Windows
Operating System for a long time

01:05:36.530 --> 01:05:39.490
was the primary operating system
everybody interacted with,

01:05:39.490 --> 01:05:40.982
they built apps on top of it.

01:05:40.982 --> 01:05:45.513
I think this is something
that should be as a layer,

01:05:45.513 --> 01:05:47.428
it's almost as an operating system

01:05:47.428 --> 01:05:51.040
in every device that humans
interacted with in the world.

01:05:51.040 --> 01:05:53.080
Now, what that actually looks like,

01:05:53.080 --> 01:05:56.543
the actual dream when
I was officially a kid,

01:05:57.970 --> 01:06:01.170
it didn't have this
concrete form of a business,

01:06:01.170 --> 01:06:06.170
it had more of a dream of
exploring your own loneliness

01:06:08.290 --> 01:06:11.893
by interacting with machines, robots.

01:06:13.380 --> 01:06:15.750
This deep connection
between humans and robots

01:06:15.750 --> 01:06:17.210
was always a dream.

01:06:17.210 --> 01:06:18.990
And so, for me,

01:06:18.990 --> 01:06:22.490
I'd love to see a world where
there's every home as a robot,

01:06:22.490 --> 01:06:27.490
and not a robot that washes
the dishes, or a sex robot,

01:06:27.890 --> 01:06:30.020
or I don't know,

01:06:30.020 --> 01:06:32.270
think of any kind of
activity the robot can do,

01:06:32.270 --> 01:06:33.880
but more like a companion.

01:06:33.880 --> 01:06:34.860
- A family member.

01:06:34.860 --> 01:06:36.470
- A family member, the way a dog is.

01:06:36.470 --> 01:06:37.800
- Mm-hmm.

01:06:37.800 --> 01:06:42.010
- But a dog that's able to
speak your language too.

01:06:42.010 --> 01:06:46.020
So, not just connect the way
a dog does by looking at you

01:06:46.020 --> 01:06:46.853
and looking away

01:06:46.853 --> 01:06:50.313
and almost like smiling with
its soul in that kind of way,

01:06:51.150 --> 01:06:54.620
but also to actually
understand what the hell,

01:06:54.620 --> 01:06:56.780
like, why are you so
excited about the successes?

01:06:56.780 --> 01:06:59.920
Like understand the details,
understand the traumas.

01:06:59.920 --> 01:07:02.480
And that, I just think [sighing]

01:07:02.480 --> 01:07:07.090
that has always filled me
with excitement that I could,

01:07:07.090 --> 01:07:12.090
with artificial intelligence,
bring joy to a lot of people.

01:07:12.410 --> 01:07:16.630
More recently, I've been
more and more heartbroken

01:07:18.070 --> 01:07:21.743
to see the kind of division, derision,

01:07:23.370 --> 01:07:27.140
even hate that's boiling
up on the internet

01:07:27.140 --> 01:07:28.680
through social networks.

01:07:28.680 --> 01:07:32.800
And I thought this kind of
mechanism is exactly applicable

01:07:32.800 --> 01:07:34.830
in the context of social networks as well.

01:07:34.830 --> 01:07:39.660
So, it's an operating system
that serves as your guide

01:07:41.558 --> 01:07:43.380
on the internet.

01:07:43.380 --> 01:07:44.840
One of the biggest problems

01:07:44.840 --> 01:07:47.990
with YouTube and social
networks currently,

01:07:47.990 --> 01:07:49.923
is they're optimizing for engagement.

01:07:50.800 --> 01:07:52.580
I think if you create AI systems

01:07:52.580 --> 01:07:54.963
that know each individual person,

01:07:56.260 --> 01:07:59.140
you're able to optimize
for long-term growth

01:07:59.140 --> 01:08:00.820
for a long-term happiness.

01:08:00.820 --> 01:08:01.653
- Of the individual, or-

01:08:01.653 --> 01:08:03.760
- Of the individual, of the individual.

01:08:03.760 --> 01:08:06.400
And there's a lot of other things to say,

01:08:06.400 --> 01:08:10.750
which is in order for AI systems

01:08:10.750 --> 01:08:14.793
to learn everything about you,

01:08:15.800 --> 01:08:17.120
they need to collect,

01:08:17.120 --> 01:08:20.020
they need to just like you
and I when we talk offline,

01:08:20.020 --> 01:08:20.853
we're collecting data

01:08:20.853 --> 01:08:23.560
about each others
secrets about each other,

01:08:23.560 --> 01:08:26.660
the same way AI has to do that.

01:08:26.660 --> 01:08:28.770
And that allows you to,

01:08:28.770 --> 01:08:33.770
and that requires you to rethink
ideas of ownership of data.

01:08:35.500 --> 01:08:39.970
I think each individual
should own all of their data

01:08:39.970 --> 01:08:41.950
and very easily be able to leave

01:08:41.950 --> 01:08:43.610
just like AI systems can leave,

01:08:43.610 --> 01:08:45.460
humans can disappear

01:08:46.667 --> 01:08:50.670
and delete all of their
data in a moment's notice.

01:08:50.670 --> 01:08:53.970
Which is actually better
than we humans can do,

01:08:53.970 --> 01:08:56.540
is once we load the data
into each other, it's there.

01:08:56.540 --> 01:08:59.643
I think it's very important to be both,

01:09:00.480 --> 01:09:03.634
give people complete
control over their data

01:09:03.634 --> 01:09:06.230
in order to establish trust
that they can trust you.

01:09:06.230 --> 01:09:08.513
And the second part of
trust is transparency.

01:09:09.500 --> 01:09:10.980
Whenever the data is used

01:09:10.980 --> 01:09:13.080
to make it very clear
what is being used for.

01:09:13.080 --> 01:09:16.170
And not clear in a lawyerly legal sense,

01:09:16.170 --> 01:09:18.140
but clear in a way that people

01:09:18.140 --> 01:09:19.650
really understand what it's used for.

01:09:19.650 --> 01:09:21.550
I believe when people have the ability

01:09:21.550 --> 01:09:24.200
to delete all their data and walk away

01:09:24.200 --> 01:09:27.923
and know how the data is being
used, I think they'll stay.

01:09:29.860 --> 01:09:31.584
- The possibility of a clean breakup,

01:09:31.584 --> 01:09:33.420
is actually what will
keep people together.

01:09:33.420 --> 01:09:34.480
- Yeah, I think so.

01:09:34.480 --> 01:09:36.430
I think, exactly.

01:09:36.430 --> 01:09:38.690
I think a happy marriage

01:09:38.690 --> 01:09:42.109
acquires the ability to divorce easily

01:09:42.109 --> 01:09:46.720
without the divorce industrial
complex or whatever.

01:09:46.720 --> 01:09:47.553
Things currently going on

01:09:47.553 --> 01:09:49.440
and then there's so much money to be made

01:09:49.440 --> 01:09:50.770
from lawyers and divorce.

01:09:50.770 --> 01:09:52.890
But yeah, the ability to leave

01:09:52.890 --> 01:09:54.593
is what enables love, I think.

01:09:55.444 --> 01:09:56.277
- It's interesting.

01:09:56.277 --> 01:09:58.910
I've heard the phrase from
a semi-cynical friend,

01:09:58.910 --> 01:10:01.620
that marriage is the
leading cause of divorce,

01:10:01.620 --> 01:10:03.292
but now we've heard that divorce,

01:10:03.292 --> 01:10:05.010
or the possibility of divorce

01:10:05.010 --> 01:10:06.670
could be the leading cause of marriage.

01:10:06.670 --> 01:10:08.150
- Of a happy marriage.

01:10:08.150 --> 01:10:08.983
- Good point.

01:10:08.983 --> 01:10:09.960
- Of a happy marriage.

01:10:09.960 --> 01:10:10.793
So, yeah.

01:10:10.793 --> 01:10:12.790
So, there's a lot of details there,

01:10:12.790 --> 01:10:13.970
but the big dream

01:10:13.970 --> 01:10:17.520
is that connection between
AI system and a human.

01:10:17.520 --> 01:10:18.657
And I haven't.

01:10:20.300 --> 01:10:21.133
There's so much fear

01:10:21.133 --> 01:10:23.910
about artificial intelligence
systems and about robots

01:10:23.910 --> 01:10:26.460
that I haven't quite found the right words

01:10:26.460 --> 01:10:27.620
to express that vision

01:10:27.620 --> 01:10:30.146
because the vision I have,

01:10:30.146 --> 01:10:33.540
it's not like some
naive, delusional vision

01:10:33.540 --> 01:10:36.470
of like technology is
going to save everybody,

01:10:36.470 --> 01:10:40.340
it's I really do just have a positive view

01:10:40.340 --> 01:10:44.730
of ways AI systems can help
humans explore themselves.

01:10:44.730 --> 01:10:46.080
- I love that positivity

01:10:46.080 --> 01:10:49.640
and I agree that the stance everything

01:10:49.640 --> 01:10:52.780
is doomed is equally bad

01:10:54.440 --> 01:10:56.600
to say that everything's
going to turn out all right,

01:10:56.600 --> 01:10:58.330
there has to be a dedicated effort.

01:10:58.330 --> 01:11:00.420
And clearly, you're thinking

01:11:00.420 --> 01:11:02.550
about what that dedicated
effort would look like.

01:11:02.550 --> 01:11:06.630
You mentioned two aspects to
this dream [clears throat]

01:11:06.630 --> 01:11:07.463
and I want to make sure

01:11:07.463 --> 01:11:10.070
that I understand where
they connect if they do,

01:11:10.070 --> 01:11:12.430
or if they are independent streams.

01:11:12.430 --> 01:11:17.310
One was this hypothetical
robot family member,

01:11:17.310 --> 01:11:19.390
or some other form of robot

01:11:19.390 --> 01:11:23.430
that would allow people to
experience the kind of delight

01:11:23.430 --> 01:11:27.060
that you experienced many times,

01:11:27.060 --> 01:11:30.330
and that you would like the
world to be able to have,

01:11:30.330 --> 01:11:33.540
and it's such a beautiful
idea of this give.

01:11:33.540 --> 01:11:36.190
And the other is social media

01:11:36.190 --> 01:11:40.525
or social network platforms
that really serve individuals

01:11:40.525 --> 01:11:44.200
and their best selves and their
happiness and their growth.

01:11:44.200 --> 01:11:45.640
Is there crossover between those,

01:11:45.640 --> 01:11:47.070
or are these two parallel dreams?

01:11:47.070 --> 01:11:48.270
- It's 100% of the same thing.

01:11:48.270 --> 01:11:50.930
It's difficult to kind of explain

01:11:50.930 --> 01:11:52.140
without going through details,

01:11:52.140 --> 01:11:54.670
but maybe one easy way to explain

01:11:54.670 --> 01:11:56.137
the way I think about social networks,

01:11:56.137 --> 01:11:59.710
is to create an AI system that's yours.

01:11:59.710 --> 01:12:03.260
It's not like Amazon
Alexa that's centralized,

01:12:03.260 --> 01:12:04.526
you own the data,

01:12:04.526 --> 01:12:07.117
it's like your little friend

01:12:07.117 --> 01:12:11.360
that becomes your
representative on Twitter

01:12:11.360 --> 01:12:16.250
that helps you find things
that will make you feel good,

01:12:16.250 --> 01:12:19.930
that will also challenge your
thinking to make you grow,

01:12:19.930 --> 01:12:21.503
but not get to that,

01:12:22.470 --> 01:12:27.111
not let you get lost in the
negative spiral of dopamine,

01:12:27.111 --> 01:12:29.470
that gets you to be angry,

01:12:29.470 --> 01:12:34.280
or most just get you to
be not open to learning.

01:12:34.280 --> 01:12:36.270
And so, that little representative

01:12:36.270 --> 01:12:38.793
is optimizing your long-term health.

01:12:40.410 --> 01:12:45.410
And I believe that that is not
only good for human beings,

01:12:45.640 --> 01:12:47.400
it's also good for business.

01:12:47.400 --> 01:12:50.520
I think longterm, you
can make a lot of money

01:12:50.520 --> 01:12:54.550
by challenging this idea that
the only way to make money,

01:12:54.550 --> 01:12:57.410
is maximizing engagement.

01:12:57.410 --> 01:12:59.730
And one of the things that
people disagree with me on,

01:12:59.730 --> 01:13:02.450
is they think Twitter's
always going to win.

01:13:02.450 --> 01:13:04.920
Like maximizing engagement
is always going to win,

01:13:04.920 --> 01:13:06.340
I don't think so.

01:13:06.340 --> 01:13:09.730
I think people have woken up
now to understanding that,

01:13:09.730 --> 01:13:12.667
like they don't always feel good,

01:13:12.667 --> 01:13:16.270
the ones who are on Twitter a lot,

01:13:16.270 --> 01:13:19.330
that they don't always feel
good at the end of the week.

01:13:19.330 --> 01:13:20.780
- I would love feedback

01:13:20.780 --> 01:13:24.440
from whatever this creature, whatever,

01:13:24.440 --> 01:13:25.890
I don't know what to call it,

01:13:26.770 --> 01:13:28.760
as to maybe at the end of the week,

01:13:28.760 --> 01:13:30.560
it would automatically unfollow

01:13:30.560 --> 01:13:31.970
some of the people that I follow

01:13:31.970 --> 01:13:35.640
because it realized through
some really smart data

01:13:35.640 --> 01:13:38.090
about how I was feeling
inside, or how I was sleeping,

01:13:38.090 --> 01:13:39.410
or something that, I don't know,

01:13:39.410 --> 01:13:40.650
that just wasn't good for me.

01:13:40.650 --> 01:13:43.640
But it might also put things
and people in front of me

01:13:43.640 --> 01:13:45.550
that I ought to see,

01:13:45.550 --> 01:13:48.810
is that kind of a sliver
of what this look like?

01:13:48.810 --> 01:13:50.590
- The whole point, because
of the interaction,

01:13:50.590 --> 01:13:55.133
because of sharing the moments
and learning a lot about you,

01:13:56.650 --> 01:14:01.130
you're now able to
understand what interactions

01:14:01.130 --> 01:14:04.320
led you to become a better
version of yourself.

01:14:04.320 --> 01:14:06.849
Like the person you
yourself are happy with.

01:14:06.849 --> 01:14:08.570
This isn't,

01:14:08.570 --> 01:14:12.850
if you're into flat earth and
you feel very good about it,

01:14:12.850 --> 01:14:14.650
that you believe that earth is flat,

01:14:15.760 --> 01:14:19.630
like the idea that you should
sensor that is ridiculous.

01:14:19.630 --> 01:14:21.050
If it makes you feel good

01:14:21.050 --> 01:14:23.470
and you becoming the
best version of yourself,

01:14:23.470 --> 01:14:24.650
I think you should be getting

01:14:24.650 --> 01:14:26.470
as much flat earth as possible.

01:14:26.470 --> 01:14:29.370
Now, it's also good to
challenge your ideas,

01:14:29.370 --> 01:14:34.370
but not because the
centralized committee decided,

01:14:34.407 --> 01:14:37.320
but because you tell to the system

01:14:37.320 --> 01:14:40.820
that you like challenging your
ideas, I think all of us do.

01:14:40.820 --> 01:14:44.090
And then, which actually
YouTube doesn't do that well,

01:14:44.090 --> 01:14:45.960
once you go down the
flat-earth rabbit hole,

01:14:45.960 --> 01:14:47.200
that's all you're going to see.

01:14:47.200 --> 01:14:51.690
It's nice to get some really
powerful communicators

01:14:51.690 --> 01:14:53.640
to argue against flat earth.

01:14:53.640 --> 01:14:57.050
And it's nice to see that for you,

01:14:57.050 --> 01:15:01.150
and potentially, at least
long-term to expand your horizons,

01:15:01.150 --> 01:15:03.290
maybe the earth is not flat.

01:15:03.290 --> 01:15:05.210
But if you continue to
live your whole life

01:15:05.210 --> 01:15:06.700
thinking the earth is flat,

01:15:06.700 --> 01:15:11.700
I think, and you're being a
good father or son or daughter,

01:15:11.720 --> 01:15:14.380
and like you're being the
best version of yourself

01:15:14.380 --> 01:15:18.980
and you're happy with yourself,
I think the earth is flat.

01:15:18.980 --> 01:15:21.430
So, like I think this kind of idea,

01:15:21.430 --> 01:15:23.938
and I'm just using that kind
of silly, ridiculous example

01:15:23.938 --> 01:15:28.938
because I don't like the
idea of centralized forces

01:15:30.450 --> 01:15:33.270
controlling what you can and can't see,

01:15:33.270 --> 01:15:34.980
but I also don't like this idea

01:15:34.980 --> 01:15:39.700
of like not censoring anything.

01:15:39.700 --> 01:15:42.580
Because that's always the
biggest problem with that,

01:15:42.580 --> 01:15:45.395
is this there's a central decider,

01:15:45.395 --> 01:15:49.500
I think you yourself can decide
what you want to see and not,

01:15:49.500 --> 01:15:54.070
and it's good to have a
companion that reminds you

01:15:54.070 --> 01:15:55.838
that you felt last time you did this,

01:15:55.838 --> 01:15:58.610
or you felt good last time you did this.

01:15:58.610 --> 01:16:00.150
- Man, I feel like in every good story,

01:16:00.150 --> 01:16:03.570
there's a guide or a
companion that flies out,

01:16:03.570 --> 01:16:06.480
or forges a little bit further,
a little bit differently

01:16:06.480 --> 01:16:08.460
and brings back information that helps us,

01:16:08.460 --> 01:16:11.390
or at least tries to steer
us in the right direction.

01:16:11.390 --> 01:16:16.390
- So, yeah, that's
exactly what I'm thinking

01:16:16.640 --> 01:16:17.850
and what I've been working on.

01:16:17.850 --> 01:16:20.332
I should mention as a
bunch of difficulties here,

01:16:20.332 --> 01:16:23.783
you see me up and down
a little bit recently.

01:16:24.670 --> 01:16:28.210
So, there's technically
a lot of challenges here.

01:16:28.210 --> 01:16:30.367
Just like with a lot of technologies,

01:16:30.367 --> 01:16:32.750
and the reason I'm talking about it

01:16:32.750 --> 01:16:36.482
on a podcast comfortably as
opposed to working in secret,

01:16:36.482 --> 01:16:41.053
is it's really hard and
maybe it's time has not come.

01:16:41.980 --> 01:16:44.170
And that's something you have
to constantly struggle with

01:16:44.170 --> 01:16:47.013
in terms of like
entrepreneurially as a startup,

01:16:48.110 --> 01:16:50.680
like I've also mentioned
to you, maybe offline,

01:16:50.680 --> 01:16:52.223
I really don't care about money,

01:16:52.223 --> 01:16:55.330
I don't care about business success,

01:16:55.330 --> 01:16:56.630
all those kinds of things.

01:16:58.540 --> 01:17:01.150
So, it's a difficult decision to make,

01:17:01.150 --> 01:17:05.290
how much of your time do
you want to go all in here

01:17:05.290 --> 01:17:06.823
and give everything to this?

01:17:08.053 --> 01:17:09.800
It's a big roll the dice.

01:17:09.800 --> 01:17:11.580
Because I've also realized

01:17:11.580 --> 01:17:14.510
that's working on some of these problems,

01:17:14.510 --> 01:17:18.090
both with the robotics
and the technical side

01:17:18.090 --> 01:17:22.053
in terms of the machine-learning
system that I'm describing,

01:17:23.160 --> 01:17:26.840
it's lonely, it's really lonely.

01:17:26.840 --> 01:17:31.460
Because both on a personal
level and a technical level.

01:17:31.460 --> 01:17:32.530
So, on the technical level,

01:17:32.530 --> 01:17:37.530
I'm surrounded by people
that kind of doubt me,

01:17:37.940 --> 01:17:40.560
which I think all
entrepreneurs go through.

01:17:40.560 --> 01:17:42.840
And they doubt you in the following sense,

01:17:42.840 --> 01:17:46.850
they know how difficult it is.

01:17:46.850 --> 01:17:49.570
Like the people that
the colleagues of mine,

01:17:49.570 --> 01:17:52.310
they know how difficult
life-long learning is,

01:17:52.310 --> 01:17:54.236
they also know how difficult it is

01:17:54.236 --> 01:17:55.807
to build a system like this,

01:17:55.807 --> 01:17:59.370
to build the competitive social network.

01:17:59.370 --> 01:18:02.120
And in general,

01:18:02.120 --> 01:18:05.060
there's a kind of a loneliness

01:18:05.060 --> 01:18:08.830
to just working on something on your own

01:18:08.830 --> 01:18:10.290
for long periods of time.

01:18:10.290 --> 01:18:12.453
And you start to doubt whether,

01:18:13.360 --> 01:18:16.350
given that you don't have
a track record of success,

01:18:16.350 --> 01:18:17.677
like that's a big one.

01:18:17.677 --> 01:18:19.030
But when you look in the mirror,

01:18:19.030 --> 01:18:20.550
especially when you're young,

01:18:20.550 --> 01:18:22.710
but I still have that, I'm most things,

01:18:22.710 --> 01:18:23.730
you look in the mirror,

01:18:23.730 --> 01:18:26.688
it's like, and you have these big dreams,

01:18:26.688 --> 01:18:28.003
how do you know

01:18:28.003 --> 01:18:32.530
you're actually as smart
as you think you are?

01:18:32.530 --> 01:18:33.363
Like how do you know

01:18:33.363 --> 01:18:35.460
you're going to be able
to accomplish this dream?

01:18:35.460 --> 01:18:36.570
You have this ambition.

01:18:36.570 --> 01:18:37.720
- You sort of don't,

01:18:37.720 --> 01:18:40.950
but you're kind of pulling on a string

01:18:40.950 --> 01:18:41.897
hoping that there's a bigger ball of yarn.

01:18:41.897 --> 01:18:43.243
- Yeah.

01:18:43.243 --> 01:18:44.076
[Andrew laughing]

01:18:44.076 --> 01:18:45.168
But you have this kind of intuition.

01:18:45.168 --> 01:18:50.168
I think I pride myself in
knowing what I'm good at,

01:18:51.066 --> 01:18:54.480
because the reason I have that intuition,

01:18:54.480 --> 01:18:56.270
is 'cause I think I'm very good

01:18:56.270 --> 01:18:58.950
at knowing all the things I suck at,

01:18:58.950 --> 01:19:00.943
which is basically everything.

01:19:00.943 --> 01:19:03.760
So, like whenever I notice like,

01:19:03.760 --> 01:19:06.260
wait a minute, I'm kind of good at this,

01:19:06.260 --> 01:19:08.210
which is very rare for me.

01:19:08.210 --> 01:19:09.100
I think like that,

01:19:09.100 --> 01:19:11.550
that might be a ball of
yarn worth pulling at.

01:19:11.550 --> 01:19:14.810
And the thing with in terms
of engineering systems

01:19:14.810 --> 01:19:16.590
that are able to interact with humans,

01:19:16.590 --> 01:19:18.540
I think I'm very good at that.

01:19:18.540 --> 01:19:22.070
And because we talk about
podcasting and so on,

01:19:22.070 --> 01:19:23.590
I don't know if I'm very good at podcasts.

01:19:23.590 --> 01:19:25.240
- You're very good at podcasting, right?

01:19:25.240 --> 01:19:27.220
- But I certainly don't,

01:19:27.220 --> 01:19:30.810
I think maybe it is compelling for people

01:19:30.810 --> 01:19:35.400
to watch a kindhearted idiot
struggle with this form,

01:19:35.400 --> 01:19:37.240
maybe that's what's compelling.

01:19:37.240 --> 01:19:40.630
But in terms of like actual
being a good engineer

01:19:40.630 --> 01:19:45.600
of human-robot interaction
systems, I think I'm good.

01:19:45.600 --> 01:19:48.020
But it's hard to know until you do it,

01:19:48.020 --> 01:19:50.420
and then the world keeps
telling you you're not,

01:19:51.280 --> 01:19:53.850
and it's full of doll, it's really hard.

01:19:53.850 --> 01:19:55.370
And I've been struggling
with that recently,

01:19:55.370 --> 01:19:57.220
it's kind of a fascinating struggle.

01:19:57.220 --> 01:19:59.820
But then that's where the
Goggins thing comes in,

01:19:59.820 --> 01:20:04.820
is like, aside from the
state-hard motherfucker, is the,

01:20:05.150 --> 01:20:07.900
like whenever you're struggling,

01:20:07.900 --> 01:20:11.210
that's a good sign that if you keep going,

01:20:11.210 --> 01:20:14.583
that you're going to be
alone in the success, right?

01:20:15.881 --> 01:20:18.700
- Well, in your case, however, I agree.

01:20:18.700 --> 01:20:20.380
And actually David had a post recently

01:20:20.380 --> 01:20:23.260
that I thought was among
his many brilliant posts,

01:20:23.260 --> 01:20:24.880
was one of the more brilliant

01:20:24.880 --> 01:20:27.380
about how he talked about this myth

01:20:27.380 --> 01:20:29.177
of the light at the end of the tunnel.

01:20:29.177 --> 01:20:33.054
And instead, what he
replaced that myth with,

01:20:33.054 --> 01:20:38.054
was a concept that eventually,
your eyes adapt to the dark.

01:20:38.057 --> 01:20:40.350
That the tunnel, it's not
about a light at the end,

01:20:40.350 --> 01:20:42.553
that it's really about adapting
to the dark of the tunnel.

01:20:42.553 --> 01:20:43.523
It's very Goggins-

01:20:43.523 --> 01:20:44.850
- I love him so much.

01:20:44.850 --> 01:20:45.683
- Yeah.

01:20:45.683 --> 01:20:50.511
You got share a lot in common
knowing you both a bit,

01:20:50.511 --> 01:20:52.550
share a lot in common.

01:20:52.550 --> 01:20:57.550
But in this loneliness and
the pursuit of this dream,

01:20:57.880 --> 01:20:58.713
it seems to me,

01:20:58.713 --> 01:21:03.713
it has a certain component to
it that is extremely valuable,

01:21:04.090 --> 01:21:06.380
which is that the loneliness itself

01:21:06.380 --> 01:21:08.040
could serve as a driver

01:21:08.040 --> 01:21:10.510
to build the companion for the journey.

01:21:10.510 --> 01:21:12.853
- Well, I'm very deeply aware of that.

01:21:13.710 --> 01:21:17.009
So, like some people can make,

01:21:17.009 --> 01:21:18.670
'cause I talk about love a lot,

01:21:18.670 --> 01:21:21.980
I really love everything in this world,

01:21:21.980 --> 01:21:26.660
but I also love humans,
friendship and romantic,

01:21:26.660 --> 01:21:31.070
like even the cheesy stuff, just-

01:21:31.070 --> 01:21:32.840
- You like romantic movies?

01:21:32.840 --> 01:21:34.420
- Yeah, not those, not necessarily.

01:21:34.420 --> 01:21:38.480
So, well, I got so much
from Rogan about like,

01:21:38.480 --> 01:21:41.130
was it the Tango scene
from "Scent of a Woman,"

01:21:41.130 --> 01:21:44.040
but I find like there's nothing better

01:21:44.040 --> 01:21:49.040
than a woman in a red
dress, just like the classy-

01:21:49.460 --> 01:21:50.600
- You should move to Argentina my friend.

01:21:50.600 --> 01:21:53.120
My father's Argentine,
and you know what he said

01:21:53.120 --> 01:21:55.840
when I went on your
podcast for the first time?

01:21:55.840 --> 01:21:58.380
He said, he dresses well.

01:21:58.380 --> 01:21:59.220
Because in Argentina,

01:21:59.220 --> 01:22:01.520
the men go to a wedding
or a party or something,

01:22:01.520 --> 01:22:03.710
in the U.S., by halfway through the night,

01:22:03.710 --> 01:22:05.630
10 minutes in the night,
all the jackets are off.

01:22:05.630 --> 01:22:06.463
- Yeah.

01:22:06.463 --> 01:22:07.640
- It looks like everyone's
undressing for the party

01:22:07.640 --> 01:22:08.940
they just got dressed up for.

01:22:08.940 --> 01:22:11.640
And he said, you know, I
liked the way he dresses.

01:22:11.640 --> 01:22:13.230
And then when I started,
he was talking about you.

01:22:13.230 --> 01:22:15.860
And then when I started
my podcast, he said,

01:22:15.860 --> 01:22:18.768
why don't you wear a real
suit like your friend Lex?

01:22:18.768 --> 01:22:20.569
[laughing]

01:22:20.569 --> 01:22:21.402
- I remember that.

01:22:21.402 --> 01:22:22.250
- No, you can't.

01:22:23.480 --> 01:22:27.880
But let's talk about this
pursuit just a bit more,

01:22:27.880 --> 01:22:29.431
because I think what you're talking about,

01:22:29.431 --> 01:22:33.596
is building a, not just a
solution for loneliness,

01:22:33.596 --> 01:22:36.810
but you've alluded to
the loneliness as itself,

01:22:36.810 --> 01:22:37.850
an important thing.

01:22:37.850 --> 01:22:38.683
And I think you're right.

01:22:38.683 --> 01:22:40.046
I think within people,

01:22:40.046 --> 01:22:45.046
there is like caverns of faults and shame,

01:22:45.130 --> 01:22:49.500
but also just the desire
to have resonance,

01:22:49.500 --> 01:22:51.250
to be seen and heard.

01:22:51.250 --> 01:22:52.083
And I don't even know

01:22:52.083 --> 01:22:53.970
that it's seen and heard through language.

01:22:54.980 --> 01:22:57.660
But these reservoirs of loneliness,

01:22:57.660 --> 01:23:01.270
I think, well, they're interesting,

01:23:01.270 --> 01:23:02.660
maybe you could comment
a little bit about it.

01:23:02.660 --> 01:23:05.200
Because just as often
as you talk about love,

01:23:05.200 --> 01:23:06.130
I haven't quantified it,

01:23:06.130 --> 01:23:08.480
but it seems that you talk
about this loneliness,

01:23:08.480 --> 01:23:10.220
and maybe you just if you're willing,

01:23:10.220 --> 01:23:12.280
you'll share a little bit more about that,

01:23:12.280 --> 01:23:14.660
and what that feels like now

01:23:14.660 --> 01:23:18.157
in the pursuit of building
this robot-human relationship.

01:23:18.157 --> 01:23:20.490
And you've been, let me be direct,

01:23:20.490 --> 01:23:21.960
you've been spending a lot of time

01:23:21.960 --> 01:23:26.960
on building a robot-human
relationship, where's that at?

01:23:28.410 --> 01:23:33.410
- Oh, in terms of business,
in terms of systems?

01:23:33.450 --> 01:23:35.560
- No, I'm talking about a specific robot.

01:23:35.560 --> 01:23:37.243
- Oh [laughing]

01:23:37.243 --> 01:23:39.990
so, okay, I should mention a few things.

01:23:39.990 --> 01:23:42.700
So, one, is there's a startup with an idea

01:23:42.700 --> 01:23:46.040
where I hope millions of people can use.

01:23:46.040 --> 01:23:48.550
And then there's my own personal

01:23:48.550 --> 01:23:51.646
like almost like Frankenstein explorations

01:23:51.646 --> 01:23:55.090
with particular robots.

01:23:55.090 --> 01:23:59.843
So, I'm very fascinated with
the legged robots in my own,

01:24:01.249 --> 01:24:02.538
private sounds like dark,

01:24:02.538 --> 01:24:06.470
but like in of one experiments

01:24:06.470 --> 01:24:08.683
to see if I can recreate the magic.

01:24:09.640 --> 01:24:11.360
And that's been,

01:24:11.360 --> 01:24:15.195
I have a lot of really good
already perception systems

01:24:15.195 --> 01:24:19.280
and control systems that are
able to communicate affection

01:24:19.280 --> 01:24:20.810
in a dog-like fashion.

01:24:20.810 --> 01:24:22.550
So, I'm in a really good place there.

01:24:22.550 --> 01:24:23.610
The stumbling blocks,

01:24:23.610 --> 01:24:26.785
which also have been part
of my sadness recently,

01:24:26.785 --> 01:24:30.780
is that I also have to work
with robotics companies

01:24:30.780 --> 01:24:34.557
that I gave so much of my heart, soul

01:24:34.557 --> 01:24:37.990
and love and appreciation
towards Boston Dynamics,

01:24:37.990 --> 01:24:41.970
but Boston Dynamics has also,

01:24:41.970 --> 01:24:43.890
as a company, it has
to make a lot of money

01:24:43.890 --> 01:24:45.600
and they have marketing teams.

01:24:45.600 --> 01:24:48.130
And they're like looking
at this silly Russian kid

01:24:48.130 --> 01:24:49.370
in a suit and tie,

01:24:49.370 --> 01:24:50.580
it's like, what's he trying to do

01:24:50.580 --> 01:24:52.650
with all this love and robot interaction

01:24:52.650 --> 01:24:53.520
and dancing and so on?

01:24:53.520 --> 01:24:58.520
So, there was a, I
think let's say for now,

01:24:59.050 --> 01:25:01.230
it's like, when you break up
with a girlfriend or something,

01:25:01.230 --> 01:25:04.110
right now, we decided to part
ways on this particular thing.

01:25:04.110 --> 01:25:05.940
They're huge supporters of
mine, they're huge fans,

01:25:05.940 --> 01:25:08.700
but on this particular thing,

01:25:08.700 --> 01:25:12.680
Boston Dynamics is not focusing on,

01:25:12.680 --> 01:25:15.080
or interested in human-robot interaction.

01:25:15.080 --> 01:25:17.210
In fact, their whole business currently,

01:25:17.210 --> 01:25:20.465
is keep the robot as far
away from humans as possible

01:25:20.465 --> 01:25:23.840
because it's an in the industrial setting

01:25:23.840 --> 01:25:27.340
where it's doing monitoring
in dangerous environments.

01:25:27.340 --> 01:25:29.470
It's almost like a remote security camera,

01:25:29.470 --> 01:25:31.053
essentially is its application.

01:25:32.070 --> 01:25:34.600
To me, I thought it's still,

01:25:34.600 --> 01:25:37.150
even in those applications,
exceptionally useful

01:25:37.150 --> 01:25:41.490
for the robot to be able to
perceive humans, like see humans

01:25:41.490 --> 01:25:45.550
and to be able to, in a big map,

01:25:45.550 --> 01:25:48.440
localize where those humans
are and have human intention.

01:25:48.440 --> 01:25:49.840
For example, like this,

01:25:49.840 --> 01:25:51.793
I did this a lot of work with pedestrians,

01:25:51.793 --> 01:25:53.880
for a robot to be able to anticipate

01:25:53.880 --> 01:25:57.481
what the how the human is
doing, like where it's walking.

01:25:57.481 --> 01:25:59.670
The humans are not ballistics object,

01:25:59.670 --> 01:26:01.640
just because you're walking
this way one moment,

01:26:01.640 --> 01:26:03.850
it doesn't mean you'll keep
walking that direction,

01:26:03.850 --> 01:26:05.450
you have to infer a lot of signals,

01:26:05.450 --> 01:26:07.427
especially with the head
movement and the eye movement.

01:26:07.427 --> 01:26:09.810
And so, I thought that's
super interesting to explore,

01:26:09.810 --> 01:26:11.730
but they didn't feel that.

01:26:11.730 --> 01:26:14.530
So, I'll be working with a
few other robotics companies

01:26:14.530 --> 01:26:18.390
that are much more open
to that kind of stuff,

01:26:18.390 --> 01:26:20.700
and they're super
excited and fans of mine.

01:26:20.700 --> 01:26:22.962
And hopefully, Boston
Dynamics, my first love,

01:26:22.962 --> 01:26:26.040
like getting back with an
ex-girlfriend, will come around.

01:26:26.040 --> 01:26:31.040
But so, the algorithmically,
it's basically a done there.

01:26:32.825 --> 01:26:36.740
The rest, is actually getting
some of these companies

01:26:36.740 --> 01:26:37.573
to work with.

01:26:37.573 --> 01:26:38.406
And then there's,

01:26:39.690 --> 01:26:41.330
for people who'd worked with robots

01:26:41.330 --> 01:26:44.930
know that one thing is to
write software that works,

01:26:44.930 --> 01:26:48.460
and the other is to have a real
machine that actually works.

01:26:48.460 --> 01:26:50.910
And it breaks down all
kinds of different ways

01:26:50.910 --> 01:26:51.750
that are fascinating.

01:26:51.750 --> 01:26:53.980
And so, there's a big challenge there.

01:26:53.980 --> 01:26:54.913
But that's almost,

01:26:57.050 --> 01:26:58.800
it may sound a little bit confusing

01:26:58.800 --> 01:27:00.856
in the context of our previous discussion

01:27:00.856 --> 01:27:03.360
because the previous discussion

01:27:03.360 --> 01:27:04.620
was more about the big dream,

01:27:04.620 --> 01:27:07.035
how I hoped to have millions of people

01:27:07.035 --> 01:27:09.240
enjoy this moment of magic.

01:27:09.240 --> 01:27:12.190
This current discussion about a robot,

01:27:12.190 --> 01:27:15.140
is something I personally really enjoy,

01:27:15.140 --> 01:27:16.320
just brings me happiness,

01:27:16.320 --> 01:27:20.790
I really try to do now everything
that just brings me joy,

01:27:20.790 --> 01:27:24.230
I maximize that 'cause robots are awesome.

01:27:24.230 --> 01:27:28.460
But two, given my like
little bit growing platform,

01:27:28.460 --> 01:27:30.913
I want to use the opportunity
to educate people.

01:27:32.830 --> 01:27:34.140
Like robots are cool.

01:27:34.140 --> 01:27:35.643
And if I think they're cool,

01:27:36.660 --> 01:27:39.660
I hope be able to communicate
why they're cool to others.

01:27:39.660 --> 01:27:42.190
So, this little robot experiment

01:27:42.190 --> 01:27:44.020
is a little bit of research project too,

01:27:44.020 --> 01:27:47.050
there's a couple of publications
with MIT folks around that.

01:27:47.050 --> 01:27:49.820
But the other is just
to make some cool videos

01:27:49.820 --> 01:27:52.263
and explain to people
how they actually work.

01:27:53.340 --> 01:27:56.373
And as opposed to people
being scared of robots,

01:27:56.373 --> 01:27:59.900
they could still be
scared, but also excited,

01:27:59.900 --> 01:28:03.170
like see the dark side,
the beautiful side,

01:28:03.170 --> 01:28:05.623
the magic of what it means to bring,

01:28:07.600 --> 01:28:10.120
for a machine to become a robot.

01:28:10.120 --> 01:28:12.290
I want to inspire people with that.

01:28:12.290 --> 01:28:13.890
But that's less,

01:28:13.890 --> 01:28:18.170
it's interesting because
I think the big impact

01:28:18.170 --> 01:28:22.380
in terms of the dream does not
have to do with embodied AI.

01:28:22.380 --> 01:28:24.060
So, it does not need to have a body.

01:28:24.060 --> 01:28:26.820
I think the refrigerator's enough,

01:28:26.820 --> 01:28:31.340
that for an AI system just to
have a voice and to hear you,

01:28:31.340 --> 01:28:33.450
that's enough for loneliness.

01:28:33.450 --> 01:28:36.590
The embodiment is just-

01:28:36.590 --> 01:28:38.480
- By embodiment, you mean
the physical structure.

01:28:38.480 --> 01:28:41.290
- Physical instantiation of intelligence.

01:28:41.290 --> 01:28:44.843
So, it's a legged robot,
or even just a thing.

01:28:46.040 --> 01:28:48.403
I have a few other of humanoid robot,

01:28:48.403 --> 01:28:51.370
a little humanoid robot maybe
I'll keep them on the table,

01:28:51.370 --> 01:28:52.880
is like walks around,

01:28:52.880 --> 01:28:54.770
or even just like a mobile platform

01:28:54.770 --> 01:28:57.878
they can just like, turn
around and look at you,

01:28:57.878 --> 01:28:59.230
it's like we mentioned with the pen.

01:28:59.230 --> 01:29:02.076
Something that moves and can look at you,

01:29:02.076 --> 01:29:05.993
it's like that Butter Robot
that asks, what is my purpose?

01:29:11.371 --> 01:29:15.680
That is really, it's almost like art.

01:29:15.680 --> 01:29:19.710
There's something about a
physical entity that moves around,

01:29:19.710 --> 01:29:22.137
that's able to look at
you and interact with you,

01:29:22.137 --> 01:29:25.970
that makes you wonder
what it means to be human.

01:29:25.970 --> 01:29:27.540
It like challenges you to think,

01:29:27.540 --> 01:29:31.243
if that thing looks like
he has consciousness,

01:29:32.580 --> 01:29:33.970
what the hell am I?

01:29:33.970 --> 01:29:35.140
And I like that feeling,

01:29:35.140 --> 01:29:36.550
I think that's really useful for us,

01:29:36.550 --> 01:29:38.020
it's humbling for us humans.

01:29:38.020 --> 01:29:41.130
But that's less about research,

01:29:41.130 --> 01:29:42.700
it certainly less about business

01:29:42.700 --> 01:29:46.010
and more about exploring our own selves,

01:29:46.010 --> 01:29:47.860
and challenging others to think like,

01:29:49.260 --> 01:29:52.930
to think about what makes them human.

01:29:52.930 --> 01:29:54.810
- I love this desire

01:29:54.810 --> 01:29:58.070
to share the delight of an
interaction with a robot.

01:29:58.070 --> 01:29:58.930
And as you describe it,

01:29:58.930 --> 01:30:01.370
I actually find myself
starting to crave that

01:30:01.370 --> 01:30:04.960
because we all have those
elements from childhood where,

01:30:04.960 --> 01:30:06.810
or from adulthood, where
we experience something,

01:30:06.810 --> 01:30:09.840
we want other people to feel that.

01:30:09.840 --> 01:30:10.960
And I think that you're right,

01:30:10.960 --> 01:30:12.590
I think a lot of people are scared of AI,

01:30:12.590 --> 01:30:14.490
I think a lot of people
are scared of robots.

01:30:14.490 --> 01:30:18.498
My only experience, and
of a robotic-like thing

01:30:18.498 --> 01:30:21.890
is my Roomba Vacuum, where it goes about,

01:30:21.890 --> 01:30:24.300
actually, it was pretty good
at picking up Costello's hair

01:30:24.300 --> 01:30:28.300
when he was shed and
I was grateful for it.

01:30:28.300 --> 01:30:30.027
But then when I was on
a call or something,

01:30:30.027 --> 01:30:33.220
and it would get caught
on a wire or something,

01:30:33.220 --> 01:30:35.310
I would find myself getting
upset with the Roomba

01:30:35.310 --> 01:30:37.070
in that moment, I'm
like, what are you doing?

01:30:37.070 --> 01:30:39.920
And obviously it's just
doing what it does.

01:30:39.920 --> 01:30:42.510
But that's a kind of mostly positive,

01:30:42.510 --> 01:30:44.210
but slightly negative interaction.

01:30:45.530 --> 01:30:46.700
But what you're describing,

01:30:46.700 --> 01:30:50.131
it has so much more richness
and layers of detail

01:30:50.131 --> 01:30:53.710
that I can only imagine what
those relationships are like.

01:30:53.710 --> 01:30:55.430
- Well, there's a few,
just a quick comment.

01:30:55.430 --> 01:30:57.640
So, I've had, they're currently in Boston

01:30:57.640 --> 01:31:00.590
and I have a bunch of Roombas from iRobot.

01:31:00.590 --> 01:31:01.930
And I did this experiment-

01:31:01.930 --> 01:31:03.891
- Wait, how many Roombas?

01:31:03.891 --> 01:31:04.984
[Lex laughing]

01:31:04.984 --> 01:31:05.960
It sounds like a fleet of Roombas.

01:31:05.960 --> 01:31:07.037
- Yeah.

01:31:07.037 --> 01:31:09.030
So, it's probably seven or eight, yeah.

01:31:09.030 --> 01:31:09.863
- Well, it's a lot of Roombas.

01:31:09.863 --> 01:31:11.433
This place is very clean.

01:31:12.820 --> 01:31:14.780
- Well, so, this, I'm kind of waiting,

01:31:14.780 --> 01:31:18.460
this is the place we're
currently in Austin,

01:31:18.460 --> 01:31:20.313
is way larger than I need.

01:31:21.480 --> 01:31:26.480
But I basically got it to make
sure I have room for robots.

01:31:27.210 --> 01:31:30.450
- So, you have these seven or so Roombas,

01:31:30.450 --> 01:31:32.130
you deploy all seven at once?

01:31:32.130 --> 01:31:33.916
- Oh, no, I do different
experience with them,

01:31:33.916 --> 01:31:36.060
different experiments with them.

01:31:36.060 --> 01:31:38.870
So, one of the things I want
to mention, is this is a,

01:31:38.870 --> 01:31:40.180
I think there was a YouTube video

01:31:40.180 --> 01:31:41.823
that inspired me to try this,

01:31:42.830 --> 01:31:47.830
is I got them to scream
in pain and moan in pain

01:31:48.770 --> 01:31:52.453
whenever they were kicked or contacted.

01:31:53.430 --> 01:31:56.053
And I did that experiment
to see how I would feel.

01:31:57.110 --> 01:31:58.840
I meant to do like a YouTube video on it,

01:31:58.840 --> 01:32:00.400
but then it just seemed very cruel.

01:32:00.400 --> 01:32:02.420
- Did any Roomba rights
activists come at you?

01:32:02.420 --> 01:32:07.420
- Like I think if I released that video,

01:32:07.660 --> 01:32:09.730
I think it's going to make me look insane,

01:32:09.730 --> 01:32:12.780
which I know people
know I'm already insane-

01:32:12.780 --> 01:32:13.866
- Now, you have to release the video.

01:32:13.866 --> 01:32:14.699
[Lex laughing]

01:32:14.699 --> 01:32:15.532
- Sure.

01:32:15.532 --> 01:32:18.330
Well, I think maybe if I contextualize it

01:32:18.330 --> 01:32:20.420
by showing other robots

01:32:20.420 --> 01:32:23.240
like to show why this is fascinating,

01:32:23.240 --> 01:32:24.340
because ultimately,

01:32:24.340 --> 01:32:27.400
I felt like there were
human almost immediately.

01:32:27.400 --> 01:32:30.380
And that display of
pain was what did that.

01:32:30.380 --> 01:32:31.530
- Giving them a voice.

01:32:31.530 --> 01:32:32.400
- Giving them a voice,

01:32:32.400 --> 01:32:37.210
especially a voice of dislike, of pain.

01:32:37.210 --> 01:32:39.250
- I have to connect you
to my friend Eddie Chang,

01:32:39.250 --> 01:32:41.400
he studied speech and
language, he's a neurosurgeon,

01:32:41.400 --> 01:32:43.790
and we're life-long friends.

01:32:43.790 --> 01:32:46.390
He studied speech and language,

01:32:46.390 --> 01:32:50.190
but he describes some
of these more primitive,

01:32:50.190 --> 01:32:55.190
visceral vocalizations, cries,
groans, moans of delight,

01:32:56.470 --> 01:32:58.990
other sounds as well,
use your imagination,

01:32:58.990 --> 01:33:02.870
as such powerful rudders for the other,

01:33:02.870 --> 01:33:04.143
for the emotions of other people.

01:33:04.143 --> 01:33:06.120
And so, I find it fascinating,

01:33:06.120 --> 01:33:07.610
I can't wait to see this video.

01:33:07.610 --> 01:33:09.520
So, is the video available online?

01:33:09.520 --> 01:33:12.080
- No, I haven't recorded it,

01:33:12.080 --> 01:33:13.710
I just hit a bunch of Roombas

01:33:13.710 --> 01:33:18.252
that are able to scream in
pain in my Boston place.

01:33:18.252 --> 01:33:19.410
[Andrew laughing]

01:33:19.410 --> 01:33:22.370
So, like people already-

01:33:22.370 --> 01:33:24.870
- Next podcast episode with Lex,

01:33:24.870 --> 01:33:26.800
maybe we'll have that one, who knows?

01:33:26.800 --> 01:33:28.280
- So, the thing is like people,

01:33:28.280 --> 01:33:31.010
I've noticed because I
talk so much about love

01:33:31.010 --> 01:33:32.410
and it's really who I am,

01:33:32.410 --> 01:33:34.164
I think they want to,

01:33:34.164 --> 01:33:35.720
to a lot of people,

01:33:35.720 --> 01:33:38.570
seems like there's there
got to be a dark person

01:33:38.570 --> 01:33:39.480
in there somewhere.

01:33:39.480 --> 01:33:41.930
And I thought if I release
videos of Roombas screaming

01:33:41.930 --> 01:33:44.590
and they're like, yep, yep,
that guy's definitely insane.

01:33:44.590 --> 01:33:47.810
- What about like shouts
of glee and delight,

01:33:47.810 --> 01:33:48.780
you could do that too, right?

01:33:48.780 --> 01:33:51.670
- Well, I don't know how to,

01:33:51.670 --> 01:33:54.850
to me, delight is quiet, right?

01:33:54.850 --> 01:33:56.325
- You're a Russian.

01:33:56.325 --> 01:33:59.890
Americans are much louder than Russians.

01:33:59.890 --> 01:34:00.723
- Yeah.
- Yeah.

01:34:00.723 --> 01:34:01.556
- Yeah.

01:34:01.556 --> 01:34:04.370
But like I don't, unless
you're talking about like,

01:34:04.370 --> 01:34:05.203
I don't know

01:34:05.203 --> 01:34:07.120
how you would have sexual
relationships with the Roomba.

01:34:07.120 --> 01:34:10.082
- Well, I wasn't necessarily
saying a sexual delight, but-

01:34:10.082 --> 01:34:11.356
- Trust me, I tried.

01:34:11.356 --> 01:34:14.130
I'm just kidding, that's a joke, internet.

01:34:14.130 --> 01:34:14.963
Okay [giggles]

01:34:14.963 --> 01:34:16.810
but I was fascinated in the psychology

01:34:16.810 --> 01:34:17.750
of how little it took.

01:34:17.750 --> 01:34:18.730
'Cause you mentioned

01:34:18.730 --> 01:34:21.521
you had a negative
relationship with a Roomba.

01:34:21.521 --> 01:34:24.930
- Well, I'd find that mostly,
I took it for granted.

01:34:24.930 --> 01:34:25.763
- Yeah.

01:34:25.763 --> 01:34:27.580
- It just served me, it
collected Costello's hair.

01:34:27.580 --> 01:34:29.230
And then when it would do
something I didn't like,

01:34:29.230 --> 01:34:30.270
I would get upset with it.

01:34:30.270 --> 01:34:33.410
So, that's not a good relationship,
it was taken for granted

01:34:33.410 --> 01:34:36.090
and I would get upset and
then I'd park it again,

01:34:36.090 --> 01:34:39.060
and I just like you're in the corner.

01:34:39.060 --> 01:34:39.893
- Yeah.

01:34:39.893 --> 01:34:44.893
- But there's a way to
frame it being quite dumb

01:34:45.410 --> 01:34:47.720
as almost cute.

01:34:47.720 --> 01:34:51.160
You're almost connecting
with it for its dumbness.

01:34:51.160 --> 01:34:54.752
And I think that's artificial
intelligence problem.

01:34:54.752 --> 01:34:55.585
- [Andrew] It's interesting.

01:34:55.585 --> 01:34:59.330
- I think flaws should
be feature, not a bug.

01:34:59.330 --> 01:35:01.180
- So, along the lines of this,

01:35:01.180 --> 01:35:02.590
the different sorts of relationships

01:35:02.590 --> 01:35:03.607
that one could have with robots,

01:35:03.607 --> 01:35:06.940
and the fear, but also some
of the positive relationships

01:35:06.940 --> 01:35:07.940
that one could have,

01:35:08.930 --> 01:35:12.440
there's so much dimensionality,
there's so much to explore.

01:35:12.440 --> 01:35:16.340
But power dynamics in
relationships are very interesting,

01:35:16.340 --> 01:35:18.822
because the obvious ones,

01:35:18.822 --> 01:35:21.040
the unsophisticated view of this,

01:35:21.040 --> 01:35:25.070
is one, there's a master
and a servant, right?

01:35:25.070 --> 01:35:27.840
But there's also manipulation,

01:35:27.840 --> 01:35:29.853
there's benevolent manipulation,

01:35:30.860 --> 01:35:33.160
children do this with
parents, puppies do this.

01:35:33.160 --> 01:35:34.960
Puppies turn their head and look cute

01:35:34.960 --> 01:35:37.600
and maybe give out a little noise,

01:35:37.600 --> 01:35:41.580
kids coup and parents always
think that they're doing this

01:35:41.580 --> 01:35:45.010
because they love the parent,

01:35:45.010 --> 01:35:46.580
but in many ways,

01:35:46.580 --> 01:35:48.500
studies show that those coups are ways

01:35:48.500 --> 01:35:50.860
to extract the sorts of
behaviors and expressions

01:35:50.860 --> 01:35:51.850
from the parent that they want.

01:35:51.850 --> 01:35:53.200
The child doesn't know it's doing this,

01:35:53.200 --> 01:35:54.290
it's completely subconscious,

01:35:54.290 --> 01:35:56.500
but it's benevolent manipulation.

01:35:56.500 --> 01:35:59.750
So, there's one version of fear of robots

01:35:59.750 --> 01:36:01.043
that I hear a lot about

01:36:01.043 --> 01:36:02.750
that I think most people can relate to

01:36:02.750 --> 01:36:04.570
where the robots take over

01:36:04.570 --> 01:36:07.320
and they become the masters
and we become the servants.

01:36:08.200 --> 01:36:10.040
But there could be another version

01:36:10.040 --> 01:36:13.680
that in certain communities

01:36:13.680 --> 01:36:15.170
that I'm certainly not a part of,

01:36:15.170 --> 01:36:17.250
but they call topping from the bottom,

01:36:17.250 --> 01:36:20.840
where the robot is
actually manipulating you

01:36:20.840 --> 01:36:22.390
into doing things,

01:36:22.390 --> 01:36:26.780
but you are under the belief
that you are in charge,

01:36:26.780 --> 01:36:29.240
but actually they're in charge.

01:36:29.240 --> 01:36:31.000
And so, I think that's one

01:36:31.000 --> 01:36:34.560
that if we could explore
that for a second,

01:36:34.560 --> 01:36:37.190
you could imagine it
wouldn't necessarily be bad,

01:36:37.190 --> 01:36:39.113
although it could lead to bad things.

01:36:40.170 --> 01:36:41.120
The reason I want to explore this,

01:36:41.120 --> 01:36:44.330
is I think people always
default to the extreme,

01:36:44.330 --> 01:36:47.070
like the robots take over and
we're in little jail cells

01:36:47.070 --> 01:36:50.354
and they're out having fun
and ruling the universe.

01:36:50.354 --> 01:36:53.050
What sorts of manipulation

01:36:53.050 --> 01:36:56.550
can a robot potentially
carry out, good or bad?

01:36:56.550 --> 01:36:57.383
- Yeah.

01:36:57.383 --> 01:36:59.830
Just so, there's a lot of
good and bad manipulation

01:36:59.830 --> 01:37:00.810
between humans, right?

01:37:00.810 --> 01:37:01.933
Just like you said.

01:37:03.354 --> 01:37:04.440
[Lex sighing]

01:37:04.440 --> 01:37:09.440
To me [sighing] especially
like you said [giggles]

01:37:09.970 --> 01:37:11.700
topping from the bottom, is that the term?

01:37:11.700 --> 01:37:14.551
- I think someone from
MIT told me that term.

01:37:14.551 --> 01:37:15.815
[Lex laughing]

01:37:15.815 --> 01:37:16.648
It wasn't Lex.

01:37:17.860 --> 01:37:18.693
- I think.

01:37:18.693 --> 01:37:22.080
So, first of all, there's
power dynamics in bed,

01:37:22.080 --> 01:37:24.250
and power dynamics in relationships,

01:37:24.250 --> 01:37:25.900
and power dynamics on the street,

01:37:25.900 --> 01:37:28.523
and in the work environment,
those are all very different.

01:37:29.359 --> 01:37:34.359
I think power dynamics can
make human relationships,

01:37:34.780 --> 01:37:39.780
especially romantic relationships
fascinating and rich

01:37:39.880 --> 01:37:42.780
and fulfilling and exciting
and all those kinds of things.

01:37:42.780 --> 01:37:47.780
So, I don't think in
themselves they're bad,

01:37:48.670 --> 01:37:50.860
and the same goes with robots.

01:37:50.860 --> 01:37:52.106
I really love the idea

01:37:52.106 --> 01:37:55.000
that a robot will be at top or a bottom

01:37:55.000 --> 01:37:57.540
in terms of like power dynamics.

01:37:57.540 --> 01:38:00.020
And I think everybody
should be aware of that.

01:38:00.020 --> 01:38:02.490
And the manipulation is
not so much manipulation,

01:38:02.490 --> 01:38:06.740
but a dance of like pulling
away, a push and pull,

01:38:06.740 --> 01:38:08.003
and all those kinds of things.

01:38:08.003 --> 01:38:10.400
In terms of control,

01:38:10.400 --> 01:38:13.950
I think we're very, very,
very far away from AI systems

01:38:13.950 --> 01:38:16.013
that are able to lock us up.

01:38:17.760 --> 01:38:18.893
To lock us up in,

01:38:20.230 --> 01:38:21.670
like to have so much control

01:38:21.670 --> 01:38:25.170
that we basically cannot live our lives

01:38:25.170 --> 01:38:26.950
in the way that we want.

01:38:26.950 --> 01:38:29.730
I think there's a, in terms
of dangers of AI systems,

01:38:29.730 --> 01:38:30.870
there's much more dangers

01:38:30.870 --> 01:38:33.087
that have to do with
autonomous weapon systems

01:38:33.087 --> 01:38:34.280
and all those kinds of things.

01:38:34.280 --> 01:38:37.950
So, the power dynamics as
exercised in the struggle

01:38:37.950 --> 01:38:40.700
between nations and war and
all those kinds of things.

01:38:40.700 --> 01:38:42.813
But in terms of personal relationships,

01:38:43.710 --> 01:38:45.950
I think power dynamics
are a beautiful thing.

01:38:45.950 --> 01:38:47.210
Now, there's of course,

01:38:47.210 --> 01:38:49.610
going to be all those kinds of discussions

01:38:49.610 --> 01:38:52.660
about consent and rights and
all those kinds of things.

01:38:52.660 --> 01:38:54.000
- Well, here, we're talking about,

01:38:54.000 --> 01:38:56.470
I always say in any
discussion around this,

01:38:56.470 --> 01:38:59.210
if we need to define a really the context,

01:38:59.210 --> 01:39:03.320
it always should be
consensual, age-appropriate,

01:39:03.320 --> 01:39:06.110
context-appropriate, species-appropriate,

01:39:06.110 --> 01:39:09.250
but now we're talking about
human-robot interactions.

01:39:09.250 --> 01:39:10.820
And so, I guess that-

01:39:10.820 --> 01:39:13.660
- No, I actually was trying
to make a different point,

01:39:13.660 --> 01:39:15.020
which is I do believe

01:39:15.020 --> 01:39:17.880
that robots will have
rights down the line.

01:39:17.880 --> 01:39:20.860
And I think in order for us

01:39:20.860 --> 01:39:23.100
to have deep, meaningful
relationships with robots,

01:39:23.100 --> 01:39:26.580
we would have to consider
them as entities in themselves

01:39:26.580 --> 01:39:28.423
that deserve respect.

01:39:29.770 --> 01:39:31.277
And that's a really interesting concept

01:39:31.277 --> 01:39:34.380
that I think people are
starting to talk about

01:39:34.380 --> 01:39:35.520
a little bit more,

01:39:35.520 --> 01:39:37.660
but it's very difficult
for us to understand

01:39:37.660 --> 01:39:39.750
how entities that are other than human.

01:39:39.750 --> 01:39:42.510
I mean, the same as with
dogs and other animals

01:39:42.510 --> 01:39:44.940
can have rights on a level as humans.

01:39:44.940 --> 01:39:45.860
- Well, yeah.

01:39:45.860 --> 01:39:49.980
We can't and nor should we do
whatever we want with animals,

01:39:49.980 --> 01:39:54.740
we have a USDA, we have
Department of Agriculture

01:39:54.740 --> 01:39:59.050
that deal with animal care and
use committees for research,

01:39:59.050 --> 01:40:02.110
for farming and ranching and all that.

01:40:02.110 --> 01:40:05.940
So, when you first said it,
I thought, wait, why would,

01:40:05.940 --> 01:40:07.410
there'll be a bill of robotic rights,

01:40:07.410 --> 01:40:08.833
but it absolutely makes sense

01:40:08.833 --> 01:40:12.230
in the context of everything
we've been talking about

01:40:12.230 --> 01:40:13.143
up until now.

01:40:15.293 --> 01:40:18.740
If you're willing, I'd
love to talk about dogs,

01:40:18.740 --> 01:40:21.310
because you've mentioned
dogs a couple of times,

01:40:21.310 --> 01:40:26.080
a robot dog, you had a biological dog.

01:40:26.080 --> 01:40:26.913
Yeah.
- Yeah.

01:40:26.913 --> 01:40:31.540
I had a Newfoundland named
Homer for many years growing up.

01:40:34.270 --> 01:40:35.640
- In Russia or in the U.S.?

01:40:35.640 --> 01:40:37.330
- In the United States.

01:40:37.330 --> 01:40:40.970
And he was about, he's over
200 pounds, that's a big dog.

01:40:40.970 --> 01:40:42.040
- That's a big dog.

01:40:42.040 --> 01:40:43.760
- People know Newfoundland.

01:40:43.760 --> 01:40:48.620
So, he's this black dog
that's a really a long hair

01:40:48.620 --> 01:40:50.500
and just a kind soul.

01:40:50.500 --> 01:40:53.270
I think perhaps that's
true for a lot of large,

01:40:53.270 --> 01:40:55.230
but he thought he was a small dog.

01:40:55.230 --> 01:40:56.520
So, he moved like that, and-

01:40:56.520 --> 01:40:57.430
- Was he your dog?

01:40:57.430 --> 01:40:58.263
- Yeah, yeah.

01:40:58.263 --> 01:41:00.890
- So, you had him since
he was fairly young?

01:41:00.890 --> 01:41:03.810
- Since the very, very beginning,
till the very, very end.

01:41:03.810 --> 01:41:08.660
And one of the things, I
mean, he had this kind of a,

01:41:08.660 --> 01:41:11.330
we mentioned like the Roombas,

01:41:11.330 --> 01:41:15.156
he had kind-hearted dumbness about him

01:41:15.156 --> 01:41:16.710
that was just overwhelming,

01:41:16.710 --> 01:41:20.060
it's part of the reason I named him Homer,

01:41:20.060 --> 01:41:22.520
because it's after Homer Simpson,

01:41:22.520 --> 01:41:25.423
in case people are wondering
which Homer I'm referring to.

01:41:27.041 --> 01:41:27.874
[Andrew laughing]

01:41:27.874 --> 01:41:28.970
And so, there's a.

01:41:28.970 --> 01:41:30.923
Yeah, exactly.

01:41:32.330 --> 01:41:35.240
There's a clumsiness
that was just something

01:41:35.240 --> 01:41:37.685
that immediately led to a
deep love for each other.

01:41:37.685 --> 01:41:39.323
And one of the,

01:41:40.685 --> 01:41:43.370
I mean, he was always,
it's the shared moments,

01:41:43.370 --> 01:41:46.550
he was always there for
so many a nights together,

01:41:46.550 --> 01:41:48.640
that's a powerful thing about a dog

01:41:48.640 --> 01:41:52.350
that he was there through
all the loneliness,

01:41:52.350 --> 01:41:54.440
through all the tough
times, through the successes

01:41:54.440 --> 01:41:55.870
and all those kinds of things.

01:41:55.870 --> 01:41:56.703
And I remember,

01:41:57.550 --> 01:42:00.150
I mean, that was a really
moving moment for me,

01:42:00.150 --> 01:42:02.190
I still miss him to this day.

01:42:02.190 --> 01:42:03.490
- How long ago did he die?

01:42:05.400 --> 01:42:07.100
- Maybe 15 years ago.

01:42:07.100 --> 01:42:09.170
So, it's been awhile.

01:42:09.170 --> 01:42:11.964
But it was the first time

01:42:11.964 --> 01:42:15.723
I've really experienced
like the feeling of death.

01:42:17.010 --> 01:42:22.010
So, what happened, is he got a cancer.

01:42:22.870 --> 01:42:26.060
And so, he was dying slowly.

01:42:26.060 --> 01:42:29.396
And then there's a certain point
he couldn't get up anymore.

01:42:29.396 --> 01:42:31.796
Now, there's a lot of
things that could say here

01:42:32.710 --> 01:42:34.184
that I struggle with.

01:42:34.184 --> 01:42:39.120
Maybe he suffered much
longer than he needed to,

01:42:39.120 --> 01:42:42.080
that's something I
really think about a lot.

01:42:42.080 --> 01:42:47.080
But I remember when I had
to take him to the hospital

01:42:47.200 --> 01:42:52.200
and the nurses couldn't carry him, right?

01:42:52.350 --> 01:42:54.120
So, you're talking about a 200 pound dog

01:42:54.120 --> 01:42:56.730
and I was really into
power lifting at the time.

01:42:56.730 --> 01:42:59.390
And I remember they tried to figure out

01:42:59.390 --> 01:43:02.015
all these kinds of ways to.

01:43:02.015 --> 01:43:03.620
So, in order to put them to sleep,

01:43:03.620 --> 01:43:07.270
they had to take them into a room.

01:43:07.270 --> 01:43:09.540
And so, I had to carry him everywhere.

01:43:09.540 --> 01:43:14.540
And here's this dying friend
of mine that I just had to,

01:43:15.260 --> 01:43:17.020
first of all, that was
really difficult to carry,

01:43:17.020 --> 01:43:19.791
somebody that heavy when
they're not helping you out.

01:43:19.791 --> 01:43:22.760
And, yeah.

01:43:22.760 --> 01:43:25.960
So, I remember it was the first time

01:43:25.960 --> 01:43:28.470
seeing a friend laying there

01:43:28.470 --> 01:43:33.073
and seeing life drain from his body.

01:43:34.138 --> 01:43:38.390
And that realization that
we're here for a short time

01:43:38.390 --> 01:43:40.590
was made so real,

01:43:40.590 --> 01:43:43.750
that here is friend that was
there for me the week before,

01:43:43.750 --> 01:43:46.270
the day before, and now he's gone.

01:43:46.270 --> 01:43:47.103
And that was,

01:43:48.500 --> 01:43:50.800
I don't know, that spoke to the fact

01:43:50.800 --> 01:43:53.303
that he could be deeply
connected with the dog.

01:43:54.560 --> 01:43:59.560
Also spoke to the fact that
the shared moments together

01:44:00.860 --> 01:44:05.860
that led to that deep friendship
will make life so amazing,

01:44:08.560 --> 01:44:11.733
but it also spoke to the fact
that death is a motherfucker.

01:44:13.440 --> 01:44:15.870
So, I know you've lost Costello recently.

01:44:15.870 --> 01:44:16.872
- Yeah.

01:44:16.872 --> 01:44:17.705
- And you can-
- And as you're saying this,

01:44:17.705 --> 01:44:20.090
I'm definitely fighting back the tears.

01:44:20.090 --> 01:44:23.360
I thank you for sharing that.

01:44:23.360 --> 01:44:26.190
That I guess we're about to both cry over,

01:44:26.190 --> 01:44:28.690
I don't want to say dogs [laughing]

01:44:28.690 --> 01:44:30.340
that it was bound to happen

01:44:30.340 --> 01:44:32.653
just given when this is happening.

01:44:33.530 --> 01:44:35.266
Yeah, it's-

01:44:35.266 --> 01:44:38.533
- How long did you know that
Costello was not doing well?

01:44:39.700 --> 01:44:44.310
- We'll, let's see, a year
ago during the start of,

01:44:44.310 --> 01:44:46.480
about six months into the pandemic,

01:44:46.480 --> 01:44:49.110
he started getting
abscesses and he was not,

01:44:49.110 --> 01:44:51.620
his behavior change and
something really changed.

01:44:51.620 --> 01:44:56.090
And then I put him on testosterone

01:44:56.090 --> 01:44:58.140
which helped a lot of things.

01:44:58.140 --> 01:44:59.330
It certainly didn't cure everything,

01:44:59.330 --> 01:45:00.660
but it helped a lot of things,

01:45:00.660 --> 01:45:03.920
he was dealing with
joint pain, sleep issues,

01:45:03.920 --> 01:45:07.780
and then it just became
a very slow decline

01:45:08.910 --> 01:45:11.410
to the point where two, three weeks ago,

01:45:11.410 --> 01:45:15.370
he had a closet full of medication.

01:45:15.370 --> 01:45:17.390
I mean, this dog was,
it was like a pharmacy.

01:45:17.390 --> 01:45:19.600
It's amazing to me when I
looked at it the other day,

01:45:19.600 --> 01:45:22.120
I still haven't cleaned up
and removed all those things,

01:45:22.120 --> 01:45:24.520
'cause I can't quite bring
myself to do it, but-

01:45:25.961 --> 01:45:27.510
- Do you think he was suffering?

01:45:27.510 --> 01:45:30.330
- Well, so, what happened,
was about a week ago,

01:45:30.330 --> 01:45:32.163
it was really just about
a week ago, it's amazing.

01:45:32.163 --> 01:45:35.080
He was going up the
stairs, I saw him slip.

01:45:35.080 --> 01:45:35.913
And he was a big guy,

01:45:35.913 --> 01:45:37.860
he wasn't 200 pounds, but
he was about 90 pounds,

01:45:37.860 --> 01:45:40.310
he's a bulldog, he was
pretty big and he was fit.

01:45:41.240 --> 01:45:42.073
And then I noticed

01:45:42.073 --> 01:45:44.450
that he wasn't carrying a foot in the back

01:45:44.450 --> 01:45:46.440
like it was injured, it
had no feeling at all.

01:45:46.440 --> 01:45:48.920
He never liked me to touch
his hind paws, and I could do,

01:45:48.920 --> 01:45:50.520
that thing was just flopping there.

01:45:50.520 --> 01:45:53.890
And then the vet found
some spinal degeneration

01:45:53.890 --> 01:45:55.760
and I was told that the next one would go.

01:45:55.760 --> 01:45:56.863
Did he suffer?

01:45:56.863 --> 01:46:00.960
Sure, hope not, but something
changed in his eyes.

01:46:00.960 --> 01:46:02.840
- Yeah.
- Yeah, it's the eyes again,

01:46:02.840 --> 01:46:05.160
I know you and I spend
long hours on the phone

01:46:05.160 --> 01:46:06.410
and tell you about like the eyes

01:46:06.410 --> 01:46:08.050
and what they convey and what they mean

01:46:08.050 --> 01:46:09.230
about internal states

01:46:09.230 --> 01:46:12.797
and for sake of robots and
biology of other kinds, but-

01:46:12.797 --> 01:46:17.797
- You think something about
him was gone in his eyes?

01:46:17.920 --> 01:46:20.660
- I think he was real,

01:46:20.660 --> 01:46:22.513
here, I am anthropomorphizing,

01:46:22.513 --> 01:46:26.870
I think he was realizing that
one of his great joys in life,

01:46:26.870 --> 01:46:31.870
which was to walk and
sniff and pee on things.

01:46:32.167 --> 01:46:33.150
[Lex laughing]

01:46:33.150 --> 01:46:33.983
This dog.

01:46:33.983 --> 01:46:36.057
- The fundamental.
- Loved to pee on things,

01:46:36.057 --> 01:46:36.890
it was amazing.

01:46:36.890 --> 01:46:38.940
I've wondered where he put it,

01:46:38.940 --> 01:46:42.330
he was like a reservoir of
urine, it was incredible.

01:46:42.330 --> 01:46:43.550
I think, oh, that's Eddie,

01:46:43.550 --> 01:46:46.590
he'd put like one drop on
the 50 millionth plant.

01:46:46.590 --> 01:46:49.017
And then we get to the 50
millionth in one plant,

01:46:49.017 --> 01:46:51.260
and he just have, leave a puddle.

01:46:51.260 --> 01:46:53.460
And here I am talking
about Costello peeing.

01:46:54.540 --> 01:46:57.080
He was losing that ability
to stand up and do that,

01:46:57.080 --> 01:46:58.920
he was falling down
while he was doing that.

01:46:58.920 --> 01:47:01.600
And I do think he started to realize.

01:47:01.600 --> 01:47:04.600
And the passage was easy and peaceful,

01:47:04.600 --> 01:47:08.803
but I'll say this, I'm
not ashamed to say it,

01:47:08.803 --> 01:47:11.214
I mean, I wake up every
morning since then just,

01:47:11.214 --> 01:47:13.270
I don't even make the conscious decision

01:47:13.270 --> 01:47:16.110
to allow my self to cry, I wake up crying.

01:47:16.110 --> 01:47:18.200
And I'm unfortunately able
to make it through the day,

01:47:18.200 --> 01:47:20.010
thanks to the great support of my friends

01:47:20.010 --> 01:47:23.847
and you and my family,
but I miss him, man.

01:47:23.847 --> 01:47:24.680
- You miss him?

01:47:24.680 --> 01:47:25.560
- Yeah, I miss him.

01:47:25.560 --> 01:47:29.440
And I feel like, Homer, Costello,

01:47:29.440 --> 01:47:33.090
the relationship to one's
dog is so specific part.

01:47:34.140 --> 01:47:36.093
- So, that part of you is gone?

01:47:37.970 --> 01:47:39.203
- That's the hard thing.

01:47:45.120 --> 01:47:46.980
What I think is different,

01:47:46.980 --> 01:47:49.807
is that I made the mistake, I think.

01:47:49.807 --> 01:47:51.850
Moreover, I hope it was a good decision,

01:47:51.850 --> 01:47:53.300
but sometimes I think I made the mistake

01:47:53.300 --> 01:47:56.520
of I brought Costello a
little bit to the world

01:47:56.520 --> 01:47:59.000
through the podcast or posting about him,

01:47:59.000 --> 01:48:01.580
I anthropomorphized about him in public.

01:48:01.580 --> 01:48:03.730
Let's be honest, I have no
idea what his mental life was,

01:48:03.730 --> 01:48:04.910
or his relationship to me.

01:48:04.910 --> 01:48:06.397
And I'm just exploring all
this for the first time

01:48:06.397 --> 01:48:07.790
'cause he was my first dog,

01:48:07.790 --> 01:48:09.710
but I raised him since he was seven weeks.

01:48:09.710 --> 01:48:11.050
- Yeah, you got hold it together,

01:48:11.050 --> 01:48:14.970
I noticed the episode
you released on Monday,

01:48:14.970 --> 01:48:16.610
you mentioned Costello.

01:48:16.610 --> 01:48:18.950
Like you brought them back to life for me

01:48:18.950 --> 01:48:20.350
for that brief moment.

01:48:20.350 --> 01:48:21.401
- Yeah.

01:48:21.401 --> 01:48:22.420
But he's gone.

01:48:22.420 --> 01:48:23.493
- That's the,

01:48:24.660 --> 01:48:26.963
he's going to be gone
for a lot of people too.

01:48:28.530 --> 01:48:29.860
- Well, this is what I'm struggling with.

01:48:29.860 --> 01:48:33.420
I think that maybe you're
pretty good at this.

01:48:33.420 --> 01:48:36.083
Like, have you done this before?

01:48:36.083 --> 01:48:37.977
[Andrew laughing]

01:48:37.977 --> 01:48:38.810
This is the challenge.

01:48:38.810 --> 01:48:40.600
Is that actually part of me.

01:48:40.600 --> 01:48:42.570
I know how to take care
of myself pretty well.

01:48:42.570 --> 01:48:43.403
- Yeah.

01:48:43.403 --> 01:48:44.760
- Not perfectly, but pretty well.

01:48:44.760 --> 01:48:46.040
And I have good support.

01:48:46.040 --> 01:48:48.810
I do worry a little bit
about how it's going to land

01:48:48.810 --> 01:48:50.230
and how people will feel.

01:48:50.230 --> 01:48:54.121
I'm concerned about their internalization.

01:48:54.121 --> 01:48:56.300
So that's something
I'm still iterating on.

01:48:56.300 --> 01:48:58.400
- And you have to watch you struggle,

01:48:58.400 --> 01:48:59.400
which is fascinating.

01:48:59.400 --> 01:49:00.233
- Right.

01:49:00.233 --> 01:49:01.660
And I've mostly been
shielding them from this,

01:49:01.660 --> 01:49:04.010
but what would make me happiest

01:49:04.010 --> 01:49:06.420
is if people would internalize

01:49:06.420 --> 01:49:08.240
some of Costello's best traits.

01:49:08.240 --> 01:49:13.240
And his best traits were
that he was incredibly tough.

01:49:14.260 --> 01:49:15.840
I mean, he was a,

01:49:15.840 --> 01:49:17.720
22-inch-neck bulldog, the whole thing.

01:49:17.720 --> 01:49:18.999
He was just born that way.

01:49:18.999 --> 01:49:22.420
What was so beautiful
is that his toughness

01:49:22.420 --> 01:49:24.100
has never what he rolled forward.

01:49:24.100 --> 01:49:27.140
It was just how sweet and kind he was.

01:49:27.140 --> 01:49:29.180
And so if people can take that,

01:49:29.180 --> 01:49:33.200
then there's a win in there someplace, so.

01:49:33.200 --> 01:49:34.650
- I think there's some ways

01:49:34.650 --> 01:49:37.607
in which she should probably
live on in your podcast too.

01:49:37.607 --> 01:49:39.100
You should,

01:49:39.100 --> 01:49:40.593
I mean, it's such a,

01:49:41.830 --> 01:49:45.830
one of the things I loved
about his role in your podcast

01:49:45.830 --> 01:49:48.640
is that he brought so much joy to you.

01:49:48.640 --> 01:49:49.925
We mentioned the robots.

01:49:49.925 --> 01:49:50.758
- Mm-hmm.

01:49:50.758 --> 01:49:51.633
- Right?

01:49:51.633 --> 01:49:54.350
I think that's such a powerful thing

01:49:54.350 --> 01:49:56.330
to bring that joy into,

01:49:56.330 --> 01:49:59.420
like, allowing yourself
to experience that joy,

01:49:59.420 --> 01:50:02.480
to bring that joy to others,
to share it with others.

01:50:02.480 --> 01:50:03.850
That's really powerful.

01:50:03.850 --> 01:50:05.640
And I mean, not to,

01:50:05.640 --> 01:50:07.210
this is like the Russian thing,

01:50:07.210 --> 01:50:12.210
is [chuckles] it touched me
when Lucy Kay had that moment

01:50:14.080 --> 01:50:18.000
that I keep thinking about
in this show "Louie,"

01:50:18.000 --> 01:50:20.290
or like an old man was criticizing Louis

01:50:20.290 --> 01:50:22.630
for whining about breaking
up with his girlfriend,

01:50:22.630 --> 01:50:27.630
and he was saying like the most
beautiful thing about love,

01:50:30.460 --> 01:50:32.340
they made a song that's catchy

01:50:32.340 --> 01:50:35.690
now that's now making me
feel horrible saying it,

01:50:35.690 --> 01:50:37.740
but like, is the loss.

01:50:37.740 --> 01:50:41.260
The loss really also is making you realize

01:50:41.260 --> 01:50:44.490
how much that person,

01:50:44.490 --> 01:50:46.370
that dog meant to you.

01:50:46.370 --> 01:50:48.740
And like allowing
yourself to feel that loss

01:50:48.740 --> 01:50:51.450
and not run away from that
loss is really powerful.

01:50:51.450 --> 01:50:55.100
And in some ways that's also sweet,

01:50:55.100 --> 01:50:57.735
just like the love was
the loss is also sweet

01:50:57.735 --> 01:51:02.085
because you know that
you felt a lot for that

01:51:02.085 --> 01:51:03.810
through your friend.

01:51:03.810 --> 01:51:06.812
So I, and like continue to bring that joy.

01:51:06.812 --> 01:51:09.433
I think it would be
amazing to the podcast.

01:51:10.435 --> 01:51:13.710
I hope to do the same
with [laughing] robots,

01:51:13.710 --> 01:51:16.143
or whatever else is the
source of joy, right?

01:51:17.750 --> 01:51:22.490
And maybe, do you think about
one day getting another dog?

01:51:22.490 --> 01:51:23.653
- Yeah, in time.

01:51:25.060 --> 01:51:27.513
You're hitting on all
the key buttons here.

01:51:28.610 --> 01:51:30.090
I want that to,

01:51:30.090 --> 01:51:34.780
we're thinking about ways to
kind of immortalize Costello

01:51:34.780 --> 01:51:35.660
in a way that's real,

01:51:35.660 --> 01:51:39.950
not just creating some little
logo or something silly.

01:51:39.950 --> 01:51:43.880
Costello much like David
Goggins is a person,

01:51:43.880 --> 01:51:47.190
but Goggins also has
grown into kind of a verb.

01:51:47.190 --> 01:51:48.870
You're going to Goggins
this or you're going to,

01:51:48.870 --> 01:51:50.150
and there's an adjective.

01:51:50.150 --> 01:51:51.060
Like that's extreme.

01:51:51.060 --> 01:51:52.460
Like it,

01:51:52.460 --> 01:51:54.490
I think that for me, Costello
was all those things.

01:51:54.490 --> 01:51:56.850
He was a being, he was his own being,

01:51:56.850 --> 01:52:00.380
he was a noun, a verb and an adjective.

01:52:00.380 --> 01:52:02.470
So, and he had this amazing super power

01:52:02.470 --> 01:52:03.340
that I wish I could get,

01:52:03.340 --> 01:52:05.090
which is this ability to get everyone else

01:52:05.090 --> 01:52:07.893
to do things for you
without doing a thing.

01:52:07.893 --> 01:52:08.726
[Lex laughing]

01:52:08.726 --> 01:52:09.830
The Costello effect,

01:52:09.830 --> 01:52:10.663
as I call it.

01:52:10.663 --> 01:52:12.290
- So is an idea I hope he lives on.

01:52:12.290 --> 01:52:13.810
- Yes.

01:52:13.810 --> 01:52:14.643
Thank you for that.

01:52:14.643 --> 01:52:16.870
This actually has been
very therapeutic for me,

01:52:18.100 --> 01:52:22.380
which actually brings me to a question,

01:52:22.380 --> 01:52:25.870
we're friends, we're
not just co-scientists,

01:52:25.870 --> 01:52:28.220
colleagues working on a project together

01:52:28.220 --> 01:52:31.323
and in the world,

01:52:33.330 --> 01:52:34.800
that's somewhat similar.

01:52:34.800 --> 01:52:37.230
- Just two dogs.

01:52:37.230 --> 01:52:39.133
- Just two dogs basically.

01:52:40.570 --> 01:52:42.803
But let's talk about friendship,

01:52:44.260 --> 01:52:49.190
because I think that I
certainly know as a scientist

01:52:49.190 --> 01:52:51.150
that there are elements
that are very lonely

01:52:51.150 --> 01:52:52.780
of the scientific pursuit.

01:52:52.780 --> 01:52:57.030
There are elements of many
pursuits that are lonely.

01:52:57.030 --> 01:52:58.350
Music,

01:52:58.350 --> 01:53:00.760
Math always seem to me like they're like

01:53:00.760 --> 01:53:02.125
the loneliest people.

01:53:02.125 --> 01:53:03.657
Who knows if that's true or not.

01:53:03.657 --> 01:53:05.410
Also people work in teams.

01:53:05.410 --> 01:53:06.630
And sometimes people are surrounded

01:53:06.630 --> 01:53:09.330
by people interacting with
people and they feel very lonely.

01:53:09.330 --> 01:53:14.330
But for me, and I think as well for you,

01:53:14.470 --> 01:53:17.960
friendship is an incredibly strong force

01:53:17.960 --> 01:53:22.960
in making one feel like
certain things are possible

01:53:23.560 --> 01:53:25.820
or worth reaching for,

01:53:25.820 --> 01:53:28.250
maybe even making us
compulsively reach for them.

01:53:28.250 --> 01:53:30.750
So, when you were growing up,

01:53:30.750 --> 01:53:32.820
you grew up in Russia until what age?

01:53:32.820 --> 01:53:33.730
- 13.

01:53:33.730 --> 01:53:34.563
- Okay.

01:53:34.563 --> 01:53:38.320
And then you moved
directly to Philadelphia?

01:53:38.320 --> 01:53:39.330
- To Chicago.

01:53:39.330 --> 01:53:40.163
- [Andrew] Chicago.

01:53:40.163 --> 01:53:41.593
- And then Philadelphia,

01:53:42.430 --> 01:53:45.060
and San Francisco and Boston and so on.

01:53:45.060 --> 01:53:48.480
But really to Chicago, that's
where I went to high school.

01:53:48.480 --> 01:53:49.880
- Do you have siblings?

01:53:49.880 --> 01:53:50.730
- Older brother.

01:53:50.730 --> 01:53:51.851
- But most people don't know that.

01:53:51.851 --> 01:53:53.870
[Lex laughing]

01:53:53.870 --> 01:53:58.010
- Yeah, he is a very different person.

01:53:58.010 --> 01:53:59.640
But somebody I definitely look up to.

01:53:59.640 --> 01:54:00.810
So he's a wild man.

01:54:00.810 --> 01:54:01.860
He's extrovert,

01:54:01.860 --> 01:54:05.060
he was into, I mean,

01:54:05.060 --> 01:54:07.580
so he's also scientists, a bio engineer,

01:54:07.580 --> 01:54:09.826
but he's, when we were growing up,

01:54:09.826 --> 01:54:14.826
he was the person who did,

01:54:14.910 --> 01:54:16.920
drank and did every drug.

01:54:16.920 --> 01:54:19.400
And, but also as the life of the party.

01:54:19.400 --> 01:54:21.120
And I just thought he was the,

01:54:21.120 --> 01:54:23.480
when your older brother, five years older,

01:54:23.480 --> 01:54:28.340
he was the coolest person
that I was wanting to be him.

01:54:28.340 --> 01:54:29.920
So for that,

01:54:29.920 --> 01:54:31.230
he definitely had a big influence.

01:54:31.230 --> 01:54:35.926
But I think for me in terms
of friendship, growing up,

01:54:35.926 --> 01:54:40.090
I had one really close friend.

01:54:40.090 --> 01:54:42.330
And then when I came here
I had another close friend,

01:54:42.330 --> 01:54:43.283
but I'm very,

01:54:44.360 --> 01:54:45.283
I believe,

01:54:46.255 --> 01:54:47.560
I don't know if I believe,

01:54:47.560 --> 01:54:52.560
but I draw a lot of strength
from deep connections

01:54:53.060 --> 01:54:56.200
with other people,

01:54:56.200 --> 01:54:57.780
and just the small number of people.

01:54:57.780 --> 01:54:59.090
Just a really small number of people.

01:54:59.090 --> 01:55:00.530
That's when I moved to this country,

01:55:00.530 --> 01:55:02.290
I was really surprised how,

01:55:02.290 --> 01:55:03.366
like, there were

01:55:03.366 --> 01:55:08.330
these large groups of
friends, quote, unquote.

01:55:08.330 --> 01:55:12.280
But the depth of connection
was not there at all

01:55:12.280 --> 01:55:14.300
from my sort of perspective.

01:55:14.300 --> 01:55:17.740
Now, I moved to the suburb
of Chicago, was Naperville.

01:55:17.740 --> 01:55:21.010
It's more like a middle class,
maybe upper middle class.

01:55:21.010 --> 01:55:23.580
So it's like people that cared more

01:55:23.580 --> 01:55:26.510
about material possessions
than deep human connection.

01:55:26.510 --> 01:55:28.440
So that added to the thing.

01:55:28.440 --> 01:55:33.440
But I drove more meaning
than almost anything else

01:55:34.050 --> 01:55:35.050
was from friendship.

01:55:35.050 --> 01:55:37.220
Early on I had a best friend.

01:55:37.220 --> 01:55:38.410
His name was,

01:55:38.410 --> 01:55:40.223
his name is Yura.

01:55:41.121 --> 01:55:43.470
I don't know how to say it in English.

01:55:43.470 --> 01:55:44.720
- How do you say in Russian?

01:55:44.720 --> 01:55:45.553
- Yura.

01:55:45.553 --> 01:55:46.470
What's his last name?

01:55:46.470 --> 01:55:47.473
Do you remember if was...

01:55:47.473 --> 01:55:48.930
[Lex chuckles]

01:55:48.930 --> 01:55:49.763
- Mikolov.

01:55:50.928 --> 01:55:51.773
Yura Mikolov.

01:55:53.750 --> 01:55:56.370
So we just spent all our time together.

01:55:56.370 --> 01:55:58.510
There's also a group of friends.

01:55:58.510 --> 01:55:59.611
Like, I dunno, it's like eight guys.

01:55:59.611 --> 01:56:04.023
In Russia growing up,

01:56:04.870 --> 01:56:07.510
it's like parents didn't care

01:56:07.510 --> 01:56:09.700
if you're coming back at certain hour.

01:56:09.700 --> 01:56:13.380
So we'll spent all day, all
night just playing soccer,

01:56:13.380 --> 01:56:14.933
usually called football,

01:56:16.006 --> 01:56:18.940
and just talking about life
and all those kinds of things,

01:56:18.940 --> 01:56:20.820
even at that young age.

01:56:20.820 --> 01:56:22.740
I think people in Russia

01:56:22.740 --> 01:56:25.234
and Soviet Union grew up much quicker.

01:56:25.234 --> 01:56:26.536
[Lex chuckles]

01:56:26.536 --> 01:56:30.930
I think the education system
at the university level

01:56:30.930 --> 01:56:34.590
is world-class in the United
States in terms of like,

01:56:34.590 --> 01:56:38.980
really creating really
big, powerful minds.

01:56:38.980 --> 01:56:40.090
At least they used to be,

01:56:40.090 --> 01:56:41.715
but I think that they aspire to that.

01:56:41.715 --> 01:56:44.810
But the education system for like,

01:56:44.810 --> 01:56:49.070
for younger kids in the
Soviet Union was incredible.

01:56:49.070 --> 01:56:51.127
Like they did not treat us as kids.

01:56:51.127 --> 01:56:54.798
The level of literature,
Tolstoy, Dostoevsky.

01:56:54.798 --> 01:56:56.000
- When you were a small child?

01:56:56.000 --> 01:56:56.926
- Yeah.

01:56:56.926 --> 01:56:57.759
- Amazing.

01:56:57.759 --> 01:56:58.592
Amazing.

01:56:58.592 --> 01:57:00.440
- And like the level of mathematics,

01:57:00.440 --> 01:57:02.110
and you're made to feel like shit

01:57:02.110 --> 01:57:03.810
if you're not good at mathematics.

01:57:03.810 --> 01:57:06.460
Like we, I think in this country,

01:57:06.460 --> 01:57:07.400
there's more like,

01:57:07.400 --> 01:57:08.240
especially young kids

01:57:08.240 --> 01:57:09.740
'cause they're so cute.

01:57:09.740 --> 01:57:11.533
Like they're being babied.

01:57:12.380 --> 01:57:15.280
We only start to really
push adults later in life.

01:57:15.280 --> 01:57:17.890
Like, so if you want to be
the best in the world at this,

01:57:17.890 --> 01:57:19.510
then you get to be pushed.

01:57:19.510 --> 01:57:21.810
But we were pushed at a young age.

01:57:21.810 --> 01:57:22.950
Everybody was pushed.

01:57:22.950 --> 01:57:25.060
And that brought out the best in people.

01:57:25.060 --> 01:57:29.060
I think it really forced
people to discover,

01:57:29.060 --> 01:57:31.890
like discover themselves
in the Goggin style,

01:57:31.890 --> 01:57:34.983
but also discover what they're
actually passionate about,

01:57:34.983 --> 01:57:35.816
what they're not.

01:57:35.816 --> 01:57:37.490
- Is this true for boys and girls?

01:57:37.490 --> 01:57:39.010
Were they pushed equally there?

01:57:39.010 --> 01:57:39.843
- Yeah.

01:57:39.843 --> 01:57:40.676
They were pushed.

01:57:40.676 --> 01:57:41.990
Yeah, they were pushed
equally, I would say.

01:57:41.990 --> 01:57:43.030
There was a,

01:57:43.030 --> 01:57:44.930
obviously there was more,

01:57:44.930 --> 01:57:45.763
not obviously,

01:57:45.763 --> 01:57:48.630
but at least from my memories,

01:57:48.630 --> 01:57:49.483
more of a,

01:57:50.400 --> 01:57:51.725
what's the right way to put it?

01:57:51.725 --> 01:57:53.910
But there was like gender roles,

01:57:53.910 --> 01:57:56.650
but not in a negative connotation.

01:57:56.650 --> 01:57:59.520
It was the red dress
versus the suit and tie

01:57:59.520 --> 01:58:01.600
kind of connotation, which is like,

01:58:01.600 --> 01:58:02.873
there's a,

01:58:04.630 --> 01:58:08.070
like guys like lifting heavy things

01:58:08.070 --> 01:58:11.540
and girls like creating beautiful art,

01:58:11.540 --> 01:58:14.053
and, like there's-

01:58:14.053 --> 01:58:15.733
- A more traditional view of gender,

01:58:15.733 --> 01:58:18.250
more 1950, '60s.

01:58:18.250 --> 01:58:20.440
- But we didn't think in terms
of, at least at that age,

01:58:20.440 --> 01:58:23.830
in terms of like roles
and then like a homemaker

01:58:23.830 --> 01:58:25.480
or something like that or not,

01:58:25.480 --> 01:58:28.270
it was more about what people care about.

01:58:28.270 --> 01:58:31.420
Like girls cared about this set of things,

01:58:31.420 --> 01:58:33.280
and guys cared about the set of things.

01:58:33.280 --> 01:58:35.990
I think mathematics and engineering

01:58:35.990 --> 01:58:38.630
was something that guys
cared about and sort of,

01:58:38.630 --> 01:58:40.530
at least my perception of that time.

01:58:40.530 --> 01:58:44.020
And then girls cared about beauty.

01:58:44.020 --> 01:58:46.100
So like guys want to create machines,

01:58:46.100 --> 01:58:48.035
girls want to create beautiful stuff.

01:58:48.035 --> 01:58:48.882
[Lex laughing]

01:58:48.882 --> 01:58:49.890
And now, of course,

01:58:49.890 --> 01:58:52.790
that I don't take that forward

01:58:52.790 --> 01:58:54.413
in some kind of philosophy of life,

01:58:54.413 --> 01:58:57.560
but it's just the way I grew
up and the way I remember it.

01:58:57.560 --> 01:59:01.630
But all, everyone worked hard.

01:59:01.630 --> 01:59:06.530
The value of hard work was
instilled in everybody.

01:59:06.530 --> 01:59:09.143
And through that,

01:59:10.110 --> 01:59:12.078
I think it's a little bit of hardship.

01:59:12.078 --> 01:59:14.980
Of course also economically
everybody was poor,

01:59:14.980 --> 01:59:17.140
especially with the collapse
of the Soviet Union.

01:59:17.140 --> 01:59:18.650
There's poverty everywhere.

01:59:18.650 --> 01:59:19.840
You didn't notice it as much,

01:59:19.840 --> 01:59:21.070
but there was a,

01:59:21.070 --> 01:59:24.140
because there's not much
material possessions,

01:59:24.140 --> 01:59:27.673
there was a huge value
placed on human connection.

01:59:27.673 --> 01:59:30.150
Just meeting with neighbors,

01:59:30.150 --> 01:59:31.230
everybody knew each other.

01:59:31.230 --> 01:59:34.340
We lived in an apartment
building very different

01:59:34.340 --> 01:59:36.500
than you have in the
United States these days.

01:59:36.500 --> 01:59:37.853
Everybody knew each other.

01:59:39.030 --> 01:59:39.960
You would get together,

01:59:39.960 --> 01:59:41.690
drink vodka, smoke cigarettes,

01:59:41.690 --> 01:59:45.670
and play guitar and sing
sad songs about life.

01:59:47.610 --> 01:59:50.630
- What's with the sad
songs in the Russian thing?

01:59:50.630 --> 01:59:54.560
I mean, Russians do I express
joy from time to time.

01:59:54.560 --> 01:59:55.970
- Yeah, they do.

01:59:55.970 --> 01:59:57.590
- Certainly you do.

01:59:57.590 --> 02:00:00.280
But what do you think that's about?

02:00:00.280 --> 02:00:01.360
Is it 'cause it's cold there?

02:00:01.360 --> 02:00:03.603
But it's called other places too, right?

02:00:04.490 --> 02:00:05.440
- I think,

02:00:05.440 --> 02:00:08.383
let's just, first of all the Soviet Union,

02:00:10.380 --> 02:00:13.522
the echoes of World War II
and the millions and millions

02:00:13.522 --> 02:00:14.720
and millions of people that,

02:00:14.720 --> 02:00:17.040
civilians that were slaughtered,

02:00:17.040 --> 02:00:20.210
and also starvation is there, right?

02:00:20.210 --> 02:00:23.213
So like the echoes of that,

02:00:23.213 --> 02:00:25.950
of the ideas, the
literature, the art is there.

02:00:25.950 --> 02:00:27.340
Like that's a grandparents,

02:00:27.340 --> 02:00:29.370
that's parents, that's all there.

02:00:29.370 --> 02:00:30.600
So that contributes to it,

02:00:30.600 --> 02:00:35.600
that life can be absurdly
unexplainably cruel.

02:00:35.620 --> 02:00:37.410
At any moment everything can change.

02:00:37.410 --> 02:00:38.640
So that's in there.

02:00:38.640 --> 02:00:40.960
Then I think there's an empowering aspect

02:00:40.960 --> 02:00:43.270
to finding beauty in suffering

02:00:43.270 --> 02:00:45.103
that then everything
else is beautiful too.

02:00:45.103 --> 02:00:47.680
It's like, if you just
linger or it's like,

02:00:47.680 --> 02:00:49.280
why you meditate on death?

02:00:49.280 --> 02:00:52.080
Is like, if you just think
about the worst possible case

02:00:52.080 --> 02:00:53.130
and find beauty in that,

02:00:53.130 --> 02:00:54.417
then everything else is beautiful too.

02:00:54.417 --> 02:00:57.440
And so you write songs
about the dark stuff.

02:00:57.440 --> 02:01:02.200
And that's somehow helps you
deal with whatever comes.

02:01:02.200 --> 02:01:07.200
There's a hopelessness
to the Soviet Union that,

02:01:07.490 --> 02:01:09.390
like, inflation,

02:01:09.390 --> 02:01:13.240
all those kinds of things
where people were sold dreams

02:01:13.240 --> 02:01:15.440
and never delivered.

02:01:15.440 --> 02:01:18.220
And so like, there's a,

02:01:18.220 --> 02:01:21.420
if you don't sing songs about sad things,

02:01:21.420 --> 02:01:24.000
you're going to become
cynical about this world.

02:01:24.000 --> 02:01:24.833
- Mm-hmm.

02:01:24.833 --> 02:01:25.692
Interesting.

02:01:25.692 --> 02:01:27.390
- So they don't want
to give in to cynicism.

02:01:27.390 --> 02:01:30.413
Now, a lot of people did, one of the,

02:01:31.540 --> 02:01:34.280
but that is the battle against cynicism.

02:01:34.280 --> 02:01:38.470
One of the things that
may be common in Russia

02:01:38.470 --> 02:01:41.070
is a kind of cynicism about,

02:01:41.070 --> 02:01:43.230
like, if I told you the
thing I said earlier

02:01:43.230 --> 02:01:44.853
about dreaming about robots,

02:01:44.853 --> 02:01:48.840
it's very common for people
to dismiss that dream,

02:01:48.840 --> 02:01:52.210
of saying, no, that's
not, that's too wild.

02:01:52.210 --> 02:01:54.350
Like, who else do you know that did that?

02:01:54.350 --> 02:01:55.920
Or you want to start a podcast?

02:01:55.920 --> 02:01:57.030
Like who else?

02:01:57.030 --> 02:01:58.820
Like nobody's making money on podcasts.

02:01:58.820 --> 02:02:00.050
Like, why do you want to start a podcast?

02:02:00.050 --> 02:02:03.410
That kind of mindset I
think is quite common,

02:02:03.410 --> 02:02:07.550
which is why I would say
entrepreneurship in Russia

02:02:07.550 --> 02:02:09.360
is still not very good.

02:02:09.360 --> 02:02:11.060
Which to be a business,

02:02:11.060 --> 02:02:13.470
like, to be an entrepreneur
you have to dream big,

02:02:13.470 --> 02:02:15.020
and you have to have others around you,

02:02:15.020 --> 02:02:19.120
like friends and support
group that make you dream big.

02:02:19.120 --> 02:02:21.420
But if you don't give in to cynicism

02:02:22.390 --> 02:02:27.390
and appreciate the beauty
in the unfairness of life,

02:02:27.830 --> 02:02:29.960
the absurd unfairness of life,

02:02:29.960 --> 02:02:34.520
then I think it just makes you
appreciative of everything.

02:02:34.520 --> 02:02:35.420
It's like a,

02:02:35.420 --> 02:02:38.050
it's a prerequisite for gratitude.

02:02:38.050 --> 02:02:40.340
And so, yeah,

02:02:40.340 --> 02:02:42.580
I think that instilled in me ability

02:02:42.580 --> 02:02:44.020
to appreciate everything,

02:02:44.020 --> 02:02:45.240
just like everything.

02:02:45.240 --> 02:02:46.367
Everything's amazing.

02:02:46.367 --> 02:02:48.950
And then also there is a culture

02:02:51.267 --> 02:02:56.140
of like romanticizing everything.

02:02:56.140 --> 02:03:01.140
Like, it's almost like
romantic relationships

02:03:01.370 --> 02:03:03.430
were very like soap opera,

02:03:03.430 --> 02:03:07.720
like is very like over the top dramatic.

02:03:07.720 --> 02:03:10.930
And I think that it was
instilled in me too,

02:03:10.930 --> 02:03:13.680
not only do I appreciate
everything about life,

02:03:13.680 --> 02:03:15.616
but I get like emotional about it.

02:03:15.616 --> 02:03:17.080
In a sense, like,

02:03:17.080 --> 02:03:21.700
I get like a visceral feeling
of joy for everything.

02:03:21.700 --> 02:03:26.130
And the same with friends or
people of the opposite sex.

02:03:26.130 --> 02:03:28.420
Like, there's a deep,

02:03:28.420 --> 02:03:33.000
like emotional connection
there that like [laughing]

02:03:33.000 --> 02:03:34.960
that's like way too dramatic too.

02:03:34.960 --> 02:03:38.800
Like, I guess relative to
what the actual moment is.

02:03:38.800 --> 02:03:42.380
But I derive so much deep,

02:03:42.380 --> 02:03:46.660
like dramatic joy from
so many things in life.

02:03:46.660 --> 02:03:48.940
And I think I would attributed that

02:03:48.940 --> 02:03:50.370
to the upbringing in Russia.

02:03:50.370 --> 02:03:54.040
But the thing that sticks
most of all is the friendship.

02:03:54.040 --> 02:03:59.040
And have now since then had
one other friend like that

02:03:59.244 --> 02:04:02.660
in the United States, he lives in Chicago.

02:04:02.660 --> 02:04:03.832
His name is Matt.

02:04:03.832 --> 02:04:08.320
And slowly here and there accumulating

02:04:08.320 --> 02:04:09.890
really fascinating people,

02:04:09.890 --> 02:04:11.570
but I'm very selective with that.

02:04:11.570 --> 02:04:14.373
Funny enough, the few times,

02:04:16.180 --> 02:04:18.010
it's not few it's a lot of times now

02:04:18.010 --> 02:04:19.940
interacting with Joe Rogan [chuckles]

02:04:19.940 --> 02:04:21.414
it's sounds surreal to say,

02:04:21.414 --> 02:04:24.210
but there was a kindred spirit there.

02:04:24.210 --> 02:04:25.660
Like I've connected with him.

02:04:26.811 --> 02:04:28.020
And there's been people like that

02:04:28.020 --> 02:04:31.250
also in the grappling sports
that are really connected with.

02:04:31.250 --> 02:04:33.420
I've actually struggled,

02:04:33.420 --> 02:04:36.930
which is why I'm so
glad to be your friend,

02:04:36.930 --> 02:04:40.290
is I've struggled to
connect with scientists.

02:04:40.290 --> 02:04:42.690
- They can be a little
bit wooden sometimes.

02:04:42.690 --> 02:04:43.523
- [Lex] Yeah.

02:04:43.523 --> 02:04:44.356
- Even the biologist.

02:04:44.356 --> 02:04:45.510
I mean, one thing that I,

02:04:46.559 --> 02:04:50.130
well, I'm so struck by the
fact that you work with robots,

02:04:50.130 --> 02:04:51.408
you're an engineer, AI,

02:04:51.408 --> 02:04:52.980
science technology,

02:04:52.980 --> 02:04:55.350
and that all sounds like hardware, right?

02:04:55.350 --> 02:04:58.310
But what you're describing
and I know is true about you

02:04:58.310 --> 02:05:01.690
is this deep emotional
life and this resonance

02:05:01.690 --> 02:05:02.740
and it's really wonderful.

02:05:02.740 --> 02:05:06.530
I actually think it's one of
the reasons why so many people,

02:05:06.530 --> 02:05:09.040
scientists and otherwise
have gravitated towards you

02:05:09.040 --> 02:05:12.100
and your podcast is because
you hold both elements.

02:05:12.100 --> 02:05:14.270
In the Hermann Hesse's book,

02:05:14.270 --> 02:05:16.140
I don't know if you, "Narcissus
and Goldmund," right?

02:05:16.140 --> 02:05:19.430
It's about these elements
of the logical rational mind

02:05:19.430 --> 02:05:22.980
and the emotional mind and
how those are woven together.

02:05:22.980 --> 02:05:24.900
And if people haven't
read it, they should,

02:05:24.900 --> 02:05:27.360
and you embody the full picture.

02:05:27.360 --> 02:05:30.060
And I think that's so much
of what draws people to you.

02:05:30.060 --> 02:05:31.960
- I've read every Hermann
Hesse book by the way.

02:05:31.960 --> 02:05:33.490
- As usual [chuckles]

02:05:33.490 --> 02:05:37.010
as usual I've done about
9% of what life is.

02:05:37.010 --> 02:05:37.843
No, it's true.

02:05:37.843 --> 02:05:39.740
You mentioned Joe,

02:05:39.740 --> 02:05:42.380
who is a phenomenal human being,

02:05:42.380 --> 02:05:44.300
not just for his amazing accomplishments,

02:05:44.300 --> 02:05:48.530
but for how he shows up
to the world one on one.

02:05:48.530 --> 02:05:51.640
I think I heard him say the
other day on an interview,

02:05:51.640 --> 02:05:55.730
he said, there is no public
or private version of him.

02:05:55.730 --> 02:05:57.030
And he's like, this is me.

02:05:57.030 --> 02:05:58.350
He said that it was beautiful.

02:05:58.350 --> 02:06:00.950
He said, I'm like the fish
that got through the net.

02:06:00.950 --> 02:06:03.600
And there is no onstage offstage version.

02:06:03.600 --> 02:06:04.610
And you're absolutely right.

02:06:04.610 --> 02:06:05.880
And I.

02:06:05.880 --> 02:06:06.713
- Fish.

02:06:06.713 --> 02:06:07.680
[Lex laughing]

02:06:07.680 --> 02:06:08.513
- So, but, well, you guys,

02:06:08.513 --> 02:06:09.860
I have a question actually about-

02:06:09.860 --> 02:06:10.890
- But that's a really good point

02:06:10.890 --> 02:06:12.670
about public and private life.

02:06:12.670 --> 02:06:13.503
He was a huge,

02:06:13.503 --> 02:06:15.680
if I could just comment real quick.

02:06:15.680 --> 02:06:17.000
Like that, he was a,

02:06:17.000 --> 02:06:18.610
I've been a fan of Joe for a long time,

02:06:18.610 --> 02:06:19.887
but he's been an inspiration

02:06:19.887 --> 02:06:24.740
to not have any difference
between public and private life.

02:06:24.740 --> 02:06:28.200
I actually had a conversation
with Naval about this,

02:06:28.200 --> 02:06:33.200
and he said that you
can't have a rich life,

02:06:34.290 --> 02:06:36.660
like exciting life

02:06:36.660 --> 02:06:39.380
if you're the same person
publicly and privately.

02:06:39.380 --> 02:06:42.460
And I think I understand that idea,

02:06:42.460 --> 02:06:45.410
but I don't agree with it.

02:06:45.410 --> 02:06:49.150
I think that's really
fulfilling and exciting

02:06:49.150 --> 02:06:51.390
to be the same person
privately and publicly

02:06:51.390 --> 02:06:52.540
with very few exceptions.

02:06:52.540 --> 02:06:57.540
Now that said, I don't have
any really strange sex kinks.

02:06:58.090 --> 02:06:58.923
So like,

02:06:58.923 --> 02:07:00.460
I feel like it can be open
with basically everything.

02:07:00.460 --> 02:07:02.373
I don't have anything I'm ashamed of.

02:07:03.580 --> 02:07:05.700
There's some things that
could be perceived poorly,

02:07:05.700 --> 02:07:07.770
like the screaming Roombas,

02:07:07.770 --> 02:07:09.100
but I'm not ashamed of them.

02:07:09.100 --> 02:07:11.440
I just have to present
them in the right context.

02:07:11.440 --> 02:07:15.620
But there's a freedom to being
the same person in private

02:07:15.620 --> 02:07:16.670
as in public.

02:07:16.670 --> 02:07:21.670
And that Joe made me realize
that you can be that.

02:07:22.500 --> 02:07:25.280
And also to be kind to others.

02:07:25.280 --> 02:07:28.670
It sounds kind of absurd,

02:07:28.670 --> 02:07:33.670
but I really always enjoyed
like being good to others.

02:07:38.490 --> 02:07:41.130
Like just being kind towards others.

02:07:41.130 --> 02:07:45.420
But I always felt like the
world didn't want me to be.

02:07:45.420 --> 02:07:48.550
Like, there's so much negativity
when I was growing up,

02:07:48.550 --> 02:07:49.740
like just around people.

02:07:49.740 --> 02:07:53.120
If you actually just
notice how people talk,

02:07:53.120 --> 02:07:57.161
they, from like, complaining
about the weather,

02:07:57.161 --> 02:07:59.010
this could be just like the big cities

02:07:59.010 --> 02:07:59.843
that I've visited.

02:07:59.843 --> 02:08:01.735
But there's a general negativity,

02:08:01.735 --> 02:08:05.070
and positivity is kind of suppressed.

02:08:05.070 --> 02:08:05.903
You're not,

02:08:05.903 --> 02:08:08.750
one, you're not seen as very intelligent,

02:08:08.750 --> 02:08:10.450
and two, there's a kind of,

02:08:10.450 --> 02:08:12.860
you're seen as like a
little bit of a weirdo.

02:08:12.860 --> 02:08:15.790
And so I always felt
like I had to hide that.

02:08:15.790 --> 02:08:17.160
And what Joe made me realize,

02:08:17.160 --> 02:08:19.130
one, I could be fully

02:08:19.130 --> 02:08:22.330
just the same person private and public,

02:08:22.330 --> 02:08:25.180
and two, I can embrace being kind,

02:08:25.180 --> 02:08:28.310
in just, in the way that I like,

02:08:28.310 --> 02:08:31.270
in the way I know how to do.

02:08:31.270 --> 02:08:36.270
And sort of for me on like,
on Twitter or like publicly,

02:08:36.430 --> 02:08:37.560
whenever I say stuff,

02:08:37.560 --> 02:08:39.670
that means saying stuff simply

02:08:39.670 --> 02:08:41.240
almost to the point of cliche.

02:08:41.240 --> 02:08:44.590
And like, I have the
strength now to say it,

02:08:44.590 --> 02:08:46.157
even if I'm being mocked.

02:08:46.157 --> 02:08:46.990
[Lex laughing]

02:08:46.990 --> 02:08:47.823
You know what I mean?

02:08:47.823 --> 02:08:48.720
Like, just it's okay.

02:08:48.720 --> 02:08:50.430
If everything's going to be okay.

02:08:50.430 --> 02:08:52.071
Okay, some people will think you're dumb.

02:08:52.071 --> 02:08:53.560
They're probably right.

02:08:53.560 --> 02:08:54.393
The point is,

02:08:54.393 --> 02:08:56.320
like, just enjoy being yourself.

02:08:56.320 --> 02:08:58.350
And that Joe, more than
almost anybody else,

02:08:58.350 --> 02:09:03.100
because he's so successful at
it, inspired me to do that.

02:09:03.100 --> 02:09:06.230
Be kind and be the same
person, private and public.

02:09:06.230 --> 02:09:07.063
- I love it.

02:09:07.063 --> 02:09:08.690
And I love the idea that authenticity

02:09:08.690 --> 02:09:11.085
doesn't have to be oversharing, right?

02:09:11.085 --> 02:09:14.990
That it doesn't mean you reveal
every detail of your life.

02:09:14.990 --> 02:09:19.060
It's a way of being true
to an essence of oneself.

02:09:19.060 --> 02:09:19.980
- Right.

02:09:19.980 --> 02:09:24.460
There's never a feeling when
you deeply think and introspect

02:09:24.460 --> 02:09:26.150
that you're hiding
something from the world

02:09:26.150 --> 02:09:28.770
or you're being dishonest
in some fundamental way.

02:09:28.770 --> 02:09:33.520
So, yeah, that's truly liberating.

02:09:33.520 --> 02:09:34.760
It allows you to think,

02:09:34.760 --> 02:09:37.080
it allows you to like think freely,

02:09:37.080 --> 02:09:38.730
to speak freely,

02:09:38.730 --> 02:09:42.140
to just to be freely.

02:09:42.140 --> 02:09:43.170
That said,

02:09:43.170 --> 02:09:48.170
it's not like there's not
still a responsibility

02:09:49.550 --> 02:09:52.150
to be the best version of yourself.

02:09:52.150 --> 02:09:57.150
So, I'm very careful with
the way I say something.

02:09:57.220 --> 02:09:58.650
So, the whole point,

02:09:58.650 --> 02:10:02.610
it's not so simple to express the spirit

02:10:02.610 --> 02:10:04.997
that's inside you with words.

02:10:04.997 --> 02:10:07.563
I mean, some people are
much better than others.

02:10:08.800 --> 02:10:09.633
I struggle.

02:10:09.633 --> 02:10:12.331
Like oftentimes when I say something

02:10:12.331 --> 02:10:14.250
and I hear myself say it,

02:10:14.250 --> 02:10:16.750
it sounds really dumb and
not at all what I meant.

02:10:16.750 --> 02:10:18.450
So that's the responsibility you have.

02:10:18.450 --> 02:10:20.330
It's not just like being

02:10:20.330 --> 02:10:21.870
the same person publicly and privately

02:10:21.870 --> 02:10:24.500
means you can just say whatever the hell.

02:10:24.500 --> 02:10:27.670
It means there's still
responsibility to try to be,

02:10:27.670 --> 02:10:29.330
to express who you truly are.

02:10:29.330 --> 02:10:32.240
And that's hard.

02:10:32.240 --> 02:10:33.073
[Lex chuckles]

02:10:33.073 --> 02:10:33.906
- It hard.

02:10:33.906 --> 02:10:34.739
And I think that,

02:10:34.739 --> 02:10:37.670
we have this pressure,

02:10:37.670 --> 02:10:40.568
all people, when I say
we, I mean all humans,

02:10:40.568 --> 02:10:42.750
and maybe robots too,

02:10:42.750 --> 02:10:46.680
feel this pressure to be
able to express ourselves

02:10:46.680 --> 02:10:48.930
in that one moment in that one form.

02:10:48.930 --> 02:10:51.300
And it is beautiful when
somebody, for instance,

02:10:51.300 --> 02:10:55.190
can capture some essence
of love or sadness or anger

02:10:55.190 --> 02:10:58.790
or something in a song or in
a poem or in a short quote,

02:10:58.790 --> 02:11:02.373
but perhaps it's also possible
to do it in aggregate,

02:11:03.210 --> 02:11:05.658
all the things how you show up.

02:11:05.658 --> 02:11:08.720
For instance, one of the
things that initially drew me

02:11:08.720 --> 02:11:11.460
to want to get to know you as
a human being and a scientist

02:11:11.460 --> 02:11:13.730
and eventually we became friends,

02:11:13.730 --> 02:11:15.870
was the level of respect

02:11:15.870 --> 02:11:18.020
that you brought to your podcast listeners

02:11:18.020 --> 02:11:19.380
by wearing a suit.

02:11:19.380 --> 02:11:20.942
- Yeah.
- I'm being serious here.

02:11:20.942 --> 02:11:24.390
I was raised thinking that if
you overdress a little bit,

02:11:24.390 --> 02:11:27.300
overdressed by American,
certainly by American standards,

02:11:27.300 --> 02:11:28.680
you're overdressed for a podcast,

02:11:28.680 --> 02:11:30.580
but it's genuine.

02:11:30.580 --> 02:11:31.860
You're not doing it for any reason,

02:11:31.860 --> 02:11:34.798
except I have to assume,
and I assumed at the time,

02:11:34.798 --> 02:11:37.990
that it was because you have
a respect for your audience,

02:11:37.990 --> 02:11:42.440
you respect them enough to
show up a certain way for them.

02:11:42.440 --> 02:11:44.190
It's for you also, but it's for them.

02:11:44.190 --> 02:11:45.023
- Yeah.

02:11:45.023 --> 02:11:45.960
- And I think between that

02:11:45.960 --> 02:11:47.893
and your commitment to your friendship,

02:11:47.893 --> 02:11:50.070
just the way that you talk
about friendships and love

02:11:50.070 --> 02:11:52.880
and the way you hold
up these higher ideals,

02:11:52.880 --> 02:11:56.640
I think at least as a
consumer of your content

02:11:57.940 --> 02:11:59.617
and as your friend,

02:11:59.617 --> 02:12:01.800
what I find, is that in aggregate,

02:12:01.800 --> 02:12:03.400
you're communicating who you are,

02:12:03.400 --> 02:12:05.850
it doesn't have to be
one quote or something.

02:12:05.850 --> 02:12:08.180
And I think that we're sort of obsessed

02:12:08.180 --> 02:12:10.160
by like the one Einstein quote,

02:12:10.160 --> 02:12:13.050
or the one line of poetry or something,

02:12:13.050 --> 02:12:18.050
but I think you so embody the
way that, and Joe as well,

02:12:18.320 --> 02:12:20.040
it's about how you live your life

02:12:20.040 --> 02:12:22.880
and how you show up as
a collection of things

02:12:22.880 --> 02:12:24.910
and said and done.

02:12:24.910 --> 02:12:25.743
- Yeah, that that's,

02:12:25.743 --> 02:12:30.420
and so, the aggregate is
the goal, the tricky thing,

02:12:30.420 --> 02:12:32.250
and Jordan Peterson talks about this

02:12:32.250 --> 02:12:33.280
because he's under attack

02:12:33.280 --> 02:12:36.260
way more than you and I will ever be, but-

02:12:36.260 --> 02:12:37.260
- Right now?

02:12:37.260 --> 02:12:38.093
- For now, right?

02:12:38.093 --> 02:12:40.470
This is very true for now.

02:12:40.470 --> 02:12:45.470
That the people who
attack on the internet,

02:12:46.990 --> 02:12:48.777
this is one of the problems with Twitter,

02:12:48.777 --> 02:12:53.210
is they don't consider the aggregate,

02:12:53.210 --> 02:12:55.340
they take a single statements.

02:12:55.340 --> 02:12:58.460
And so, one of the defense mechanisms,

02:12:58.460 --> 02:13:01.190
like again why Joe has
been an inspiration,

02:13:01.190 --> 02:13:05.570
is that when you in
aggregate, a good person,

02:13:05.570 --> 02:13:06.897
a lot of people will know that.

02:13:06.897 --> 02:13:08.980
And so, that makes you much more immune

02:13:08.980 --> 02:13:10.050
to the attacks of people

02:13:10.050 --> 02:13:11.627
that bring out an individual statement

02:13:11.627 --> 02:13:14.270
that might be a misstatement of some kind,

02:13:14.270 --> 02:13:16.990
or doesn't express who you are.

02:13:16.990 --> 02:13:20.990
And so, that, I like that
idea is the aggregate.

02:13:20.990 --> 02:13:23.820
And the power of the podcast,

02:13:23.820 --> 02:13:27.240
is you have hundreds of hours out there,

02:13:27.240 --> 02:13:30.202
and being yourself and people
get to know who you are.

02:13:30.202 --> 02:13:31.561
And once they do,

02:13:31.561 --> 02:13:34.780
and you post pictures of screaming Roombas

02:13:34.780 --> 02:13:35.764
as you kick them,

02:13:35.764 --> 02:13:38.160
they will understand
that you don't mean well.

02:13:38.160 --> 02:13:40.183
By the way, as a side comment,

02:13:41.320 --> 02:13:42.970
I don't know if I want to release this

02:13:42.970 --> 02:13:45.553
because it's not just the Roombas-

02:13:46.790 --> 02:13:48.520
- You have a whole dungeon of robots.

02:13:48.520 --> 02:13:49.353
- Okay.

02:13:49.353 --> 02:13:51.650
So, this is a problem,

02:13:51.650 --> 02:13:54.470
the Boston Dynamics came
up against this problem.

02:13:54.470 --> 02:13:58.763
But, let me work this out like
workshop this out with you,

02:13:59.870 --> 02:14:03.723
and maybe because we'll post
this, people will let me know.

02:14:05.590 --> 02:14:09.085
So, there's legged robots,
they look like a dog,

02:14:09.085 --> 02:14:14.030
I'm trying to create a very
real human-robot connection,

02:14:14.030 --> 02:14:15.450
but like they're also incredible

02:14:15.450 --> 02:14:19.510
because you can throw them
like off of a building

02:14:19.510 --> 02:14:21.450
and they'll land fine.

02:14:21.450 --> 02:14:22.430
And this beautiful.

02:14:22.430 --> 02:14:23.263
- That's amazing.

02:14:23.263 --> 02:14:24.360
I've seen the Instagram videos

02:14:24.360 --> 02:14:27.320
of like cats jumping off of
like fifth story buildings

02:14:27.320 --> 02:14:28.690
and then walking away.

02:14:28.690 --> 02:14:30.410
But no one should throw their cat

02:14:30.410 --> 02:14:31.452
out of a window of a building.

02:14:31.452 --> 02:14:32.570
- Well, this is the
problem I'm experiencing,

02:14:32.570 --> 02:14:34.720
all certainly kicking the robots,

02:14:34.720 --> 02:14:38.040
its really fascinating how
they recover from those kicks.

02:14:38.040 --> 02:14:40.470
But like just seeing myself do it

02:14:40.470 --> 02:14:43.400
and also seeing others do it,
it just does not look good,

02:14:43.400 --> 02:14:44.940
and I don't know what to do with that.

02:14:44.940 --> 02:14:46.793
'Cause it's such a-
- Ill 'do it.

02:14:48.093 --> 02:14:49.430
[Lex laughing]

02:14:49.430 --> 02:14:50.263
- See.

02:14:50.263 --> 02:14:51.910
But you don't,

02:14:51.910 --> 02:14:54.110
'cause you are-
- A robot, no, I'm kidding.

02:14:55.400 --> 02:14:56.233
What's interesting?

02:14:56.233 --> 02:14:57.066
- Yeah.

02:14:57.066 --> 02:15:00.020
- Before today's conversation,
I probably could do it,

02:15:00.020 --> 02:15:04.611
and I'm thinking about robots,
bills of rights and things.

02:15:04.611 --> 02:15:08.600
Not to satisfy you or to satisfy anything,

02:15:08.600 --> 02:15:13.040
except that if they have
some sentience aspect

02:15:13.040 --> 02:15:16.440
to their being, then I
would load to kick it.

02:15:16.440 --> 02:15:17.700
- I don't think we'd be able to kick it,

02:15:17.700 --> 02:15:19.030
you might be able to kick the first time,

02:15:19.030 --> 02:15:21.687
but not the second, this is
the problem of experience.

02:15:21.687 --> 02:15:22.875
One of the cool things,

02:15:22.875 --> 02:15:26.610
is one of the robots I'm working with,

02:15:26.610 --> 02:15:29.380
you can pick it up by
one leg and is dangling,

02:15:29.380 --> 02:15:31.772
and you can throw it in any kind of way

02:15:31.772 --> 02:15:33.710
and it'll land correctly.

02:15:33.710 --> 02:15:34.704
So, it's really-

02:15:34.704 --> 02:15:35.720
- I had a friend who had a cat like that.

02:15:35.720 --> 02:15:37.778
[Lex laughing]

02:15:37.778 --> 02:15:40.600
- Oh man, we look forward
to the letters on the cat-

02:15:40.600 --> 02:15:42.277
- Oh no, I'm not
suggesting anyone did that,

02:15:42.277 --> 02:15:43.970
but he had this cat,

02:15:43.970 --> 02:15:46.080
and the cat, he would
just throw it onto the bed

02:15:46.080 --> 02:15:48.840
from across the room, and then
it would run back for more,

02:15:48.840 --> 02:15:51.620
or somehow that was the
nature of the relationship.

02:15:51.620 --> 02:15:54.130
I think no one should
do that to an animal,

02:15:54.130 --> 02:15:57.580
but this cat seemed to
return for whatever reason.

02:15:57.580 --> 02:15:58.777
- But a robot is a robot,

02:15:58.777 --> 02:16:02.270
and it's fascinating to me how
hard it is for me to do that.

02:16:02.270 --> 02:16:04.050
So, it's unfortunate,

02:16:04.050 --> 02:16:06.280
but I don't think I
can do that to a robot.

02:16:06.280 --> 02:16:08.293
Like I struggle with that.

02:16:09.661 --> 02:16:12.879
So, for me to be able
to do that with a robot,

02:16:12.879 --> 02:16:15.860
I have to almost get like into the state

02:16:15.860 --> 02:16:17.750
that I imagine like doctors get into

02:16:17.750 --> 02:16:19.380
when they're doing surgery,

02:16:19.380 --> 02:16:23.020
like I have to do what
robotics colleagues of mine do,

02:16:23.020 --> 02:16:25.260
which is like start
seeing it as an object.

02:16:25.260 --> 02:16:26.093
- Dissociate.

02:16:26.093 --> 02:16:26.926
- Like dissociate.

02:16:26.926 --> 02:16:27.950
So, it was just fascinating

02:16:27.950 --> 02:16:30.730
that I have to do that in
to do that with a robot.

02:16:30.730 --> 02:16:33.650
I just want to take that
little bit of a tangent.

02:16:33.650 --> 02:16:35.030
- No, I think it's an important thing.

02:16:35.030 --> 02:16:40.030
I mean, I'm not shy about
the fact that for many years

02:16:40.710 --> 02:16:42.460
I've worked on experimental animals,

02:16:42.460 --> 02:16:44.560
and that's been a very challenging aspect

02:16:44.560 --> 02:16:46.100
of being a biologist.

02:16:46.100 --> 02:16:48.640
Mostly mice, but in the past no longer,

02:16:48.640 --> 02:16:51.250
thank goodness 'cause I
just don't like doing it,

02:16:51.250 --> 02:16:52.710
larger animals as well.

02:16:52.710 --> 02:16:53.760
And now I work on humans,

02:16:53.760 --> 02:16:55.950
which I can give consent, verbal consent.

02:16:55.950 --> 02:17:00.840
So, I think that it's extremely important

02:17:00.840 --> 02:17:03.920
to have an understanding
of what the guidelines are

02:17:03.920 --> 02:17:06.220
and where one's own
boundaries are around this.

02:17:06.220 --> 02:17:09.060
It's not just an important question,

02:17:09.060 --> 02:17:11.080
it might be the most important question

02:17:11.080 --> 02:17:12.910
before any work can progress.

02:17:12.910 --> 02:17:14.960
- So, you asked me about friendship.

02:17:14.960 --> 02:17:18.210
I know you have a lot of
thoughts about friendship,

02:17:18.210 --> 02:17:20.723
what do you think is the
value of friendship in life?

02:17:22.350 --> 02:17:24.850
- Well, for me personally,

02:17:24.850 --> 02:17:29.850
just because of my life
trajectory and arc friendship,

02:17:29.910 --> 02:17:31.540
and I should say,

02:17:31.540 --> 02:17:35.650
I do have some female friends
that are just friends,

02:17:35.650 --> 02:17:37.150
they're completely platonic relationships,

02:17:37.150 --> 02:17:39.700
but it's been mostly male
friendship to me, has been-

02:17:39.700 --> 02:17:41.960
- It has been all male
friendships to me actually, yeah.

02:17:41.960 --> 02:17:43.060
- Interesting.
- Yeah.

02:17:43.060 --> 02:17:45.730
- It's been an absolute lifeline.

02:17:45.730 --> 02:17:47.070
They are my family,

02:17:47.070 --> 02:17:48.310
I have a biological family

02:17:48.310 --> 02:17:50.090
and I have great respect and love for them

02:17:50.090 --> 02:17:51.290
and an appreciation for them,

02:17:51.290 --> 02:17:54.227
but it's provided me the,

02:17:57.912 --> 02:17:58.920
I won't even say confidence

02:17:58.920 --> 02:18:01.997
because there's always an
anxiety in taking any good risk,

02:18:01.997 --> 02:18:04.250
or any risk worth taking.

02:18:04.250 --> 02:18:08.900
It's given me the sense that
I should go for certain things

02:18:08.900 --> 02:18:12.210
and try certain things to take
risk to weather that anxiety.

02:18:12.210 --> 02:18:14.670
And I don't consider myself

02:18:14.670 --> 02:18:16.810
a particularly competitive person,

02:18:16.810 --> 02:18:21.810
but I would sooner die than disappoint,

02:18:21.910 --> 02:18:24.660
or let down one of my friends.

02:18:24.660 --> 02:18:26.960
I can think of nothing worse actually,

02:18:26.960 --> 02:18:29.170
than disappointing one of my friends,

02:18:29.170 --> 02:18:31.290
everything else is secondary to me.

02:18:31.290 --> 02:18:33.160
- What disappointment?

02:18:33.160 --> 02:18:35.930
- Disappoint, meaning not,

02:18:35.930 --> 02:18:40.760
I mean, certainly I strive
always to show up as best I can

02:18:40.760 --> 02:18:43.000
for the friendship, and
that can be in small ways.

02:18:43.000 --> 02:18:45.030
That can mean making
sure the phone is away,

02:18:45.030 --> 02:18:46.113
sometimes it's about,

02:18:48.580 --> 02:18:50.860
I'm terrible with punctuality
'cause I'm an academic.

02:18:50.860 --> 02:18:53.270
And so, I just get lost in
time and I don't mean anything,

02:18:53.270 --> 02:18:56.320
but it's striving to, to listen to,

02:18:56.320 --> 02:18:58.540
to enjoy good times and to make time.

02:18:58.540 --> 02:19:01.890
It kind of goes back to this
first variable we talked about,

02:19:01.890 --> 02:19:03.646
to make sure that I spend time

02:19:03.646 --> 02:19:06.770
and to get time in person and check in.

02:19:06.770 --> 02:19:10.690
And I think there's so many ways

02:19:10.690 --> 02:19:12.380
in which friendship is vital to me,

02:19:12.380 --> 02:19:14.860
it's it's actually to me,
what makes life worth living.

02:19:14.860 --> 02:19:15.693
- Yeah.

02:19:15.693 --> 02:19:17.430
Well, there's a,

02:19:17.430 --> 02:19:20.110
I am surprised like with
the high school friends

02:19:20.110 --> 02:19:22.361
how we don't actually
talk that often these days

02:19:22.361 --> 02:19:23.780
in terms of time,

02:19:23.780 --> 02:19:24.980
but every time we see each other,

02:19:24.980 --> 02:19:27.120
it's immediately right
back to where we started.

02:19:27.120 --> 02:19:30.513
So, I struggled that how much
time you really allocate,

02:19:32.620 --> 02:19:34.430
for the friendship to be deeply meaningful

02:19:34.430 --> 02:19:36.293
because they're always there with me

02:19:36.293 --> 02:19:38.193
even if we don't talk often.

02:19:39.560 --> 02:19:41.020
So, there's a kind of loyalty.

02:19:41.020 --> 02:19:44.040
I think maybe it's a different style,

02:19:44.040 --> 02:19:47.040
but I think to me,

02:19:47.040 --> 02:19:51.640
friendship is being there
in the hard times, I think.

02:19:51.640 --> 02:19:56.520
Like I'm much more reliable
when you're going through shit

02:19:56.520 --> 02:19:57.610
than in like-

02:19:57.610 --> 02:19:59.600
- You're pretty reliable anyway.

02:19:59.600 --> 02:20:03.170
- No, but if you're like a
wedding or something like that,

02:20:03.170 --> 02:20:07.793
or like, I don't know, like
you want an award of some kind,

02:20:08.770 --> 02:20:11.920
yeah, I'll congratulate
the shit out of you,

02:20:11.920 --> 02:20:14.500
but like that's not, and I'll be there,

02:20:14.500 --> 02:20:16.740
but that's not as important
to me as being there

02:20:16.740 --> 02:20:20.280
when like nobody else
is like just being there

02:20:20.280 --> 02:20:23.850
when shit hits the fan,
or something's tough

02:20:23.850 --> 02:20:25.910
where the world turns their back on you,

02:20:25.910 --> 02:20:26.910
all those kinds of things,

02:20:26.910 --> 02:20:29.370
that, to me, that's where
friendship is meaningful.

02:20:29.370 --> 02:20:30.960
- Well, I know that to be true about you

02:20:30.960 --> 02:20:33.049
and that's a felt thing
and a real thing with you.

02:20:33.049 --> 02:20:35.610
Let me ask one more thing
about that actually,

02:20:35.610 --> 02:20:38.460
because I'm not a practitioner Jujitsu,

02:20:38.460 --> 02:20:39.700
I know you are, Joe is,

02:20:39.700 --> 02:20:42.450
but years ago, I read a
book that I really enjoyed,

02:20:42.450 --> 02:20:44.830
which is Sam Sheridan's
book, " A Fighter's Heart,"

02:20:44.830 --> 02:20:47.185
he talks about all these
different forms of martial arts.

02:20:47.185 --> 02:20:50.680
And maybe it was in the book,
maybe it was in an interview,

02:20:50.680 --> 02:20:53.330
but he said that fighting,

02:20:53.330 --> 02:20:56.240
or being in physical battle with somebody,

02:20:56.240 --> 02:20:58.450
Jujitsu boxing or some other form

02:20:58.450 --> 02:21:01.870
of direct physical contact
between two individuals

02:21:01.870 --> 02:21:04.340
creates this bond unlike any other.

02:21:04.340 --> 02:21:06.610
Because he said it's
like a one night stand,

02:21:06.610 --> 02:21:08.060
you're sharing bodily fluids

02:21:08.060 --> 02:21:09.830
with somebody that you barely know.

02:21:09.830 --> 02:21:10.663
- Yeah.

02:21:10.663 --> 02:21:13.140
- And I chuckled about it
'cause it's kind of funny

02:21:13.140 --> 02:21:14.850
and it kind of tongue in cheek.

02:21:14.850 --> 02:21:16.300
But at the same time,

02:21:16.300 --> 02:21:19.000
I think this is a fundamental way

02:21:19.000 --> 02:21:22.310
in which members of a species bond

02:21:22.310 --> 02:21:24.350
is through physical contact.

02:21:24.350 --> 02:21:25.920
And certainly, there are other forms,

02:21:25.920 --> 02:21:27.400
there's cuddling, and
there's hand holding,

02:21:27.400 --> 02:21:29.710
and there's in their sexual intercourse,

02:21:29.710 --> 02:21:30.543
and there's all sorts of things.

02:21:30.543 --> 02:21:31.579
- What's cuddling?

02:21:31.579 --> 02:21:32.770
I haven't heard of it.

02:21:32.770 --> 02:21:34.910
- I heard this recently,
I didn't know this term,

02:21:34.910 --> 02:21:36.180
but there's a term,

02:21:36.180 --> 02:21:39.200
they've turned the noun
cupcake into a verb,

02:21:39.200 --> 02:21:41.890
cupcaking it turns out, I
just learned about this.

02:21:41.890 --> 02:21:45.100
Cupcaking is when you
spend time just cuddling.

02:21:45.100 --> 02:21:46.340
I didn't know about this.

02:21:46.340 --> 02:21:47.330
You heard it here first,

02:21:47.330 --> 02:21:48.890
although I heard it
first just the other day.

02:21:48.890 --> 02:21:50.030
Cupcaking is actually a-

02:21:50.030 --> 02:21:50.920
- Cuddling is everything,

02:21:50.920 --> 02:21:51.810
it's not just like,

02:21:51.810 --> 02:21:53.790
is it in bed, or is it in the coach?

02:21:53.790 --> 02:21:55.440
Like what's cuddling?

02:21:55.440 --> 02:21:56.390
I do look up what cuddling is-

02:21:56.390 --> 02:21:57.223
- We need to look at this up

02:21:57.223 --> 02:21:59.030
and we need to define the variables.

02:21:59.030 --> 02:22:00.670
I think it definitely has to do

02:22:00.670 --> 02:22:04.230
with physical contact, I'm told,

02:22:04.230 --> 02:22:09.230
but in terms of battle, a competition,

02:22:10.740 --> 02:22:12.660
and the Sheridan quote, I'm just curious.

02:22:12.660 --> 02:22:17.660
So, do you get close, or
feel a bond with people that,

02:22:18.390 --> 02:22:20.130
for instance, you rolled Jujitsu with,

02:22:20.130 --> 02:22:24.010
or even though you don't know
anything else about them,

02:22:24.010 --> 02:22:25.540
was he right about this?

02:22:25.540 --> 02:22:27.170
- Yeah, I mean on many levels.

02:22:27.170 --> 02:22:28.357
He also has the book, what?

02:22:28.357 --> 02:22:29.440
"A Fighter's Mind."

02:22:29.440 --> 02:22:30.920
- Yeah, that was the third one.

02:22:30.920 --> 02:22:32.170
He's actually an excellent writer.

02:22:32.170 --> 02:22:34.540
What's interesting about him,
just briefly about Sheridan,

02:22:34.540 --> 02:22:36.140
I don't know him, but I did
a little bit of research,

02:22:36.140 --> 02:22:40.120
he went to Harvard, he was
an art major at Harvard,

02:22:40.120 --> 02:22:43.470
he claims all he did was
smoke cigarettes and do art.

02:22:43.470 --> 02:22:45.140
I don't know if his art was any good.

02:22:45.140 --> 02:22:48.348
And I think his father
was in the SEAL teams.

02:22:48.348 --> 02:22:51.760
And then when he got out
of Harvard, graduated,

02:22:51.760 --> 02:22:52.930
he took off around the world

02:22:52.930 --> 02:22:54.470
learning all the forms of martial arts,

02:22:54.470 --> 02:22:56.700
and was early to the
kind of ultimate fighting

02:22:56.700 --> 02:22:59.050
kind of mixed martial arts and things.

02:22:59.050 --> 02:23:00.000
Great book.

02:23:00.000 --> 02:23:00.833
Yeah, yeah.

02:23:00.833 --> 02:23:01.666
- It's amazing.

02:23:01.666 --> 02:23:03.178
I don't actually remember
it, but I read it,

02:23:03.178 --> 02:23:06.667
and I remember thinking that
was an amazing encapsulation

02:23:06.667 --> 02:23:10.550
of what makes fighting like the art,

02:23:10.550 --> 02:23:11.980
like what makes it compelling.

02:23:11.980 --> 02:23:15.820
I would say that there's so many ways

02:23:15.820 --> 02:23:20.820
that Jujitsu grappling, wrestling,
combat sports in general,

02:23:20.825 --> 02:23:24.280
is like one of the most
intimate things you could do.

02:23:24.280 --> 02:23:25.600
I don't know if I would describe

02:23:25.600 --> 02:23:27.643
in terms of bodily liquids
and all those kinds of things.

02:23:27.643 --> 02:23:29.533
- I think he was more or less joking.

02:23:31.266 --> 02:23:35.100
- I think there's a few
ways that it does that.

02:23:35.100 --> 02:23:40.100
So, one, because you're
so vulnerable [sighs]

02:23:41.040 --> 02:23:44.260
So, the honesty of stepping on the mat

02:23:45.570 --> 02:23:48.390
and often all of us have ego

02:23:48.390 --> 02:23:52.380
thinking we're better than we
are at this particular art.

02:23:52.380 --> 02:23:55.576
And then the honesty of being submitted,

02:23:55.576 --> 02:23:58.750
or being worse than you thought you are

02:23:58.750 --> 02:24:00.623
and just sitting with that knowledge,

02:24:00.623 --> 02:24:02.040
that kind of honesty,

02:24:02.040 --> 02:24:05.743
we don't get to experience
it in most of daily life.

02:24:05.743 --> 02:24:06.956
We can continue living

02:24:06.956 --> 02:24:10.349
somewhat of an illusion of
our conceptions of ourselves

02:24:10.349 --> 02:24:13.790
'cause people are not going
to hit us with the reality,

02:24:13.790 --> 02:24:17.860
the mat speaks only the truth,
the reality just hits you.

02:24:17.860 --> 02:24:18.989
And that vulnerability

02:24:18.989 --> 02:24:22.160
is the same as like the
loss of a loved one,

02:24:22.160 --> 02:24:26.330
though it's the loss of a
reality that you knew before,

02:24:26.330 --> 02:24:28.210
you now have to deal
with this new reality.

02:24:28.210 --> 02:24:30.211
And when you're sitting
there in that vulnerability,

02:24:30.211 --> 02:24:32.150
and there's these other people

02:24:32.150 --> 02:24:34.350
that are also sitting
in that vulnerability,

02:24:34.350 --> 02:24:36.960
you get to really connect like, fuck,

02:24:36.960 --> 02:24:40.127
like I'm not as special
as I thought I was,

02:24:40.127 --> 02:24:45.127
and life is like not, life is
harsher than I thought I was,

02:24:46.202 --> 02:24:47.710
and we're just sitting
there with that reality,

02:24:47.710 --> 02:24:50.040
some of us can put words
to them, some we can't.

02:24:50.040 --> 02:24:51.300
So, I think that definitely,

02:24:51.300 --> 02:24:53.200
is a thing that at least the intimacy.

02:24:54.650 --> 02:24:57.763
The other thing is the human contact.

02:24:58.640 --> 02:25:03.640
There's something about,
I mean, like a big hug,

02:25:03.710 --> 02:25:05.320
like during COVID,

02:25:05.320 --> 02:25:07.810
very few people hugged
me and I hugged them,

02:25:07.810 --> 02:25:10.280
and I always felt good when they did.

02:25:10.280 --> 02:25:11.610
Like we were all tested,

02:25:11.610 --> 02:25:13.890
and especially now we're vaccinated,

02:25:13.890 --> 02:25:15.120
but there's still people,

02:25:15.120 --> 02:25:17.360
this is true of San Francisco's,
it's true in Boston,

02:25:17.360 --> 02:25:19.410
they want to keep, not only six feet away,

02:25:19.410 --> 02:25:21.760
but stay at home and never touch you.

02:25:21.760 --> 02:25:24.680
That loss of basic humanity

02:25:24.680 --> 02:25:29.370
is the opposite of what I feel in Jujitsu,

02:25:29.370 --> 02:25:33.621
where it was like that
contact where you're like,

02:25:33.621 --> 02:25:34.940
I don't give a shit

02:25:34.940 --> 02:25:37.450
about whatever rules we're
supposed to have in society

02:25:37.450 --> 02:25:39.420
where you have to keep a distance

02:25:39.420 --> 02:25:40.480
and all that kind of stuff.

02:25:40.480 --> 02:25:41.860
Just the hug,

02:25:41.860 --> 02:25:46.470
like the intimacy of a hug,
that's like a good bear hug,

02:25:46.470 --> 02:25:49.750
and you're like just
controlling another person,

02:25:49.750 --> 02:25:52.140
and also there is some
kind of love communicated

02:25:52.140 --> 02:25:54.205
through just trying to
break each other's arms.

02:25:54.205 --> 02:25:56.024
I don't exactly understand

02:25:56.024 --> 02:26:01.024
why violence is the such
a close neighbor to love,

02:26:01.240 --> 02:26:02.227
but it is.

02:26:02.227 --> 02:26:04.800
- Well, in the hypothalamus,

02:26:04.800 --> 02:26:08.270
the neurons that control sexual behavior,

02:26:08.270 --> 02:26:11.018
but also non-sexual contact,

02:26:11.018 --> 02:26:13.560
are not just nearby the neurons

02:26:13.560 --> 02:26:15.810
that control aggression and fighting,

02:26:15.810 --> 02:26:19.172
they are salt and pepper
with those neurons.

02:26:19.172 --> 02:26:21.580
It's a very interesting,

02:26:21.580 --> 02:26:23.160
and it almost sounds

02:26:23.160 --> 02:26:25.070
kind of risky and controversial and stuff,

02:26:25.070 --> 02:26:27.870
I'm not anthropomorphizing
about what this means,

02:26:27.870 --> 02:26:32.486
but in the brain, those
structures are interdigitated,

02:26:32.486 --> 02:26:36.040
you can't separate them
except at a very fine level.

02:26:36.040 --> 02:26:37.750
And here, the way you describe it,

02:26:37.750 --> 02:26:39.740
is the same as a real thing.

02:26:39.740 --> 02:26:42.990
- I do want to make an
interesting comment.

02:26:42.990 --> 02:26:43.823
Again, these are the things

02:26:43.823 --> 02:26:45.690
that could be taken out of context,

02:26:45.690 --> 02:26:50.570
but one of the amazing
things about Jujitsu,

02:26:50.570 --> 02:26:52.283
is both guys and girls train it.

02:26:53.140 --> 02:26:54.409
And I was surprised.

02:26:54.409 --> 02:26:59.313
So, like I'm a big fan
of yoga pants [giggles]

02:26:59.313 --> 02:27:01.040
at the gym kind of thing.

02:27:01.040 --> 02:27:04.810
It reveals the beauty of the female form.

02:27:04.810 --> 02:27:06.240
But the thing is,

02:27:06.240 --> 02:27:08.800
like girls are dressed
in skintight clothes

02:27:08.800 --> 02:27:10.210
in Jujitsu often.

02:27:10.210 --> 02:27:12.620
And I found myself not at all,

02:27:12.620 --> 02:27:15.030
thinking like that at all
when training with girls.

02:27:15.030 --> 02:27:17.190
- Well, the context is very non-sexual.

02:27:17.190 --> 02:27:19.636
- But I was surprised to learn that.

02:27:19.636 --> 02:27:21.190
When I first started to Jujitsu,

02:27:21.190 --> 02:27:22.690
I thought, wouldn't that be kind of weird

02:27:22.690 --> 02:27:25.279
to train with the opposites
that in something so intimate.

02:27:25.279 --> 02:27:27.880
- So, boys and girls, men and women,

02:27:27.880 --> 02:27:30.560
they roll Jujitsu together?

02:27:30.560 --> 02:27:31.440
- Completely.
- Interesting.

02:27:31.440 --> 02:27:34.894
- And the only times girls kind
of try to stay away from guys,

02:27:34.894 --> 02:27:36.440
I mean, there's two contexts,

02:27:36.440 --> 02:27:38.890
of course, there's always going
to be creeps in this world.

02:27:38.890 --> 02:27:42.270
So, everyone knows who
kind of stay away from,

02:27:42.270 --> 02:27:44.310
and the other is there's a size disparity.

02:27:44.310 --> 02:27:46.290
So, girls will often
try to roll with people

02:27:46.290 --> 02:27:48.310
a little bit closer weight-wise,

02:27:48.310 --> 02:27:51.130
But no, that's one of the things

02:27:51.130 --> 02:27:52.689
that are empowering to women,

02:27:52.689 --> 02:27:54.300
that's what they fall in love with

02:27:54.300 --> 02:27:55.530
when they started doing Jujitsu,

02:27:55.530 --> 02:27:57.310
is first of all,

02:27:57.310 --> 02:28:00.270
they gain an awareness and
a pride over their body,

02:28:00.270 --> 02:28:01.103
which is great.

02:28:01.103 --> 02:28:02.906
And then second, they get to [chuckles]

02:28:02.906 --> 02:28:05.980
especially later on,
start submitting big dudes

02:28:05.980 --> 02:28:09.280
like these bros that come in

02:28:09.280 --> 02:28:11.330
who are all shredded and like muscular,

02:28:11.330 --> 02:28:16.100
and they get to technique to
exercise dominance over them,

02:28:16.100 --> 02:28:17.364
and that's a powerful feeling.

02:28:17.364 --> 02:28:21.570
- You've seen women force
a larger guy to tap her,

02:28:21.570 --> 02:28:22.460
or even choke them up.

02:28:22.460 --> 02:28:26.287
- Well, I was deadlifting like a four,

02:28:29.530 --> 02:28:31.580
oh boy, I think it's 495.

02:28:31.580 --> 02:28:33.160
So, I was really into power-lifting

02:28:33.160 --> 02:28:35.030
when I started at Jujitsu,

02:28:35.030 --> 02:28:37.440
and I remember being submitted by,

02:28:37.440 --> 02:28:40.670
I thought I walked in
feeling like I'm going to be,

02:28:40.670 --> 02:28:43.030
if not the greatest fighter
ever, at least top three.

02:28:43.030 --> 02:28:47.450
And so, as a white belt,
you roll in like all happy.

02:28:47.450 --> 02:28:48.639
And then you realize

02:28:48.639 --> 02:28:51.770
that as long as you're not
applying too much force,

02:28:51.770 --> 02:28:52.603
that you're having,

02:28:52.603 --> 02:28:54.390
I remember being submitted many times

02:28:54.390 --> 02:28:56.829
by like 130, 120-pound girls

02:28:56.829 --> 02:28:59.900
at our Balance Studios in Philadelphia,

02:28:59.900 --> 02:29:02.096
that a lot of incredible
female Jujitsu players.

02:29:02.096 --> 02:29:03.854
And that's really humbling too

02:29:03.854 --> 02:29:08.854
that technique can overpower
in combat pure strength.

02:29:11.870 --> 02:29:13.650
And that's the other thing,

02:29:13.650 --> 02:29:18.160
there is something about
combat that's primal.

02:29:18.160 --> 02:29:21.113
Like there, it just feels,

02:29:22.070 --> 02:29:26.500
it feels like we were born to do this.

02:29:26.500 --> 02:29:27.333
Like that-

02:29:27.333 --> 02:29:28.624
- We have circuits in our brain

02:29:28.624 --> 02:29:32.420
that are dedicated to
this kind of interaction.

02:29:32.420 --> 02:29:34.110
There's no question.

02:29:34.110 --> 02:29:35.450
- And that's what it felt like,

02:29:35.450 --> 02:29:38.960
it wasn't that I'm learning a new skill.

02:29:38.960 --> 02:29:39.793
It was like,

02:29:39.793 --> 02:29:42.840
somehow I am a remembering echoes

02:29:42.840 --> 02:29:44.440
of something I've learned in the past.

02:29:44.440 --> 02:29:45.690
- Well, it's like hitting puberty.

02:29:45.690 --> 02:29:47.800
A child before puberty has no concept

02:29:47.800 --> 02:29:51.040
of boys and girls having this attraction,

02:29:51.040 --> 02:29:52.650
regardless of whether
or not they're attracted

02:29:52.650 --> 02:29:53.690
to boys or girl, doesn't matter.

02:29:53.690 --> 02:29:55.630
At some point, most people, not all,

02:29:55.630 --> 02:29:58.400
but certainly, but most
people, when they hit puberty,

02:29:58.400 --> 02:30:00.991
suddenly people appear differently,

02:30:00.991 --> 02:30:05.580
and certain people take on a
romantic or sexual interest

02:30:05.580 --> 02:30:07.200
for the very first time.

02:30:07.200 --> 02:30:08.033
- Yeah.

02:30:08.033 --> 02:30:08.866
- And so it's like,

02:30:08.866 --> 02:30:10.736
it's revealing a circuitry in the brain.

02:30:10.736 --> 02:30:14.360
It's not like they learn that it's innate.

02:30:14.360 --> 02:30:15.193
And I think it,

02:30:15.193 --> 02:30:17.407
when I hear the way you describe Jujitsu

02:30:18.450 --> 02:30:19.950
and enrolling Jujitsu,

02:30:19.950 --> 02:30:21.110
it reminds me a little bit,

02:30:21.110 --> 02:30:22.083
Joe was telling me recently

02:30:22.083 --> 02:30:24.470
about the first time he went hunting

02:30:24.470 --> 02:30:26.374
and he felt like it revealed a circuit

02:30:26.374 --> 02:30:28.560
that was in him all along,

02:30:28.560 --> 02:30:30.950
but he hadn't experienced before.

02:30:30.950 --> 02:30:31.783
- Yeah.

02:30:31.783 --> 02:30:32.616
That's definitely there.

02:30:32.616 --> 02:30:34.960
And of course, there's
the physical activity.

02:30:34.960 --> 02:30:37.443
One of the interesting
things about Jujitsu

02:30:37.443 --> 02:30:40.643
is it's one of the really
strenuous exercises

02:30:40.643 --> 02:30:43.920
that you can do late into your adult life,

02:30:43.920 --> 02:30:47.011
like into your 50, 60, 70s, 80s.

02:30:47.011 --> 02:30:49.220
When I came up,

02:30:49.220 --> 02:30:51.400
there's a few people in
their 80s that were training.

02:30:51.400 --> 02:30:53.130
And as long as you're smart,

02:30:53.130 --> 02:30:54.890
as long as you practice techniques

02:30:54.890 --> 02:30:55.980
and pick your partners correctly,

02:30:55.980 --> 02:30:57.340
you can do that kind of art.

02:30:57.340 --> 02:30:58.173
That's late into life.

02:30:58.173 --> 02:30:59.570
And so you're getting exercise.

02:30:59.570 --> 02:31:01.920
There's not many activities I find

02:31:01.920 --> 02:31:04.520
that are amenable to that.

02:31:04.520 --> 02:31:08.170
So, because it's such a thinking game,

02:31:08.170 --> 02:31:10.910
the Jujitsu in particular is an art

02:31:10.910 --> 02:31:13.026
or technique pays off a lot.

02:31:13.026 --> 02:31:15.707
So you can still maintain,

02:31:15.707 --> 02:31:20.707
first of all, remain injury
free if you use good technique,

02:31:20.860 --> 02:31:25.860
and also through good
technique be able to go,

02:31:25.930 --> 02:31:28.066
be active with people that
are much, much younger.

02:31:28.066 --> 02:31:30.610
And so that was, to me,

02:31:30.610 --> 02:31:32.510
that and running are the two activities

02:31:32.510 --> 02:31:33.870
you can kind of do late in life.

02:31:33.870 --> 02:31:36.230
Because to me a healthy life

02:31:36.230 --> 02:31:39.400
has exercises as the piece of the puzzle.

02:31:39.400 --> 02:31:40.440
- No, absolutely.

02:31:40.440 --> 02:31:42.750
And I'm glad that we're
on the physical component,

02:31:42.750 --> 02:31:47.750
because I know that there's for you,

02:31:47.990 --> 02:31:49.710
you've talked before about the crossover

02:31:49.710 --> 02:31:52.560
between the physical and the
intellectual and the mental.

02:31:55.030 --> 02:31:57.710
Are you still running at
ridiculous hours of the night

02:31:57.710 --> 02:31:59.650
for ridiculously long?

02:31:59.650 --> 02:32:01.550
- Yeah, so, definitely.

02:32:01.550 --> 02:32:03.540
I've been running late
at night here in Austin.

02:32:03.540 --> 02:32:04.529
People tell,

02:32:04.529 --> 02:32:05.840
the area we're in now,

02:32:05.840 --> 02:32:07.270
people say it's a dangerous area,

02:32:07.270 --> 02:32:10.630
which I find laughable coming
from the bigger cities.

02:32:10.630 --> 02:32:12.830
No, I run late at night.

02:32:12.830 --> 02:32:14.213
There's something.

02:32:15.200 --> 02:32:17.900
- If you see a guy running
through Austin at 2:00 a.m.

02:32:19.368 --> 02:32:20.201
in a suit and tie, it's probably.

02:32:20.201 --> 02:32:22.250
[Lex laughing]

02:32:22.250 --> 02:32:23.083
- Well, yeah.

02:32:23.083 --> 02:32:24.110
I mean, I do think about that

02:32:24.110 --> 02:32:26.670
'cause I get recognized
more and more in Austin.

02:32:26.670 --> 02:32:27.847
I worry that,

02:32:27.847 --> 02:32:29.080
but not really,

02:32:29.080 --> 02:32:30.880
that I get recognized late at night.

02:32:32.630 --> 02:32:35.030
But there is something about the night

02:32:36.650 --> 02:32:39.000
that brings out those deep
philosophical thoughts

02:32:39.000 --> 02:32:40.760
and self-reflection, that really enjoy.

02:32:40.760 --> 02:32:44.590
But recently I started
getting back to the grind.

02:32:44.590 --> 02:32:46.490
So I'm going to be competing

02:32:46.490 --> 02:32:50.060
or hoping to be compete
in September and October.

02:32:50.060 --> 02:32:50.893
- In Jujitsu?

02:32:50.893 --> 02:32:51.726
- In Jujitsu, yeah.

02:32:51.726 --> 02:32:52.782
To get back to competition.

02:32:52.782 --> 02:32:57.782
And so that requires getting
back into a great cardio shape.

02:32:58.630 --> 02:32:59.870
I've been getting,

02:32:59.870 --> 02:33:02.340
running as part of my daily routine.

02:33:02.340 --> 02:33:03.230
- Got it.

02:33:03.230 --> 02:33:04.215
- [Lex] Yeah.

02:33:04.215 --> 02:33:05.180
- Well, I always know I can reach you

02:33:05.180 --> 02:33:07.690
regardless of time zone in
the middle of the night,

02:33:07.690 --> 02:33:09.370
wherever that happens.

02:33:09.370 --> 02:33:11.160
- Well, part of that has
to be just being single

02:33:11.160 --> 02:33:13.589
and being a programmer.

02:33:13.589 --> 02:33:16.100
Those two things just don't work well

02:33:16.100 --> 02:33:18.090
in terms of a steady sleep schedule.

02:33:18.090 --> 02:33:20.100
- It's not bankers hours kind of work.

02:33:20.100 --> 02:33:21.500
Nine to five.

02:33:21.500 --> 02:33:23.310
I want to, you mentioned single.

02:33:23.310 --> 02:33:24.880
I want to ask you a little bit

02:33:24.880 --> 02:33:26.440
about the other form of relationship,

02:33:26.440 --> 02:33:28.973
which is romantic love.

02:33:29.890 --> 02:33:32.410
So, your parents are still married?

02:33:32.410 --> 02:33:33.243
- Still married,

02:33:33.243 --> 02:33:34.160
still happily married.

02:33:34.160 --> 02:33:34.993
- That's impressive.

02:33:34.993 --> 02:33:35.826
- [Lex] Yeah.

02:33:35.826 --> 02:33:36.660
- A rare thing nowadays.

02:33:36.660 --> 02:33:37.493
- [Lex] Yeah.

02:33:37.493 --> 02:33:39.010
- So you grew up with that example?

02:33:39.010 --> 02:33:39.843
- Yeah.

02:33:39.843 --> 02:33:40.950
I guess that's a powerful thing, right?

02:33:40.950 --> 02:33:43.150
If there's an example
that I think can work.

02:33:44.841 --> 02:33:45.674
- Yeah.

02:33:45.674 --> 02:33:46.540
I didn't have that in my own family,

02:33:46.540 --> 02:33:49.785
but when I see it,

02:33:49.785 --> 02:33:52.070
it's inspiring and it's beautiful.

02:33:52.070 --> 02:33:53.247
The fact that they have that,

02:33:53.247 --> 02:33:55.070
and that was the norm for you,

02:33:55.070 --> 02:33:56.900
I think is really wonderful.

02:33:56.900 --> 02:33:58.040
- Well, it was a,

02:33:58.040 --> 02:34:00.120
in the case of my parents
it was interesting to watch

02:34:00.120 --> 02:34:03.270
'cause there's obviously tension.

02:34:03.270 --> 02:34:04.960
Like, there'll be times where they fought

02:34:04.960 --> 02:34:06.752
and all those kinds of things.

02:34:06.752 --> 02:34:11.752
They obviously get frustrated
with each other and they like,

02:34:11.780 --> 02:34:13.360
but they find mechanisms

02:34:13.360 --> 02:34:15.040
how to communicate that to each other,

02:34:15.040 --> 02:34:16.560
like to make fun of
each other a little bit,

02:34:16.560 --> 02:34:19.440
like to tease, to get some
of that frustration out,

02:34:19.440 --> 02:34:21.040
and then ultimately to reunite

02:34:21.040 --> 02:34:23.530
and find their joyful moments

02:34:23.530 --> 02:34:25.330
and be that the energy.

02:34:25.330 --> 02:34:26.600
I think it's clear

02:34:26.600 --> 02:34:28.870
'cause I got together in
there I think early 20s,

02:34:28.870 --> 02:34:29.913
like very, very young.

02:34:29.913 --> 02:34:32.460
I think you grow together as people.

02:34:32.460 --> 02:34:33.579
- Yeah.

02:34:33.579 --> 02:34:35.504
You're still in the critical
period of brain plasticity.

02:34:35.504 --> 02:34:37.090
[laughing]

02:34:37.090 --> 02:34:38.490
- And also, I mean,

02:34:38.490 --> 02:34:42.310
it's just like divorce was so frowned upon

02:34:42.310 --> 02:34:43.532
that you stick it out.

02:34:43.532 --> 02:34:45.920
And I think a lot of couples
especially from that time,

02:34:45.920 --> 02:34:46.753
the Soviet Union,

02:34:46.753 --> 02:34:48.324
that's probably applies
to a lot of cultures.

02:34:48.324 --> 02:34:50.670
You stick it out and you put in the work,

02:34:50.670 --> 02:34:52.360
you learn how to put in the work.

02:34:52.360 --> 02:34:53.310
And once you do,

02:34:53.310 --> 02:34:54.230
you start to get to

02:34:54.230 --> 02:34:56.653
some of those rewarding aspects of being,

02:34:57.882 --> 02:35:00.803
like through time has sharing
so many moments together.

02:35:01.930 --> 02:35:06.930
That's definitely something
that was an inspiration to me,

02:35:07.860 --> 02:35:09.740
but maybe that's where I have.

02:35:09.740 --> 02:35:11.390
So I have a similar kind of longing

02:35:11.390 --> 02:35:12.860
to have a lifelong partner,

02:35:12.860 --> 02:35:14.940
like to have that kind of view,

02:35:14.940 --> 02:35:16.790
where same with friendship,

02:35:16.790 --> 02:35:20.650
lifelong friendship is
the most meaningful kind.

02:35:20.650 --> 02:35:22.090
That there is something with that time

02:35:22.090 --> 02:35:23.716
of sharing all that time together.

02:35:23.716 --> 02:35:26.850
Like till death do us
part is a powerful thing.

02:35:26.850 --> 02:35:27.690
Not by force,

02:35:27.690 --> 02:35:29.250
not because of the religion said it

02:35:29.250 --> 02:35:31.620
or the government said it
or your culture said it,

02:35:31.620 --> 02:35:33.290
but because you want to.

02:35:33.290 --> 02:35:34.560
- Do you want children?

02:35:34.560 --> 02:35:35.960
- Definitely, yeah.

02:35:35.960 --> 02:35:37.373
Definitely want children.

02:35:38.420 --> 02:35:39.253
It's-

02:35:39.253 --> 02:35:41.470
- How many Roombas do you have?

02:35:41.470 --> 02:35:42.303
- Oh, I thought-

02:35:42.303 --> 02:35:43.136
- You should, no, no-

02:35:43.136 --> 02:35:44.042
- Human children?

02:35:44.042 --> 02:35:44.875
- No, human to human children.

02:35:44.875 --> 02:35:45.708
- 'Cause I already have the children.

02:35:45.708 --> 02:35:46.541
- Exactly.

02:35:46.541 --> 02:35:47.418
What I was saying,

02:35:47.418 --> 02:35:48.840
you probably need to at
least as many human children

02:35:48.840 --> 02:35:49.673
as you do Roombas.

02:35:49.673 --> 02:35:51.003
Big family, small family.

02:35:53.184 --> 02:35:54.017
- So.

02:35:54.017 --> 02:35:54.850
- In your mind's eyes,

02:35:54.850 --> 02:35:59.170
they're a bunch of
Fridman's running around.

02:35:59.170 --> 02:36:01.270
- So I'll tell you, like realistically,

02:36:01.270 --> 02:36:03.740
I can explain exactly my thinking,

02:36:03.740 --> 02:36:07.440
and this is similar to
the robotics work is,

02:36:07.440 --> 02:36:10.130
if I'm like purely logical right now,

02:36:10.130 --> 02:36:12.390
my answer would be I don't want kids.

02:36:12.390 --> 02:36:15.760
Because I just don't have enough time.

02:36:15.760 --> 02:36:17.320
I have so much going on.

02:36:17.320 --> 02:36:19.610
But when I'm using the
same kind of vision I use

02:36:19.610 --> 02:36:20.770
for the robots

02:36:20.770 --> 02:36:25.030
is I know my life will be
transformed with the first.

02:36:25.030 --> 02:36:27.670
Like I know I would love being a father.

02:36:27.670 --> 02:36:29.689
And so the question of how many,

02:36:29.689 --> 02:36:32.961
that's on the other side of that hill.

02:36:32.961 --> 02:36:35.930
It could be some ridiculous number.

02:36:35.930 --> 02:36:37.010
So I just know that-

02:36:37.010 --> 02:36:38.670
- I have a feeling and I could be,

02:36:38.670 --> 02:36:42.660
I don't have a crystal
ball, but I don't know.

02:36:42.660 --> 02:36:44.800
I see an upwards of,

02:36:44.800 --> 02:36:47.850
certainly three or more
come comes to mind.

02:36:47.850 --> 02:36:49.538
- So much of that has to do

02:36:49.538 --> 02:36:51.960
with the partner you're with too.

02:36:51.960 --> 02:36:55.127
So like that, that's
such an open question,

02:36:55.127 --> 02:36:58.595
especially in this society of
what the right partnership is.

02:36:58.595 --> 02:37:02.850
'Cause I'm deeply empathetic.

02:37:02.850 --> 02:37:05.150
I want to see, like to me,

02:37:05.150 --> 02:37:06.630
what I look for in your relationship

02:37:06.630 --> 02:37:09.810
is for me to be really excited

02:37:09.810 --> 02:37:12.110
about the passions of another person,

02:37:12.110 --> 02:37:13.070
like whatever they're into,

02:37:13.070 --> 02:37:15.770
it doesn't have to be a career success.

02:37:15.770 --> 02:37:16.900
Any kind of success,

02:37:16.900 --> 02:37:18.490
just to be excited for them,

02:37:18.490 --> 02:37:20.570
and for them to be excited for me.

02:37:20.570 --> 02:37:22.480
And like share in that
excitement and build,

02:37:22.480 --> 02:37:23.399
and build and build.

02:37:23.399 --> 02:37:25.840
But there was also
practical aspects of like,

02:37:25.840 --> 02:37:28.677
what kind of shit do you
enjoy doing together?

02:37:28.677 --> 02:37:32.564
And I think family is a
real serious undertaking.

02:37:32.564 --> 02:37:34.070
- It certainly is.

02:37:34.070 --> 02:37:37.520
I mean, I think that I
have a friend who said it,

02:37:37.520 --> 02:37:38.353
I think best,

02:37:38.353 --> 02:37:41.260
which is that you first have,

02:37:41.260 --> 02:37:43.020
he's in a very successful relationship

02:37:43.020 --> 02:37:44.490
and has a family.

02:37:44.490 --> 02:37:45.323
And he said,

02:37:45.323 --> 02:37:47.510
you first have to define the role

02:37:47.510 --> 02:37:49.954
and then you have to cast the
right person for the role.

02:37:49.954 --> 02:37:51.410
[Lex laughing]

02:37:51.410 --> 02:37:53.827
- Well, yeah, there's
some deep aspects of that,

02:37:53.827 --> 02:37:58.320
but there's also an aspect to
which you're not smart enough

02:37:58.320 --> 02:38:02.770
from this side of it to define the role.

02:38:02.770 --> 02:38:04.870
I think there's part of
it that has to be a leap

02:38:04.870 --> 02:38:06.550
that you have to take.

02:38:06.550 --> 02:38:11.550
And I see having kids that way.

02:38:12.160 --> 02:38:16.150
You just have to go with
it and figure it out also.

02:38:16.150 --> 02:38:17.680
As long as there's love there,

02:38:17.680 --> 02:38:20.620
like what the hell is life for even?

02:38:20.620 --> 02:38:21.900
So I've,

02:38:21.900 --> 02:38:25.320
there's so many incredibly
successful people that I know

02:38:26.350 --> 02:38:29.000
that I've gotten to
know that all have kids.

02:38:29.000 --> 02:38:32.344
And the presence of kids for the most part

02:38:32.344 --> 02:38:36.640
has only been something
that energizes them,

02:38:36.640 --> 02:38:37.930
something they gave them meaning,

02:38:37.930 --> 02:38:40.240
something that made them the
best version of themselves,

02:38:40.240 --> 02:38:42.420
like made them more productive, not less,

02:38:42.420 --> 02:38:43.470
which is fascinating to me.

02:38:43.470 --> 02:38:44.520
- It is fascinating.

02:38:44.520 --> 02:38:45.353
I mean, you can imagine

02:38:45.353 --> 02:38:47.290
if the way that you felt about Homer,

02:38:47.290 --> 02:38:49.790
the way that I feel
and felt about Costello

02:38:49.790 --> 02:38:54.650
is at all a glimpse of what
that must be like then.

02:38:54.650 --> 02:38:55.483
- Exactly.

02:38:56.450 --> 02:38:57.760
The downside,

02:38:57.760 --> 02:39:02.747
the thing I worry more about
is the partner side of that.

02:39:04.610 --> 02:39:05.513
I've seen,

02:39:06.350 --> 02:39:07.870
the kids are almost universally

02:39:07.870 --> 02:39:11.750
a source of increased productivity
and joy and happiness.

02:39:11.750 --> 02:39:13.310
Like, yeah, they're a pain in the ass.

02:39:13.310 --> 02:39:14.143
Yeah, is complicated.

02:39:14.143 --> 02:39:17.480
Yeah, so and so forth, people
like to complain about kids.

02:39:17.480 --> 02:39:19.650
But then when you actually look past

02:39:19.650 --> 02:39:22.980
that little shallow layer of
complaint, kids are great.

02:39:22.980 --> 02:39:24.810
The source of pain for a lot of people

02:39:24.810 --> 02:39:27.620
is if when the relationship doesn't work.

02:39:27.620 --> 02:39:31.420
And so I'm very kind of
concerned about like,

02:39:32.640 --> 02:39:33.940
dating is very difficult,

02:39:33.940 --> 02:39:36.600
and I'm a complicated person.

02:39:36.600 --> 02:39:38.270
And so it's been very difficult

02:39:38.270 --> 02:39:41.575
to find the right kind of person.

02:39:41.575 --> 02:39:45.080
But that statement doesn't even make sense

02:39:45.080 --> 02:39:48.300
because I'm not on dating
apps, I don't see people.

02:39:48.300 --> 02:39:50.420
You're like the first
person I saw in awhile.

02:39:50.420 --> 02:39:53.080
It's like you and Michael
Malice and like Joe.

02:39:53.080 --> 02:39:57.717
So, like, I don't think
I've seen like a female.

02:39:59.880 --> 02:40:00.890
What is it?

02:40:00.890 --> 02:40:03.710
An element of the female
species in quite a while.

02:40:03.710 --> 02:40:06.560
So, I think you have to
put yourself out there.

02:40:06.560 --> 02:40:07.480
What is it?

02:40:07.480 --> 02:40:10.049
Daniel Johnston says,
true love will find you,

02:40:10.049 --> 02:40:11.780
but only if you're looking.

02:40:11.780 --> 02:40:13.720
So there's some element
of really taking the leap

02:40:13.720 --> 02:40:14.720
and putting yourself out there

02:40:14.720 --> 02:40:17.030
in kind of different situations.

02:40:17.030 --> 02:40:18.460
And I don't know how to do that

02:40:18.460 --> 02:40:20.500
when you're behind a
computer all the time.

02:40:20.500 --> 02:40:25.240
- Well, you're a builder
and you're a problem solver,

02:40:25.240 --> 02:40:29.050
and you find solutions,

02:40:29.050 --> 02:40:34.050
and I'm confident the
solution is out there, and.

02:40:34.569 --> 02:40:35.402
- I think you're implying

02:40:35.402 --> 02:40:38.568
that I'm going to build the
girlfriend, which I think.

02:40:38.568 --> 02:40:43.057
- Well, and maybe we shouldn't
separate this friendship,

02:40:43.057 --> 02:40:45.500
the notion of friendship and community,

02:40:45.500 --> 02:40:48.950
and if we go back to this
concept of the aggregate,

02:40:48.950 --> 02:40:52.132
maybe you'll meet this
woman through a friend,

02:40:52.132 --> 02:40:53.653
or maybe you'll or something of that sort.

02:40:53.653 --> 02:40:55.253
- So, one of the things,

02:40:55.253 --> 02:40:56.950
I dunno if you feel the same way,

02:40:56.950 --> 02:41:01.550
I definitely one of those
people that just falls in love

02:41:01.550 --> 02:41:02.510
and that's it.

02:41:02.510 --> 02:41:04.030
- Yeah, I can't say I'm like that.

02:41:04.030 --> 02:41:06.620
With Costello it was instantaneous.

02:41:06.620 --> 02:41:07.453
- Yeah.

02:41:07.453 --> 02:41:08.286
- It really was.

02:41:08.286 --> 02:41:09.720
I mean, I know it's not romantic love,

02:41:09.720 --> 02:41:10.770
but it was instantaneous.

02:41:10.770 --> 02:41:12.447
No, I, but that's me.

02:41:12.447 --> 02:41:14.720
And I think that if you know, you know,

02:41:14.720 --> 02:41:18.457
because that's a good
thing that you have there.

02:41:18.457 --> 02:41:21.780
- It's, I'm very careful with that,

02:41:21.780 --> 02:41:24.880
because you don't want to fall
in love with the wrong person.

02:41:24.880 --> 02:41:27.590
So I try to be very kind of careful with,

02:41:27.590 --> 02:41:29.480
I've noticed this because
I fall in love with every,

02:41:29.480 --> 02:41:30.560
like this mug,

02:41:30.560 --> 02:41:34.050
everything I fall in love
with things in this world.

02:41:34.050 --> 02:41:35.550
So, like, you have to be really careful

02:41:35.550 --> 02:41:40.550
because a girl comes up to you and says

02:41:41.080 --> 02:41:42.443
she loves DUSTY HUSKY,

02:41:43.929 --> 02:41:46.740
that doesn't necessarily
mean to marry her tonight.

02:41:46.740 --> 02:41:47.573
- Yes.

02:41:47.573 --> 02:41:49.100
And I like the way you said that out loud

02:41:49.100 --> 02:41:50.000
so that you heard it,

02:41:50.000 --> 02:41:52.620
you doesn't mean you need
to marry her tonight, right?

02:41:52.620 --> 02:41:53.453
- [Lex] Exactly.

02:41:53.453 --> 02:41:54.447
- [Andrew] Right.

02:41:54.447 --> 02:41:56.140
- But I mean, but people are amazing,

02:41:56.140 --> 02:41:58.190
and people are beautiful and that's,

02:41:58.190 --> 02:42:00.457
so I'm fully embraced that,

02:42:00.457 --> 02:42:02.970
but also you have to be
careful with relationships.

02:42:02.970 --> 02:42:03.912
And at the same time,

02:42:03.912 --> 02:42:06.883
like I mentioned to you offline, I don't,

02:42:07.840 --> 02:42:08.930
there's something about me

02:42:08.930 --> 02:42:13.680
that appreciates swinging for
the fences and not dating,

02:42:13.680 --> 02:42:15.503
like doing serial
dating, or dating around.

02:42:15.503 --> 02:42:17.610
- Like you're a one guy,
one girl kind of guy.

02:42:17.610 --> 02:42:18.443
- [Lex] Yeah.

02:42:18.443 --> 02:42:19.276
- And you said that.

02:42:19.276 --> 02:42:21.100
- And it's tricky

02:42:21.100 --> 02:42:23.900
because you want to be careful
with that kind of stuff.

02:42:23.900 --> 02:42:26.086
Especially now there's a growing platform

02:42:26.086 --> 02:42:29.190
that have a ridiculous
amount of female interests

02:42:29.190 --> 02:42:31.400
of a certain kind.

02:42:31.400 --> 02:42:33.347
But I'm looking for deep connection,

02:42:33.347 --> 02:42:36.163
and I'm looking by sending home alone,

02:42:36.163 --> 02:42:40.699
and every once in a while
talking to Stanford professors.

02:42:40.699 --> 02:42:42.440
- Perfect solution.
- On a podcast.

02:42:42.440 --> 02:42:43.273
- Perfect solution.

02:42:43.273 --> 02:42:44.290
- Is going to workout great.

02:42:44.290 --> 02:42:45.340
- It's well,

02:42:45.340 --> 02:42:47.300
it's part of,

02:42:47.300 --> 02:42:49.580
that constitutes machine
learning of sorts.

02:42:49.580 --> 02:42:51.130
- Yeah, of sorts.

02:42:51.130 --> 02:42:51.963
- I do,

02:42:51.963 --> 02:42:55.890
you mentioned what has now
become a quite extensive

02:42:55.890 --> 02:42:59.300
and expansive public
platform, which is incredible.

02:42:59.300 --> 02:43:01.300
I mean, the number of people out,

02:43:01.300 --> 02:43:02.390
first time I saw your podcast,

02:43:02.390 --> 02:43:03.570
I noticed the suit,

02:43:03.570 --> 02:43:05.500
I was like, he respects his
audience, which was great,

02:43:05.500 --> 02:43:08.055
but I also thought this is amazing.

02:43:08.055 --> 02:43:10.790
People are showing up for
science and engineering

02:43:10.790 --> 02:43:12.850
and technology information
and those discussions

02:43:12.850 --> 02:43:14.160
and other sorts of discussions.

02:43:14.160 --> 02:43:18.140
Now, I do want to talk for
a moment about the podcast.

02:43:18.140 --> 02:43:21.760
So my two questions about the podcast are,

02:43:21.760 --> 02:43:24.340
when you started it, did you have a plan?

02:43:24.340 --> 02:43:26.988
And regardless of what that answer is,

02:43:26.988 --> 02:43:29.870
do you know where you're taking it,

02:43:29.870 --> 02:43:31.758
or would you like to leave us?

02:43:31.758 --> 02:43:35.250
I do believe in an element
of surprise is always fun.

02:43:35.250 --> 02:43:36.440
But what about the podcast?

02:43:36.440 --> 02:43:37.710
Do you enjoy the podcast?

02:43:37.710 --> 02:43:40.380
I mean, your audience
certainly includes me,

02:43:40.380 --> 02:43:41.760
really enjoys the podcast.

02:43:41.760 --> 02:43:42.670
It's incredible.

02:43:42.670 --> 02:43:46.590
- So I love talking to people,

02:43:46.590 --> 02:43:50.230
and there's something about microphones

02:43:50.230 --> 02:43:51.950
that really bring out the best in people.

02:43:51.950 --> 02:43:54.530
Like you don't get a
chance to talk like this.

02:43:54.530 --> 02:43:56.130
If you and I were just hanging out,

02:43:56.130 --> 02:43:57.724
we would have a very
different conversation

02:43:57.724 --> 02:44:01.910
in the amount of focus we
allocate to each other.

02:44:01.910 --> 02:44:04.420
We would be having fun
talking about other stuff

02:44:04.420 --> 02:44:05.726
and doing other things.

02:44:05.726 --> 02:44:07.520
There'll be a lot of distraction.

02:44:07.520 --> 02:44:11.070
There would be some phone use
and all that kind of stuff.

02:44:11.070 --> 02:44:14.020
But here we're 100% focused on each other

02:44:14.020 --> 02:44:16.050
and focus on the idea.

02:44:16.050 --> 02:44:18.240
And like sometimes playing with ideas

02:44:18.240 --> 02:44:21.130
that we both don't know the answer to,

02:44:21.130 --> 02:44:23.120
like a question we don't
know the answer to.

02:44:23.120 --> 02:44:24.400
We're both like fumbling with it,

02:44:24.400 --> 02:44:25.530
trying to figure out,

02:44:25.530 --> 02:44:27.150
trying to get some insights

02:44:27.150 --> 02:44:29.560
at something we haven't
really figured out before

02:44:29.560 --> 02:44:31.310
and together arriving at that.

02:44:31.310 --> 02:44:32.440
I think that's magical.

02:44:32.440 --> 02:44:34.240
I don't know why we need
microphones for that,

02:44:34.240 --> 02:44:35.280
but we somehow do.

02:44:35.280 --> 02:44:36.780
- It feels like doing science.

02:44:36.780 --> 02:44:38.760
- It feels like doing
science for me, definitely.

02:44:38.760 --> 02:44:40.222
That's exactly it.

02:44:40.222 --> 02:44:42.360
And I'm really glad you said that

02:44:42.360 --> 02:44:45.553
because I don't actually often say this,

02:44:45.553 --> 02:44:48.124
but that's exactly what I felt like.

02:44:48.124 --> 02:44:52.830
I wanted to talk to friends
and colleagues at MIT

02:44:53.970 --> 02:44:56.460
to do real science together.

02:44:56.460 --> 02:44:57.830
That's how I felt about it.

02:44:57.830 --> 02:44:59.830
Like to really talk through problems

02:44:59.830 --> 02:45:01.903
that are actually interesting,

02:45:03.150 --> 02:45:06.100
as opposed to like incremental work

02:45:06.100 --> 02:45:07.910
that we're currently working for

02:45:09.510 --> 02:45:10.890
for a particular conference.

02:45:10.890 --> 02:45:12.320
So really asking questions like,

02:45:12.320 --> 02:45:14.170
what are we doing?

02:45:14.170 --> 02:45:16.030
Like, where's this headed to?

02:45:16.030 --> 02:45:17.240
Like, what are the big,

02:45:17.240 --> 02:45:19.890
is this really going to help us solve,

02:45:19.890 --> 02:45:22.830
in the case of AI, solve intelligence?

02:45:22.830 --> 02:45:24.835
Like, is this even
working on intelligence?

02:45:24.835 --> 02:45:26.410
There's a certain sense,

02:45:26.410 --> 02:45:30.020
which is why I initially called
it artificial intelligence.

02:45:30.020 --> 02:45:32.940
Is like most of us are not working

02:45:32.940 --> 02:45:34.320
on artificial intelligence.

02:45:34.320 --> 02:45:37.720
You're working on some
very specific problem

02:45:37.720 --> 02:45:39.207
and a set of techniques,

02:45:39.207 --> 02:45:41.310
at the time it's machine learning

02:45:41.310 --> 02:45:43.010
to solve this particular problem.

02:45:43.010 --> 02:45:45.061
This is not going to take us to a system

02:45:45.061 --> 02:45:49.250
that is anywhere close
to the generalizability

02:45:49.250 --> 02:45:51.370
of the human mind.

02:45:51.370 --> 02:45:52.980
Like the kind of stuff
the human mind can do

02:45:52.980 --> 02:45:54.700
in terms of memory, in terms of cognition,

02:45:54.700 --> 02:45:55.730
in terms of reasoning,

02:45:55.730 --> 02:45:56.980
common sense reasoning.

02:45:56.980 --> 02:45:58.730
This doesn't seem to take us there.

02:45:58.730 --> 02:46:00.570
So the initial impulse was,

02:46:00.570 --> 02:46:02.541
can I talk to these folks

02:46:02.541 --> 02:46:05.239
do science together through conversation?

02:46:05.239 --> 02:46:08.663
And I also thought that
there was not enough,

02:46:11.610 --> 02:46:13.389
I didn't think there was
enough good conversations

02:46:13.389 --> 02:46:17.700
with world-class minds that I got to meet.

02:46:17.700 --> 02:46:19.850
And not the ones with the book,

02:46:19.850 --> 02:46:21.790
or like this was just the thing.

02:46:21.790 --> 02:46:24.300
Oftentimes you go on this
tour when you have a book,

02:46:24.300 --> 02:46:26.950
but there's a lot of minds
that don't write books.

02:46:26.950 --> 02:46:28.714
- And the books constrain
the conversation too,

02:46:28.714 --> 02:46:31.770
when you're talking about
this thing, this book.

02:46:31.770 --> 02:46:32.660
- But there's,

02:46:32.660 --> 02:46:34.030
I've noticed that,

02:46:34.030 --> 02:46:37.290
with people that haven't written
a book who are brilliant,

02:46:37.290 --> 02:46:40.110
we get to talk about ideas in a new way.

02:46:40.110 --> 02:46:42.650
We both haven't actually,

02:46:42.650 --> 02:46:43.810
when we raise a question,

02:46:43.810 --> 02:46:47.130
we don't know the answer to it
once the question is raised.

02:46:47.130 --> 02:46:49.013
And we try to arrive there.

02:46:49.013 --> 02:46:50.700
Like, I dunno,

02:46:50.700 --> 02:46:55.090
I remember asking questions
of world-class researchers

02:46:55.090 --> 02:46:58.260
in deep learning of,

02:46:58.260 --> 02:47:01.623
why do neural networks
work as well as they do?

02:47:02.640 --> 02:47:06.660
That question is often loosely asked,

02:47:06.660 --> 02:47:08.938
but like when you have microphones

02:47:08.938 --> 02:47:11.040
and you have to think through it,

02:47:11.040 --> 02:47:12.500
and you have 30 minutes to an hour

02:47:12.500 --> 02:47:16.150
to think through it together,
I think that's science.

02:47:16.150 --> 02:47:17.660
I think that's really powerful.

02:47:17.660 --> 02:47:19.720
So that was the one goal.

02:47:19.720 --> 02:47:20.633
The other one is,

02:47:23.546 --> 02:47:25.500
again, don't usually talk about this,

02:47:25.500 --> 02:47:28.540
but there's some sense in which I wanted

02:47:28.540 --> 02:47:30.353
to have dangerous conversations.

02:47:32.490 --> 02:47:35.500
Part of the reasons I
wanted to wear a suit

02:47:35.500 --> 02:47:37.941
is like, I want it to be fearless.

02:47:37.941 --> 02:47:40.220
The reason I don't usually talk about it

02:47:40.220 --> 02:47:43.040
is because I feel like I'm
not good at conversation.

02:47:43.040 --> 02:47:48.040
So it looks like it doesn't
match the current skill level.

02:47:48.280 --> 02:47:53.280
But I wanted to have really
dangerous conversations

02:47:53.900 --> 02:47:56.893
that I uniquely would be able to do.

02:47:58.210 --> 02:48:00.320
Not completely uniquely,

02:48:00.320 --> 02:48:02.500
but like, I'm a huge fan of Joe Rogan,

02:48:02.500 --> 02:48:04.570
and I had to ask myself,

02:48:04.570 --> 02:48:07.932
what conversations can I
do that Joe Rogan can't?

02:48:07.932 --> 02:48:10.593
For me, I know I bring this up,

02:48:12.010 --> 02:48:13.800
but for me that person I thought about

02:48:13.800 --> 02:48:15.690
at the time was Putin.

02:48:15.690 --> 02:48:17.570
Like that's why I bring him up.

02:48:17.570 --> 02:48:20.490
He's just like with Costello,

02:48:20.490 --> 02:48:22.110
he's not just a person.

02:48:22.110 --> 02:48:25.630
He's also an idea to me
for what I strive for.

02:48:25.630 --> 02:48:27.900
Just to have those
dangerous conversations.

02:48:27.900 --> 02:48:30.670
And the reason I'm uniquely qualified

02:48:30.670 --> 02:48:31.503
as both the Russian,

02:48:31.503 --> 02:48:34.080
but also there's the judo
and the martial arts,

02:48:34.080 --> 02:48:37.850
there's a lot of elements that
make me have a conversation

02:48:37.850 --> 02:48:39.168
he hasn't had before.

02:48:39.168 --> 02:48:43.200
And there's a few other people

02:48:43.200 --> 02:48:46.600
that I kept in mind, like Don Knuth,

02:48:46.600 --> 02:48:48.968
is a computer scientist from Stanford

02:48:48.968 --> 02:48:53.968
that I thought is one of the
most beautiful minds ever.

02:48:54.090 --> 02:48:57.320
And nobody really talked to him,

02:48:57.320 --> 02:48:59.540
like really talked to him.

02:48:59.540 --> 02:49:01.420
He did a few lectures, which people love,

02:49:01.420 --> 02:49:03.327
but really just have a
conversation with him.

02:49:03.327 --> 02:49:04.850
There's a few people like that.

02:49:04.850 --> 02:49:06.750
One of them passed away, John Conway,

02:49:06.750 --> 02:49:07.583
that I never got,

02:49:07.583 --> 02:49:10.690
we agreed to talk, but
he died before we did.

02:49:10.690 --> 02:49:12.000
There's a few people like that,

02:49:12.000 --> 02:49:15.730
that I thought like it's such a crime

02:49:15.730 --> 02:49:19.450
to not hear those folks.

02:49:19.450 --> 02:49:22.520
And I have the unique ability

02:49:22.520 --> 02:49:26.880
to know how to purchase
a microphone on Amazon

02:49:26.880 --> 02:49:29.480
and plug it into a
device that records audio

02:49:29.480 --> 02:49:32.090
and then publish it, which
seems relatively unique.

02:49:32.090 --> 02:49:34.750
Like that's not easy in
the scientific community.

02:49:34.750 --> 02:49:36.740
People knowing how to
plug in a microphone.

02:49:36.740 --> 02:49:37.573
- No.

02:49:37.573 --> 02:49:38.960
They can build Faraday cages,

02:49:38.960 --> 02:49:42.240
and two-photon microscopes
and bioengineer,

02:49:42.240 --> 02:49:43.080
all sorts of things,

02:49:43.080 --> 02:49:46.420
but the idea that you could take ideas

02:49:46.420 --> 02:49:49.320
and export them into a
structure or a pseudo structure

02:49:49.320 --> 02:49:50.710
that people would benefit from

02:49:50.710 --> 02:49:54.090
seems like a cosmic achievement to them.

02:49:54.090 --> 02:49:55.530
- I don't know if it's fear

02:49:55.530 --> 02:49:58.193
or just a basically they haven't tried it,

02:49:58.193 --> 02:50:00.370
so they haven't learned the skill level.

02:50:00.370 --> 02:50:01.640
- But I think they're not trained.

02:50:01.640 --> 02:50:03.410
I mean, we could riff on this for awhile,

02:50:03.410 --> 02:50:04.260
but I think that,

02:50:05.500 --> 02:50:06.370
but it's important.

02:50:06.370 --> 02:50:08.928
And maybe we should, which is that it's,

02:50:08.928 --> 02:50:11.090
they're not trained to do it.

02:50:11.090 --> 02:50:12.860
They're trained to think in specific games

02:50:12.860 --> 02:50:14.300
and specific hypotheses,

02:50:14.300 --> 02:50:17.979
and many of them don't care to, right?

02:50:17.979 --> 02:50:22.710
They became scientists because
that's where they felt safe,

02:50:22.710 --> 02:50:25.920
and so why would they
leave that Haven of safety?

02:50:25.920 --> 02:50:27.900
- Well, they also don't
necessarily always see

02:50:27.900 --> 02:50:28.800
the value in it.

02:50:28.800 --> 02:50:30.640
We're all together learning,

02:50:30.640 --> 02:50:33.780
you and I are learning the value of this.

02:50:33.780 --> 02:50:36.010
I think you're probably having

02:50:36.010 --> 02:50:39.233
an exceptionally successful
and amazing podcast

02:50:39.233 --> 02:50:40.950
that you started just recently.

02:50:40.950 --> 02:50:42.470
- Thanks to your encouragement.

02:50:42.470 --> 02:50:47.020
- Well, but there's a
raw skill there that's,

02:50:47.020 --> 02:50:49.140
you're definitely an inspiration to me

02:50:49.140 --> 02:50:50.437
in how you did the podcast

02:50:50.437 --> 02:50:52.880
in the level of excellence you reach.

02:50:52.880 --> 02:50:54.114
But I think you've discovered

02:50:54.114 --> 02:50:57.080
that that's also an
impactful way to do science.

02:50:57.080 --> 02:50:58.180
That podcast.

02:50:58.180 --> 02:51:00.240
And I think a lot of scientists

02:51:00.240 --> 02:51:02.053
have not yet discovered that.

02:51:02.053 --> 02:51:03.250
That this is a,

02:51:03.250 --> 02:51:06.900
if they apply same kind of rigor

02:51:06.900 --> 02:51:08.820
as they do to academic publication

02:51:08.820 --> 02:51:11.487
or to even conference presentations,

02:51:11.487 --> 02:51:16.180
and they do that rigor
and effort to podcast,

02:51:16.180 --> 02:51:17.013
whatever that is,

02:51:17.013 --> 02:51:18.550
that could be a five-minute podcast,

02:51:18.550 --> 02:51:19.610
a two-hour podcasts,

02:51:19.610 --> 02:51:20.717
it could be conversational,

02:51:20.717 --> 02:51:22.960
or it can be more like lecture like,

02:51:22.960 --> 02:51:24.128
if they apply that effort,

02:51:24.128 --> 02:51:26.870
you have the potential to reach over time,

02:51:26.870 --> 02:51:28.640
tens of thousands, hundreds of thousands,

02:51:28.640 --> 02:51:29.907
millions of people.

02:51:29.907 --> 02:51:32.510
And that's really, really powerful.

02:51:32.510 --> 02:51:37.510
But yeah, for me giving a
platform to a few of those folks,

02:51:39.440 --> 02:51:40.990
especially for me personally,

02:51:40.990 --> 02:51:45.990
so maybe you can speak to
what fields you're drawn to,

02:51:46.300 --> 02:51:48.970
but I thought computer scientists

02:51:51.200 --> 02:51:52.693
were especially bad at this.

02:51:53.590 --> 02:51:56.330
So there's brilliant computer scientists

02:51:56.330 --> 02:52:00.320
that I thought it would be
amazing to explore their mind,

02:52:00.320 --> 02:52:02.090
explore their thinking.

02:52:02.090 --> 02:52:05.190
And so that I took that almost as an,

02:52:05.190 --> 02:52:06.580
on as an effort.

02:52:06.580 --> 02:52:11.210
And at the same time I
had other guests in mind,

02:52:11.210 --> 02:52:13.940
or people that connect
to my own interests.

02:52:13.940 --> 02:52:15.533
So the wrestling.

02:52:16.840 --> 02:52:18.930
Wrestling, music, football,

02:52:18.930 --> 02:52:21.130
both American football and soccer.

02:52:21.130 --> 02:52:22.650
I have a few particular people

02:52:22.650 --> 02:52:24.781
that I'm really interested in.

02:52:24.781 --> 02:52:26.567
Buvaisar Saitiev.

02:52:26.567 --> 02:52:29.680
The Saitiev brothers,
even Khabib for wrestling,

02:52:29.680 --> 02:52:30.910
just to talk to them, 'cause.

02:52:30.910 --> 02:52:31.750
- Oh, 'cause you can,

02:52:31.750 --> 02:52:33.050
you guys can communicate-

02:52:33.050 --> 02:52:36.420
- In Russian and in wrestling, right?

02:52:36.420 --> 02:52:38.880
As wrestlers and as Russians.

02:52:38.880 --> 02:52:41.790
And so that little,

02:52:41.790 --> 02:52:43.763
it's like an opportunity to explore a mind

02:52:43.763 --> 02:52:47.720
that I'm able to bring to the world.

02:52:47.720 --> 02:52:50.460
And also it,

02:52:50.460 --> 02:52:53.404
I feel like it makes me a better person,

02:52:53.404 --> 02:52:55.670
just that being that vulnerable

02:52:55.670 --> 02:52:57.410
and exploring ideas together.

02:52:57.410 --> 02:52:59.850
I don't know, like good conversation.

02:52:59.850 --> 02:53:00.683
I don't know how often

02:53:00.683 --> 02:53:02.270
you have really good
conversation with friends,

02:53:02.270 --> 02:53:03.991
but like podcasts are like that.

02:53:03.991 --> 02:53:06.490
And it's deeply moving.

02:53:06.490 --> 02:53:07.960
- It's the best.

02:53:07.960 --> 02:53:09.970
And what you brought through.

02:53:09.970 --> 02:53:12.230
I mean, when I saw you
sit down with Penrose,

02:53:12.230 --> 02:53:13.980
Nobel Prize winning physicist,

02:53:13.980 --> 02:53:15.060
and these other folks that,

02:53:15.060 --> 02:53:16.340
it's not just 'cause he has a Nobel,

02:53:16.340 --> 02:53:18.070
it's what comes out of
his mouth is incredible.

02:53:18.070 --> 02:53:22.940
And what you were able to
hold in that conversation

02:53:22.940 --> 02:53:24.440
was so much better,

02:53:24.440 --> 02:53:28.910
light years beyond what he
had any other interviewer,

02:53:28.910 --> 02:53:30.140
I don't want to even
call you an interviewer

02:53:30.140 --> 02:53:31.650
'cause it's really about conversation.

02:53:31.650 --> 02:53:33.240
Light years beyond what anyone else

02:53:33.240 --> 02:53:36.760
had been able to engage with him

02:53:36.760 --> 02:53:40.000
was such a beacon of what's possible.

02:53:40.000 --> 02:53:40.970
And I know that,

02:53:40.970 --> 02:53:42.480
I think that's what people are drawn to.

02:53:42.480 --> 02:53:44.450
And there's a certain intimacy,

02:53:44.450 --> 02:53:47.580
that certainly to people,
our friends, as we are,

02:53:47.580 --> 02:53:48.630
and they know each other,

02:53:48.630 --> 02:53:49.900
that there's more of that,

02:53:49.900 --> 02:53:51.380
but there's an intimacy

02:53:51.380 --> 02:53:53.230
in those kinds of private conversations

02:53:53.230 --> 02:53:54.990
that are made public.

02:53:54.990 --> 02:53:55.920
And.

02:53:55.920 --> 02:53:57.940
- Well, that's the, with you,

02:53:57.940 --> 02:54:01.230
you're probably starting
to realize, and Costello,

02:54:01.230 --> 02:54:03.510
is like, part of it,

02:54:03.510 --> 02:54:04.600
because you're authentic

02:54:04.600 --> 02:54:06.726
and you're putting yourself
out there completely,

02:54:06.726 --> 02:54:10.165
people are almost not just consuming

02:54:10.165 --> 02:54:13.330
the words you're saying,

02:54:13.330 --> 02:54:17.030
they also enjoy watching you, Andrew,

02:54:17.030 --> 02:54:19.130
struggle with these ideas

02:54:19.130 --> 02:54:20.740
or try to communicate these ideas.

02:54:20.740 --> 02:54:21.750
They like the flaws,

02:54:21.750 --> 02:54:23.640
they like a human being.

02:54:23.640 --> 02:54:24.930
- Oh, good, that flaws.

02:54:24.930 --> 02:54:26.260
- Well, that's good 'cause
I got plenty of those.

02:54:26.260 --> 02:54:28.700
- But they like the self-critical aspects,

02:54:28.700 --> 02:54:30.360
like where you're very careful,

02:54:30.360 --> 02:54:32.796
where you're very
self-critical about your flaws.

02:54:32.796 --> 02:54:34.900
I mean, in that same way,

02:54:34.900 --> 02:54:36.250
it's interesting I think for people

02:54:36.250 --> 02:54:37.990
to watch me talk to Penrose,

02:54:37.990 --> 02:54:42.330
not just because Penrose
is communicating ideas,

02:54:42.330 --> 02:54:47.000
but here's this like silly
kid trying to explore ideas.

02:54:47.000 --> 02:54:48.396
Like they know this kid.

02:54:48.396 --> 02:54:51.270
There's a human connection
that is really powerful.

02:54:51.270 --> 02:54:53.610
Same, I think with Putin, right?

02:54:53.610 --> 02:54:57.490
Like it's not just as a
good interview with Putin,

02:54:57.490 --> 02:55:00.200
it's also, here's this kid struggling

02:55:00.200 --> 02:55:03.933
to talk with one of the most powerful,

02:55:04.810 --> 02:55:08.300
some will argue dangerous
people in the world.

02:55:08.300 --> 02:55:09.240
They love that.

02:55:09.240 --> 02:55:12.084
The authenticity that led up to that.

02:55:12.084 --> 02:55:14.200
And in return,

02:55:14.200 --> 02:55:15.140
I get to connect,

02:55:15.140 --> 02:55:16.840
everybody I run to in the street

02:55:16.840 --> 02:55:19.068
and all those kinds of things,

02:55:19.068 --> 02:55:21.060
there's a depth of connection there,

02:55:21.060 --> 02:55:24.350
almost within like a minute or
two that's unlike any other.

02:55:24.350 --> 02:55:25.270
- Yeah, there's an intimacy

02:55:25.270 --> 02:55:26.880
that you've formed with with them.

02:55:26.880 --> 02:55:29.770
- Yeah, we've been on this
like journey together.

02:55:29.770 --> 02:55:31.330
And yeah, I have the
same thing with Joe Rogan

02:55:31.330 --> 02:55:32.394
before I ever met him, right?

02:55:32.394 --> 02:55:33.830
Like I was,

02:55:33.830 --> 02:55:36.107
because I was a fan of
Joe for so many years,

02:55:36.107 --> 02:55:38.420
there's something,

02:55:38.420 --> 02:55:42.670
there's a kind of friendship
as absurd as it might be

02:55:42.670 --> 02:55:45.990
to say in podcasting and
listening to podcasts.

02:55:45.990 --> 02:55:46.823
- Yeah.

02:55:46.823 --> 02:55:48.900
Maybe it fills in a little bit of that

02:55:48.900 --> 02:55:50.690
or solves a little bit of that loneliness

02:55:50.690 --> 02:55:51.523
that you've been talking about earlier.

02:55:51.523 --> 02:55:53.110
- Until the robots are here.

02:55:53.110 --> 02:55:54.550
[laughing]

02:55:54.550 --> 02:55:56.570
- I have just a couple more questions,

02:55:56.570 --> 02:56:00.143
but one of them is on behalf
of your audience, which is,

02:56:01.650 --> 02:56:04.510
I'm not going to ask you
the meaning of the hedgehog,

02:56:04.510 --> 02:56:06.440
but I just want to know,

02:56:06.440 --> 02:56:08.500
does it have a name?

02:56:08.500 --> 02:56:09.950
And you don't have to tell us the name,

02:56:09.950 --> 02:56:11.010
but just, does it have a name?

02:56:11.010 --> 02:56:12.035
Yes or no?

02:56:12.035 --> 02:56:17.035
- Well, there's a name he
likes to be referred to as,

02:56:17.550 --> 02:56:19.330
and then there's a private name

02:56:19.330 --> 02:56:21.320
in the privacy of his own
company that we call each other.

02:56:21.320 --> 02:56:22.365
No.

02:56:22.365 --> 02:56:23.320
[Lex laughing]

02:56:23.320 --> 02:56:24.400
I'm not that insane.

02:56:24.400 --> 02:56:25.703
No, his name is Hedgy.

02:56:27.320 --> 02:56:28.670
He's a hedgehog.

02:56:28.670 --> 02:56:30.293
I don't like stuffed animals.

02:56:31.750 --> 02:56:35.630
But his story is one of minimalism.

02:56:35.630 --> 02:56:39.250
So I gave away everything I own,

02:56:39.250 --> 02:56:41.150
now three times in my life.

02:56:41.150 --> 02:56:43.000
By everything I mean almost everything,

02:56:43.000 --> 02:56:45.263
kept jeans and shirt and a laptop.

02:56:46.170 --> 02:56:49.140
And recently it's also been guitar,

02:56:49.140 --> 02:56:49.990
things like that.

02:56:51.290 --> 02:56:54.283
But he survived because he was always in,

02:56:55.360 --> 02:56:58.590
at least in the first two
times was in the laptop bag,

02:56:58.590 --> 02:57:00.340
and he just got lucky.

02:57:00.340 --> 02:57:03.020
And so I just liked the
perseverance of that.

02:57:03.020 --> 02:57:06.000
And I first saw him in the,

02:57:06.000 --> 02:57:07.340
the reason I got a stuffed animal,

02:57:07.340 --> 02:57:09.630
I don't have other stuffed animals,

02:57:09.630 --> 02:57:11.693
is it was in a thrift store,

02:57:13.010 --> 02:57:16.050
in this like giant pile of stuffed animals

02:57:16.050 --> 02:57:18.130
and he jumped out at me,

02:57:18.130 --> 02:57:20.050
because unlike all the rest of them,

02:57:20.050 --> 02:57:25.050
he has this intense mean look about him.

02:57:25.270 --> 02:57:26.900
That he's just,

02:57:26.900 --> 02:57:28.683
he's upset at life,

02:57:29.640 --> 02:57:30.940
at the cruelty of life.

02:57:30.940 --> 02:57:31.773
And it's just,

02:57:31.773 --> 02:57:33.393
especially in the contrast
of the other stuffed animals,

02:57:33.393 --> 02:57:35.890
they have this dumb smile on their face.

02:57:35.890 --> 02:57:37.344
If you look at most stuffed animals,

02:57:37.344 --> 02:57:38.750
they have this dumb look on their face.

02:57:38.750 --> 02:57:39.680
They're just happy.

02:57:39.680 --> 02:57:40.590
Is like "Pleasantville."

02:57:40.590 --> 02:57:41.700
- It's what we say in neuroscience,

02:57:41.700 --> 02:57:43.015
they have a smooth cortex,

02:57:43.015 --> 02:57:44.470
not many form.

02:57:44.470 --> 02:57:45.303
- Exactly.

02:57:45.303 --> 02:57:46.136
And this,

02:57:46.136 --> 02:57:48.160
like Hedgy like saw through all of it.

02:57:48.160 --> 02:57:52.040
He was like Dustyesky's
man from underground.

02:57:52.040 --> 02:57:52.920
I mean, there's a sense

02:57:52.920 --> 02:57:56.600
that he saw the darkness of
the world and persevered.

02:57:56.600 --> 02:57:57.433
So like,

02:57:57.433 --> 02:58:00.667
and there's also a famous Russian cartoon,

02:58:00.667 --> 02:58:03.950
"Hedgehog in the Fog" that I grew up with,

02:58:03.950 --> 02:58:04.950
I connected with.

02:58:04.950 --> 02:58:05.810
[Lex laughing]

02:58:05.810 --> 02:58:07.630
People who know of that cartoon,

02:58:07.630 --> 02:58:09.657
you could see it on YouTube, it's.

02:58:09.657 --> 02:58:10.830
- "Hedgehog in the Fog."

02:58:10.830 --> 02:58:11.733
- Yeah.

02:58:11.733 --> 02:58:13.830
[Lex laughing]

02:58:13.830 --> 02:58:16.108
It's just, as you would expect,

02:58:16.108 --> 02:58:17.940
especially from like
early Soviet cartoons.

02:58:17.940 --> 02:58:21.100
It's a hedgehog, like sad,

02:58:21.100 --> 02:58:22.910
walking through the fog,

02:58:22.910 --> 02:58:25.340
exploring like loneliness and sadness.

02:58:25.340 --> 02:58:26.810
It's like, but it's beautiful.

02:58:26.810 --> 02:58:27.870
It's like a piece of art,

02:58:27.870 --> 02:58:28.703
people should,

02:58:28.703 --> 02:58:29.630
even if you don't speak Russian,

02:58:29.630 --> 02:58:31.610
you'll see, you'll understand.

02:58:31.610 --> 02:58:33.970
- Oh, the moment you said
that I was going to ask,

02:58:33.970 --> 02:58:34.803
so it's in Russian?

02:58:34.803 --> 02:58:35.636
But of course it's in-

02:58:35.636 --> 02:58:37.370
- It's in Russian, but it's more,

02:58:37.370 --> 02:58:39.060
it's very little speaking in it.

02:58:39.060 --> 02:58:41.180
It's almost a,

02:58:41.180 --> 02:58:43.090
there's an interesting exploration

02:58:43.090 --> 02:58:47.410
of how you make sense of the world

02:58:47.410 --> 02:58:52.200
when you see it only
vaguely through the fog.

02:58:52.200 --> 02:58:54.150
So he's trying to understand the world.

02:58:55.470 --> 02:58:56.757
- We have Mickey Mouse,

02:58:56.757 --> 02:58:58.770
we have Bugs Bunny.

02:58:58.770 --> 02:59:01.347
We have all these crazy animals,

02:59:01.347 --> 02:59:03.610
and you have the "Hedgehog in the Fog."

02:59:03.610 --> 02:59:05.550
- So there's a certain period,

02:59:05.550 --> 02:59:06.727
and this is again,

02:59:06.727 --> 02:59:09.290
I don't know what it's attributed to,

02:59:09.290 --> 02:59:10.427
but it was really powerful,

02:59:10.427 --> 02:59:12.990
which there's a period in Soviet history,

02:59:12.990 --> 02:59:17.990
I think probably '70s and '80s where like,

02:59:18.420 --> 02:59:21.330
especially kids were
treated very seriously.

02:59:21.330 --> 02:59:24.350
Like they were treated
like they're able to deal

02:59:24.350 --> 02:59:27.850
with the weightiness of life.

02:59:27.850 --> 02:59:30.123
And that was reflected in the cartoons.

02:59:30.123 --> 02:59:32.150
And there was,

02:59:32.150 --> 02:59:37.150
it was allowed to have like
really artistic content,

02:59:37.220 --> 02:59:38.640
not like dumb cartoons

02:59:38.640 --> 02:59:41.010
that are trying to get you
to like smile and run around,

02:59:41.010 --> 02:59:42.350
but like create art.

02:59:42.350 --> 02:59:43.650
Like stuff that,

02:59:43.650 --> 02:59:45.350
you know how like short cartoons

02:59:45.350 --> 02:59:46.636
or short films can win Oscars,

02:59:46.636 --> 02:59:48.740
like that's what they're swinging for.

02:59:48.740 --> 02:59:51.140
- So what strikes me
about this is a little bit

02:59:51.140 --> 02:59:52.810
how we were talking
about the suit earlier,

02:59:52.810 --> 02:59:55.160
it's almost like they
treat kids with respect.

02:59:55.160 --> 02:59:55.993
- Yeah.

02:59:55.993 --> 02:59:58.320
- Like that they have an intelligence

02:59:58.320 --> 02:59:59.790
and they honor that intelligence.

02:59:59.790 --> 03:00:02.423
- Yeah, they're really
just adult in a small body.

03:00:03.400 --> 03:00:04.650
Like you want to protect them

03:00:04.650 --> 03:00:06.150
from the true cruelty of the world.

03:00:06.150 --> 03:00:06.983
- Sure.

03:00:06.983 --> 03:00:08.490
- But in terms of their
intellectual capacity

03:00:08.490 --> 03:00:10.290
or like philosophical capacity,

03:00:10.290 --> 03:00:11.560
they are right there with you.

03:00:11.560 --> 03:00:13.914
And so that the cartoons reflected that,

03:00:13.914 --> 03:00:16.060
the art that they consumed,

03:00:16.060 --> 03:00:17.750
education reflected that.

03:00:17.750 --> 03:00:19.150
So he represents that.

03:00:19.150 --> 03:00:22.620
I mean, there's a sense of,

03:00:22.620 --> 03:00:24.730
because it's survived so long

03:00:24.730 --> 03:00:27.370
and because I don't like stuffed animals,

03:00:27.370 --> 03:00:30.950
that it's like we've been
through all of this together

03:00:30.950 --> 03:00:31.930
and it's the same,

03:00:31.930 --> 03:00:34.380
sharing the moments
together as the friendship.

03:00:34.380 --> 03:00:36.250
And there's a sense in which,

03:00:36.250 --> 03:00:39.040
if all the world turns
on you and goes to hell,

03:00:39.040 --> 03:00:41.220
at least we got each other.

03:00:41.220 --> 03:00:42.430
And he doesn't die,

03:00:42.430 --> 03:00:45.520
because he's an inanimate object, so.

03:00:45.520 --> 03:00:47.240
- Until you animate him.

03:00:47.240 --> 03:00:49.100
- Until you animate him.

03:00:49.100 --> 03:00:50.470
And then I probably would want to know

03:00:50.470 --> 03:00:52.620
what he was thinking
about this whole time.

03:00:53.520 --> 03:00:55.240
He's probably really into Taylor Swift

03:00:55.240 --> 03:00:56.073
or something like that.

03:00:56.073 --> 03:00:58.680
And it's like that I wouldn't
even want to know anyway.

03:00:59.550 --> 03:01:01.840
- Well, I now feel a connection to Hedgy,

03:01:01.840 --> 03:01:04.150
the hedgehog that I
certainly didn't have before.

03:01:04.150 --> 03:01:05.400
And I think that encapsulates

03:01:05.400 --> 03:01:08.510
the kind of possibility of connection

03:01:09.670 --> 03:01:13.660
that is possible between
human and other object

03:01:13.660 --> 03:01:17.770
and through robotics certainly.

03:01:17.770 --> 03:01:20.000
There's a saying that I heard
when I was a graduate student

03:01:20.000 --> 03:01:22.560
that's just been ringing in my mind

03:01:22.560 --> 03:01:25.100
throughout this conversation in such a,

03:01:25.100 --> 03:01:27.223
I think appropriate way, which is that,

03:01:28.610 --> 03:01:31.350
Lex, you are in a minority of one,

03:01:31.350 --> 03:01:36.350
you are truly extraordinary
in your ability to encapsulate

03:01:36.750 --> 03:01:40.210
so many aspects of science, engineering,

03:01:40.210 --> 03:01:43.428
public communication,
about so many topics,

03:01:43.428 --> 03:01:47.160
martial arts and the emotional
depth that you bring to it.

03:01:47.160 --> 03:01:49.090
And just the purposefulness,

03:01:49.090 --> 03:01:51.680
and I think if it's not clear to people,

03:01:51.680 --> 03:01:53.930
it absolutely should be stated.

03:01:53.930 --> 03:01:55.490
But I think it's abundantly clear

03:01:55.490 --> 03:01:57.820
that just the amount of time

03:01:57.820 --> 03:02:01.420
and thinking that you put into things is,

03:02:01.420 --> 03:02:04.003
it is the ultimate mark of respect.

03:02:04.850 --> 03:02:08.070
So, I'm just extraordinarily
grateful for your friendship

03:02:08.070 --> 03:02:09.190
and for this conversation.

03:02:09.190 --> 03:02:11.180
- I'm proud to be a friend.

03:02:11.180 --> 03:02:12.440
And I just wished you showed me

03:02:12.440 --> 03:02:14.340
the same kind of respect by wearing a suit

03:02:14.340 --> 03:02:16.596
and make your father
proud maybe next time.

03:02:16.596 --> 03:02:17.530
[Andrew laughing]

03:02:17.530 --> 03:02:19.110
- Next time indeed.

03:02:19.110 --> 03:02:20.490
Thanks so much my friend.

03:02:20.490 --> 03:02:21.323
- Thank you.

03:02:21.323 --> 03:02:22.390
Thank you, Andrew.

03:02:22.390 --> 03:02:24.570
- Thank you for joining
me for my discussion

03:02:24.570 --> 03:02:26.320
with Dr. Lex Fridman.

03:02:26.320 --> 03:02:29.180
If you're enjoying this
podcast and learning from it,

03:02:29.180 --> 03:02:31.400
please consider subscribing on YouTube.

03:02:31.400 --> 03:02:35.185
As well, you can subscribe
to us on Spotify or Apple.

03:02:35.185 --> 03:02:38.250
Please leave any questions
and comments and suggestions

03:02:38.250 --> 03:02:40.880
that you have for future
podcast episodes and guests

03:02:40.880 --> 03:02:43.270
in the comment section on YouTube.

03:02:43.270 --> 03:02:46.820
At Apple, you can also leave
us up to a five-star review.

03:02:46.820 --> 03:02:48.490
If you'd like to support this podcast,

03:02:48.490 --> 03:02:49.670
we have a Patreon.

03:02:49.670 --> 03:02:51.893
That's patreon.com/andrewhuberman.

03:02:52.860 --> 03:02:56.240
And there you can support us
at any level that you like.

03:02:56.240 --> 03:02:58.570
Also, please check out
our sponsors mentioned

03:02:58.570 --> 03:03:00.890
at the beginning of the podcast episode.

03:03:00.890 --> 03:03:03.240
That's the best way to
support this podcast.

03:03:03.240 --> 03:03:06.800
Links to our sponsors can
be found in the show notes.

03:03:06.800 --> 03:03:09.533
And finally, thank you for
your interest in science.

03:03:10.532 --> 03:03:13.115
[bright music]

